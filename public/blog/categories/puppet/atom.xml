<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: puppet | Shit Gary Says]]></title>
  <link href="http://garylarizza.com/blog/categories/puppet/atom.xml" rel="self"/>
  <link href="http://garylarizza.com/"/>
  <updated>2014-03-08T09:10:25-05:00</updated>
  <id>http://garylarizza.com/</id>
  <author>
    <name><![CDATA[Gary larizza]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Building a Functional Puppet Workflow Part 3b: More R10k Madness]]></title>
    <link href="http://garylarizza.com/blog/2014/03/07/puppet-workflow-part-3b/"/>
    <updated>2014-03-07T11:00:00-05:00</updated>
    <id>http://garylarizza.com/blog/2014/03/07/puppet-workflow-part-3b</id>
    <content type="html"><![CDATA[<p><a href="http://garylarizza.com/blog/2014/02/18/puppet-workflow-part-3/">In the last workflows post,</a>, I talked about dynamic Puppet
environments and introduced R10k, which is an awesome tool for mapping modules
to their environments which are dynamically generated by git branches. I didn&rsquo;t
get out everything I wanted to say because:</p>

<ul>
<li>I was tired of that post sitting stale in a Google Doc</li>
<li>It was already goddamn long</li>
</ul>


<p>So because of that, consider this a continuation of that previous monstrosity
that talks about additional uses of R10k beyond the ordinary</p>

<h2>Let&rsquo;s talk Hiera</h2>

<p>But seriously, let&rsquo;s not actually talk about what Hiera does since
<a href="http://docs.puppetlabs.com/hiera/1/complete_example.html">there are better docs</a> out there for that. I&rsquo;m
also not going to talk about WHEN to use Hiera because
<a href="http://garylarizza.com/blog/2013/12/08/when-to-hiera/">I&rsquo;ve already done that before.</a> Instead, let&rsquo;s talk about a workflow
for submitting changes to Hiera data and testing it out before it enters into
production.</p>

<p>Most people store their Hiera data (if they&rsquo;re using a backend that reads Hiera
data from disk anyways) in separate repos as their Puppet repo. Some DO tie the
Hiera datadir folder to something like the main Puppet repo that houses their
<code>Puppetfie</code> (if they&rsquo;re using R10k), but for the most part it&rsquo;s a separate
repo because you may want separate permissions for accessing that data.
For the purposes of this post, I&rsquo;m going to refer to
<a href="https://github.com/glarizza/hiera_environment">a repository I use for storing Hiera data</a> that&rsquo;s out on Github.</p>

<p>The next logical step would be to integrate that Hiera repo into R10k so R10k can
track and create paths for Hiera data just like it did for Puppet.</p>

<p><strong>NOTE: Fundamentally, all that R10k does is checkout modules to a specific
path whose folder name comes from a git branch. PUPPET ties its environment
to this folder name with some <code>puppet.conf</code> trickery. So, to say that R10k
&ldquo;creates dynamic environments&rdquo; is the end-result, but not the actual job
of the tool.</strong></p>

<p>We COULD add Hiera&rsquo;s repository to the <code>/etc/r10k.yaml</code> file to track and
create folders for us, and if we did it EXACTLY like we did for Puppet we
would most definitely run into <a href="https://github.com/adrienthebo/r10k/issues/48">this R10k bug</a> (AND,
<a href="https://github.com/adrienthebo/r10k/issues/90">it comes up again in this bug</a>).</p>

<p><strong>UPDATE: So, I originally wrote this post BEFORE R10k version 1.1.4 was
released. Finch released version 1.1.4 which FIXES THESE BUGS&hellip;so the workflow
I&rsquo;m going to describe (i.e. using prefixing to solve the problem of using
multiple repos in <code>/etc/r10k.yaml</code> that could possibly share branch names)
TECHNICALLY does NOT need to be followed &lsquo;to the T&rsquo;, as it were. You can
disable prefixing when it comes to that step, and modify
<code>/etc/puppetlabs/puppet/hiera.yaml</code> so you don&rsquo;t prepend &lsquo;hiera_&rsquo; to the
path of each environment&rsquo;s folder, and you should be totally fine&hellip;you know,
as long as you use version 1.1.4 or greater of R10k.  So, be forewarned</strong></p>

<p>The issue is those bugs is that R10k collects the names of ALL the environments
from ALL the sources at once, so if you have multiple source repositories and
they share branch names, then you have clashes (since it only stores ONE branch
name internally). The solution that Finch came up with was prefixing (or,
prefixing the name of the branch with the name of the source). When you prefix,
however, it creates a folder on-disk that matches the prefixed name (e.g.
NameOfTheSource_NameOfTheBranch ). This is actually fine since we&rsquo;ll catch it
and deal with it, but you should be aware of it. Future versions of R10k may
most likely deal with this in a different manner, so make sure to check out the
R10k docs before blindly copying my code, okay? (Update: See the previous, bolded
paragraph where I describe how Finch DID JUST THAT).</p>

<p><a href="http://garylarizza.com/blog/2014/02/18/puppet-workflow-part-3/">In the previous post</a> I setup a file called <code>r10k_installation.pp</code>
to setup R10k. Let&rsquo;s revisit that manifest it and modify it for
<a href="https://github.com/glarizza/hiera_environment">my Hiera repo:</a></p>

<p>{% codeblock lang:puppet /var/tmp/r10k_installation.pp %}
class { &lsquo;r10k&rsquo;:
  version           => &lsquo;1.1.4&rsquo;,
  sources           => {</p>

<pre><code>'puppet' =&gt; {
  'remote'  =&gt; 'https://github.com/glarizza/puppet_repository.git',
  'basedir' =&gt; "${::settings::confdir}/environments",
  'prefix'  =&gt; false,
},
'hiera' =&gt; {
  'remote'  =&gt; 'https://github.com/glarizza/hiera_environment.git',
  'basedir' =&gt; "${::settings::confdir}/hiera",
  'prefix'  =&gt; true,
}
</code></pre>

<p>  },
  purgedirs         => [&ldquo;${::settings::confdir}/environments&rdquo;],
  manage_modulepath => true,
  modulepath        => &ldquo;${::settings::confdir}/environments/\$environment/modules:/opt/puppet/share/puppet/modules&rdquo;,
}
{% endcodeblock %}</p>

<p><strong>NOTE: For the duration of this post, I&rsquo;ll be referring to Puppet Enterprise
specific paths (like <code>/etc/puppetlabs/puppet</code> for $confdir). Please do the
translation for open source Puppet, as R10k will work just fine with either
the open source edition or the Enterprise edition of Puppet</strong></p>

<p>You&rsquo;ll note that I added a source called &lsquo;hiera&rsquo; that tracks my Hiera
repository, creates sub-folders in <code>/etc/puppetlabs/puppet/hiera</code>, and enables
prefixing to deal with the bug I mentioned in the previous paragraph. Now,
let&rsquo;s run Puppet and do an R10k synchronization:</p>

<p>```
[root@master1 garysawesomeenvironment]# puppet apply /var/tmp/r10k_installation.pp
Notice: Compiled catalog for master1 in environment production in 1.78 seconds
Notice: /Stage[main]/R10k::Config/File[r10k.yaml]/content: content changed &lsquo;{md5}c686917fcb572861429c83f1b67cfee5&rsquo; to &lsquo;{md5}69d38a14b5de0d9869ebd37922e7dec4&rsquo;
Notice: Finished catalog run in 1.24 seconds</p>

<p>[root@master1 puppet]# r10k deploy environment -pv
[R10K::Task::Deployment::DeployEnvironments &ndash; INFO] Loading environments from all sources
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment hiera_testing
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment hiera_production
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment hiera_master
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment production
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync &ndash; INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying redis into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying make into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying concat into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying portage into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying git into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying ruby into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying redis into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying make into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying concat into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying portage into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying git into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying ruby into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment master
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync &ndash; INFO] Deploying redis into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying portage into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying git into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying redis into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying portage into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying git into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment garysawesomeenvironment
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync &ndash; INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying redis into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying make into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying concat into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying portage into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying git into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying ruby into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment development
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync &ndash; INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Deployment::PurgeEnvironments &ndash; INFO] Purging stale environments from /etc/puppetlabs/puppet/environments
[R10K::Task::Deployment::PurgeEnvironments &ndash; INFO] Purging stale environments from /etc/puppetlabs/puppet/hiera</p>

<p>[root@master1 puppet]# ls /etc/puppetlabs/puppet/hiera
hiera_master  hiera_production  hiera_testing</p>

<p>[root@master1 puppet]# ls /etc/puppetlabs/puppet/environments/
development  garysawesomeenvironment  master  production
```</p>

<p>Great, so it configured R10k to clone the Hiera repository to
<code>/etc/puppetlabs/puppet/hiera</code> like we wanted it to, and you can see that with
prefixing enabled we have folders named &ldquo;hiera_${branchname}&rdquo;.</p>

<p>In Puppet, the magical connection that maps these subfolders to Puppet
environments is in <code>puppet.conf</code>, but for Hiera that&rsquo;s the <code>hiera.yaml</code> file.
I&rsquo;ve included that file in my <a href="https://github.com/glarizza/hiera_environment">Hiera repo</a>, so let&rsquo;s look at the
copy at <code>/etc/puppetlabs/puppet/hiera/hiera_production/hiera.yaml</code>:</p>

<h2>{% codeblock lang:yaml /etc/puppetlabs/puppet/hiera/hiera_production/hiera.yaml %}</h2>

<p>:backends:
  &ndash; yaml
:hierarchy:
  &ndash; &ldquo;%{clientcert}&rdquo;
  &ndash; &ldquo;%{environment}&rdquo;
  &ndash; global</p>

<p>:yaml:
  :datadir: &lsquo;/etc/puppetlabs/puppet/hiera/hiera_%{environment}/hieradata&rsquo;
{% endcodeblock %}</p>

<p>The magical line is in the <code>:datadir:</code> setting of the <code>:yaml:</code> section; it
uses <code>%{environment}</code> to evaluate the environment variable set by Puppet and
set the path accordingly.</p>

<p>As of right now R10k is configured to clone Hiera data from a known repository
to <code>/etc/puppetlabs/puppet/hiera</code>, to create sub-folders based on branches to
that repository, and to tie data provided to each Puppet environment to the
respective subfolder of <code>/etc/puppetlabs/puppet/hiera</code> that matches the pattern
of <strong>&ldquo;hiera_(environment_name)&rdquo;</strong>.</p>

<h3>The problem with <code>hiera.yaml</code></h3>

<p>You&rsquo;ll notice that each subfolder to <code>/etc/puppetlabs/puppet/hiera</code> contains
its own copy of <code>hiera.yaml</code>.  You&rsquo;re probably drawing the conclusion that
each Puppet environment can read from its own <code>hiera.yaml</code> for Hiera configuration.</p>

<p>And you would be wrong.</p>

<p><a href="http://projects.puppetlabs.com/issues/11784">For information on this bug, check out this link.</a> You&rsquo;ll see
that we provide a &lsquo;hiera_config&rsquo; configuration option in Puppet that allows
you to specify the path to <code>hiera.yaml</code>, but Puppet loads that config as
singleton, which means that it&rsquo;s read initially when the Puppet master process
starts up and it&rsquo;s NOT environment-aware. The workaround is to use one
<code>hiera.yaml</code> for all environments on a Puppet master but to dynamically change
the <code>:datadir:</code> path according to the current environment (in the same way that
dynamic Puppet environments abuse &lsquo;$environment&rsquo; in <code>puppet.conf</code>). You gain
the ability to have per-environment changes to Hiera data but lose the ability
to do things like using different hierarchies for different environments. As
of right now, if you want a different hierarchy then you&rsquo;re going to need to
use a different master (or do some hacky things that I don&rsquo;t even want to
BEGIN to approach in this article).</p>

<p>In summary &ndash; there will be a hiera.yaml per environment, but they will not
be consulted on a per-environment basis.</p>

<h3>Workflow for per-environment Hiera data</h3>

<p><a href="http://garylarizza.com/blog/2014/02/18/puppet-workflow-part-3/">Looking back on the previous post,</a> you&rsquo;ll see that the workflow
for updating Hiera data is identical to the workflow for updating code to your
Puppet environments.  Namely, to create a new environment for testing Hiera
data, you will:</p>

<ul>
<li>Push a branch to the Hiera repository and name it accordingly (remembering
that the name you choose will be a new environment).</li>
<li>Run R10k to synchronize the data down to the Puppet master</li>
<li>Add your node to that environment and test out the changes</li>
</ul>


<p>For existing environments, simply push changes to that environment&rsquo;s branch
and repeat the last two steps.</p>

<p><strong>NOTE: Puppet environments and Hiera environments are linked &ndash; both tools use
the same &lsquo;environment&rsquo; concept and so environment names MUST match for the data
to be shared (i.e. if you create an environment in Puppet called &lsquo;yellow&rsquo;, you
will need a Hiera environment called &lsquo;yellow&rsquo; for that data).</strong></p>

<p>This tight-coupling can cause issues, and will ultimately mean that certain
branches are longer-lived than others. It&rsquo;s also the reason why I don&rsquo;t use
defaults in my <code>hiera()</code> lookups inside Puppet manifests &ndash; I WANT the early
failure of a compilation error to alert me of something that needs fixed.</p>

<p>You will need to determine whether this tight-coupling is worth it for your
organization to tie your Hiera repository directly into R10k or to handle it
out-of-band.</p>

<h2>R10k and monolithic module repositories</h2>

<p>One of the first requirements you encounter when working with R10k is that your
component modules need to be stored in their own repositories.  That convention
is still relatively new &ndash; it wasn&rsquo;t so long ago that we were recommending that
modules be locked away in a giant repo. Why?</p>

<ul>
<li>It&rsquo;s easier to clone</li>
<li>The state of module reusability was poor</li>
</ul>


<p>The main reason was that it was easier to put everything in one repo and clone
it out on all your Puppet master servers. This becomes insidious as your module
count rises and people start doing lovely things like committing large binaries
into modules, pulling in old versions of modules they find out on the web, and
the like. It also becomes an issue when you start needing to lock committers
out of specific directories due to sensitive data, and blah blah blah blah&hellip;</p>

<p>There are better posts out there justifying/villafying the choice of one or
multiple repositories, this section&rsquo;s meant only to show you how to incorporate
a single repository containing multiple modules into your R10k workflow.</p>

<p><a href="http://garylarizza.com/blog/2014/02/18/puppet-workflow-part-3/">From the last post</a> you&rsquo;ll remember that the <code>Puppetfile</code> allows
you to tie a repository, and some version reference, to a directory using
R10k. Incorporating a monolithic repository starts with an entry in the
<code>Puppetfile</code> like so:</p>

<p>{% codeblock lang:ruby Puppetfile %}
mod &ldquo;my_big_module_repo&rdquo;,
  :git => &ldquo;git://github.com/glarizza/my_big_module_repo.git&rdquo;,
  :ref => &lsquo;1.0.0&rsquo;
{% endcodeblock %}</p>

<p><strong>NOTE: That git repository doesn&rsquo;t exist. I don&rsquo;t HAVE a monolithic repo to
demonstrate, so I&rsquo;ve chosen an arbitrary URI. Also note that you can use ANY
name you like after the <code>mod</code> syntax to name the resultant folder &ndash; it doesn&rsquo;t
HAVE to mirror the URI of the repository.</strong></p>

<p>Adding this entry to the <code>Puppetfile</code> would checkout that repository to
wherever all the other modules are checked out with a folder name of
&lsquo;my_big_module_repo&rsquo;. Within that folder would most-likely (again, depending
on how you&rsquo;ve laid out your repository) contain subfolders containing Puppet
modules. This entry gets the modules onto your Puppet master, but it doesn&rsquo;t
make Puppet aware of their location. For that, we&rsquo;re going to need to add an
entry to the &lsquo;modulepath&rsquo; configuration item in <code>puppet.conf</code></p>

<p>Inside <code>/etc/puppetlabs/puppet/puppet.conf</code> you should see a configuration item
called &lsquo;modulepath&rsquo; that currently has a value of:</p>

<p><code>
modulepath = /etc/puppetlabs/puppet/environments/$environment/modules:/opt/puppet/share/puppet/modules
</code></p>

<p>The modulepath itself works like a PATH environment variable in Linux &ndash; it&rsquo;s
a priority-based lookup mechanism that Puppet uses to find modules. Currently,
Puppet will first look in <code>/etc/puppetlabs/puppet/environments/$environment/modules</code>
for a module. If a the module that Puppet was looking for was found, Puppet
will use it and not inspect the second path. If the module was not found at the
FIRST path, it will inspect the second path. Failing to find the module at the
second path results in a compilation error for Puppet. Using this to our
advantage, we can add the path to the monolithic repository checked-out by the
<code>Puppetfile</code> AFTER the path to where all the individual modules are checked-out.
This should look something like this:</p>

<p><code>
modulepath = /etc/puppetlabs/puppet/environments/$environment/modules:/etc/puppetlabs/puppet/environments/$environment/modules/my_big_module_repo:/opt/puppet/share/puppet/modules
</code></p>

<p><strong>Note: This assumes all modules are in the root of the monolithic repo. If
they&rsquo;re in a subdirectory, you must adjust accordingly</strong></p>

<p>That&rsquo;s a huge line (and if you&rsquo;re afraid of anything over 80 column-widths then
I&rsquo;m sorry&hellip;and you should probably buy a new monitor&hellip;and the 80s are over),
but the gist is that we&rsquo;re first going to look for modules checked out by R10k,
THEN we&rsquo;re going to look for modules in our monolithic repo, then we&rsquo;re going
to look in Puppet Enterprise&rsquo;s vendored module directory, and finally, like I
said above, we&rsquo;ll fail if we can&rsquo;t find our module. This will allow you to KEEP
using your monolithic repository and also slowly cut modules inside that
monolithic repo over to their own repositories (since when they gain their own
repository, they will be located in a path that COMES before the monolithic
repo, and thus will be given priority).</p>

<h2>Using MCollective to perform R10k synchronizations</h2>

<p>This section is going to be much less specific than the rest because the piece
that does the ACTION is part of <a href="http://forge.puppetlabs.com/zack/r10k">a module for R10k</a>. As of the time
of this writing, this agent is in one state, but that could EASILY change. I
will defer to <a href="http://forge.puppetlabs.com/zack/r10k">the module in question</a> (and specifically its
README file) should you need specifics (or if my module is dated). What I CAN
tell you, however, is that <a href="http://forge.puppetlabs.com/zack/r10k">the R10k module</a> does come with a class
that will setup and configure both an MCollective agent for R10k and also a
helper application that should make doing R10k synchroniations on multiple
Puppet masters much easier than doing them by hand.  First, you&rsquo;ll need to
INSTALL the MCollective agent/application, and you can do that by pulling
down <a href="http://forge.puppetlabs.com/zack/r10k">the module</a> and its dependencies, and classifying all Puppet
masters with R10k enabled by doing the following:</p>

<p><code>puppet
include r10k::mcollective
</code></p>

<p>Terribly difficult, huh? With that, both the MCollective agent and application
should be available to MCollective on that node. The way to trigger a
syncronization is to login to an account on a machine that has MCollective
client access (in Puppet Enterprise, this would be any Puppet master that&rsquo;s
allowed the role, and then, specifically, the <code>peadmin</code> user&hellip;so doing a
<code>su - peadmin</code> should afford you access to that user), and perform the following
command:</p>

<p><code>
mco r10k deploy
</code></p>

<p>This is where the README differs a bit, and the reason for that is because Finch
changed the syntax that R10k uses to synchronize and deploy modules to a Master.
The CURRENTLY accepted command (because, knowing Finch, that shit might change)
is <code>r10k deploy environment -p</code>, and the action to the MCollective agent that
EXECUTES that command is the &lsquo;deploy&rsquo; action.  The README refers to the
&lsquo;synchronize&rsquo; action, which executes the <code>r10k synchronize</code> command. This command
MAY STILL WORK, but it&rsquo;s deprecated, and so it&rsquo;s NOT recommended to be used.</p>

<p>Like I said before, this agent is subject to change (mainly do to R10k command
deprecation and maturation), so definitely refer to the README and the code
itself for more information (or
<a href="http://github.com/acidprime/puppet-r10k">file issues and pull requests on the module repo directly</a>).</p>

<h2>Tying R10k to CI workflows</h2>

<p>I spent a year doing some presales work for the Puppet Labs SE team, so I can
hand-wave and tapdance like a motherfucker. I&rsquo;m going to need those skills for
this next section, because if you thought the previous section glossed over the
concepts pretty quickly and without much detail, then this section is going to
feel downright vaporous (is that a word? Fuck it; I&rsquo;m handwaving &ndash; it&rsquo;s
a word). I really debated whether to include the following sections in this
post because I don&rsquo;t really give you much specific information; it&rsquo;s all very
generic and full of &ldquo;ideas&rdquo; (though I do list some testing libraries below that
are helpful if you&rsquo;ve never heard of them). Feel free to abandon ship and skip
to the FINAL section right now if you don&rsquo;t want to hear about &lsquo;ideas&rsquo;.</p>

<p>For the record, I&rsquo;m going to just pick and use the term &ldquo;CI&rdquo; when I&rsquo;m referring
to the process of automating the testing and deployment of, in this case,
Puppet code.  There have definitely been posts arging about which definition is
more appropriate, but, frankly, I&rsquo;m just going to pick a term and go with it,</p>

<p>The issue at hand is that when you talk &ldquo;CI&rdquo; or &ldquo;CD&rdquo; or &ldquo;Continuous (fill_in_the_blank)&rdquo;, you&rsquo;re
talking about a workflow that&rsquo;s tailored to each organization (and sometimes
each DEPARTMENT of an organization). Sometimes places can agree on a specific
tool to assist them with this process (be it Jenkins, Hudson, Bamboo, or
whatever), but beyond that it&rsquo;s anyone&rsquo;s game.</p>

<p>Since we&rsquo;re talking PUPPET code, though, you&rsquo;re restricted to certain tasks
that will show up in any workflow&hellip;and THAT is what I want to talk about here.</p>

<p>To implement some sort of CI workflow means laying down a &lsquo;pipeline&rsquo; that takes a
change of your Puppet code (a new module, a change to an existing module, some
Hiera data updates, whatever) from the developer&rsquo;s/operations engineer&rsquo;s workstation
right into production.  The way we do this with R10k currently is to:</p>

<ul>
<li>Make a change to an individual module</li>
<li>Commit/push those changes to the module&rsquo;s remote repository</li>
<li>Create a test branch of the puppet_repository</li>
<li>Modify the <code>Puppetfile</code> and tie your module&rsquo;s changes to this environment</li>
<li>Commit/push those changes to the puppet_repository</li>
<li>Perform an R10k synchronization</li>
<li>Test</li>
<li>Repeat steps 1-7 as necessary until shit works how you like it</li>
<li>Merge the changes in the test branch of the puppet_repository with the production branch</li>
<li>Perform an R10k synchronization</li>
<li>Watch code changes become active in your production environment</li>
</ul>


<p>Of those steps, there&rsquo;s arguably about 3 unique steps that could be automated:</p>

<ul>
<li>R10k synchronizations</li>
<li>&lsquo;Testing&rsquo; (whatever that means)</li>
<li>Merging the changes in the test branch of the puppet_repository with the production branch</li>
</ul>


<p><strong>NOTE: As we get progressively-more-handwavey (also probably not a word, but fuck it &ndash; let&rsquo;s
be thought leaders and CREATE IT), each one of these steps is going to be more
and more&hellip;generic. For example &ndash; to say &ldquo;test your code&rdquo; is a great idea, but,
seriously, defining how to do that could (and should) be multiple blog posts.</strong></p>

<h3>Laying down the pipeline</h3>

<p>If I were building an automated workflow, the first thing I would do is
setup something like Jenkins and configure it to watch the puppet_repository
that contains the <code>Puppetfile</code> mapping all my modules and versions to Puppet
environments. On changes to this repository, we want Jenkins to perform an R10k
synchronization, run tests, and then, possibly, merge those changes into
production (depending on the quality of your tests and how &lsquo;webscale&rsquo; you think
you are on that day).</p>

<h3>R10k synchronizations</h3>

<p>If you&rsquo;re paying attention, we solved this problem in the previous section with
the R10k MCollective agent. Jenkins should be running on a machine that has the
ability to execute MCollective client commands (such as triggering
<code>mco r10k deploy</code> when necessary).  You&rsquo;ll want to tailor your calls from
Jenkins to only deploy environments it&rsquo;s currently testing (remember in the
puppet_repository that topic branches map to Puppet environments, so this
is a per-branch action) as opposed to deploying ALL environments every time.</p>

<p>Also, if you&rsquo;re buiding a pipeline, you might not want to do R10k
synchronizations on ALL of your Puppet Masters at this point. Why not? Well,
if your testing framework is good enough and has sufficient coverage that
you&rsquo;re COMPLETELY trusting it to determine whether code is acceptable or not,
then this is just the FIRST step &ndash; making the code available to be tested. It&rsquo;s
not passed tests yet, so pushing it out to all of your Puppet masters is a bit
wasteful. You&rsquo;ll probably want to only synchronize with a single master that&rsquo;s
been identified for testing (and a master that has the ability to spin up
fresh nodes, enforce the Puppet code on them, submit those nodes to a battery
of tests, and then tear them down when everything has been completed).</p>

<p>If you&rsquo;re like the VAST majority of Puppet users out there that DON&rsquo;T have a
completely automated testing framework that has such complete coverage that you
trust it to determine whether code changes are acceptable or not, then you&rsquo;re
probably &lsquo;testing&rsquo; changes manually. For these people, you&rsquo;ll probably want to
synchronize code to whichever Puppet master(s) are suitable.</p>

<p>The cool thing about these scenarios is that MCollective is flexible enough
to handle this. MCollective has the ability to filter your nodes based on
things like available MCollective agents, Facter facts, Puppet classes, and
even things like the MD5 hashes of arbitrary files on the filesystem&hellip;so
however you want to restrict synchronization, you can do it with MCollective.</p>

<p>After all of that, the answer here is &ldquo;Use MCollective to do R10k syncs/deploys.&rdquo;</p>

<h3>Testing</h3>

<p>This section needs its own subset of blog posts. There are all kinds of tools
that will allow you to test all sorts of things about your Puppet code (from
basic syntax checking and linting, to integration tests that check for the
presence of resources in the catalog, to acceptance-level tests that check
the end-state of the system to make sure Puppet left it in a state that&rsquo;s
acceptable).  The most common tools for these types of tests are:</p>

<ul>
<li><a href="http://puppet-lint.com">Puppet-lint</a></li>
<li><a href="http://rspec-puppet.com">Rspec-puppet</a></li>
<li><a href="http://github.com/puppetlabs/beaker">Beaker</a></li>
<li><a href="https://github.com/serverspec/serverspec">Serverspec</a></li>
<li>And more&hellip;</li>
</ul>


<p>Unfortunately, the point of this section is NOT to walk you through setting up
one or more of those tools (I&rsquo;d love to write those posts soon&hellip;), but rather
to make you aware of their presence and identify where they fit in our Pipeline.</p>

<p>Once you&rsquo;ve synchronized/deployed code changes to a specific machine (or
subset of machines), the next step is to trigger tests.</p>

<p>Backing up the train a bit, certain kinds of &lsquo;tests&rsquo; should be done WELL in
advance of this step. For example, if code changes don&rsquo;t even pass basic syntax
checking and linting, they shouldn&rsquo;t even MAKE it into your repository. Things
like pre-commit hooks will allow you to trigger syntactical checks and linting
before a commit is allowed. We&rsquo;re assuming you&rsquo;ve already set those up (and
if you&rsquo;ve NOT, then you should probably do that RIGHT NOW).</p>

<p>Rather, in this section, we&rsquo;re talking about doing some basic integration
smoke testing (i.e. running the rspec-puppet tests on all the modules to ensure
that what we EXPECT in the catalog is actually IN the catalog), moving into
acceptance level testing (i.e. spinning up pristine/clean nodes, actually
applying the Puppet code to the nodes, and then running things like Beaker
or Serverspec on the nodes to check the end-state of things like services, open
ports, configuration files, and whatever to ensure that Puppet ACTUALLY left
the system in a workable state), and then returning a &ldquo;PASS&rdquo; or
&ldquo;FAIL&rdquo; response to Jenkins (or whatever is controlling your pipeline).</p>

<p>These tests can be as thorough or as loose as is acceptable to you (obviously,
the goal is to automate ALL of your tests so you don&rsquo;t have to manually check
ANY changes, but that&rsquo;s the nerd-nirvana state where we&rsquo;re all browsing the web
all day), but they should catch the most NOTORIOUS and OBVIOUS things FIRST.
Follow the same rules you did when you got started with Puppet &ndash; catch the
things that are easiest to catch and start building up your cache of &ldquo;Total
Time Saved.&rdquo;</p>

<p>Jenkins needs to be able to trigger these tests from wherever it&rsquo;s running,
so your Jenkins box needs the ability to, say, spin up nodes in ESX, or
locally with something like Vagrant, or even cloud nodes in EC2 or GCE, then
TRIGGER the tests, and finally get a &ldquo;PASS&rdquo; or &ldquo;FAIL&rdquo; response back. The
HARDEST part here, by far, is that you have to define what level of testing
you&rsquo;re going to implement, how you&rsquo;re going to implement it, and devise
the actual process to perform the testing. Like I said before, there are other
blog posts that talk about this (and I hope to tackle this topic in the very
near future), so I&rsquo;ll leave it to them for the moment.</p>

<h3>To merge or not to merge</h3>

<p>The final step for any test code is to determine whether it should be merged
into production or not. Like I said before, if your tests are sufficient and
are adequate at determining whether a change is &lsquo;good&rsquo; or not, then you can
look at automating the process of merging those changes into production and
killing off the test branch (or, NOT merging those changes, and leaving the
branch open for more changes).</p>

<p>Automatically merging is scary for obvious reasons, but it&rsquo;s also a good &lsquo;test&rsquo;
for your test coverage. Committing to a &lsquo;merge upon success&rsquo; workflow takes
trust, and there&rsquo;s absolutely no shame in leaving this step to a human,
to a change review board, or to some out-of-band process.</p>

<h2>Use your illusion</h2>

<p>These are the most common questions I get asked after the initial shock of R10k,
and its workflow, wears off. Understand that I do these posts NOT from a &ldquo;Here&rsquo;s
what you should absolutely be doing!&rdquo; standpoint, but more from a &ldquo;Here&rsquo;s what&rsquo;s
going on out there.&rdquo; vantage. Every time I&rsquo;m called on-site with a customer, I
evaluate:</p>

<ul>
<li>The size and experience level of the team involved</li>
<li>The processes that the team must adhere to</li>
<li>The Puppet experience level of the team</li>
<li>The goals of the team</li>
</ul>


<p>Frankly, after all those observations, sometimes I ABSOLUTELY come to the
conclusion that something like R10k is entirely-too-much process for
not-enough benefit. For those who are a fit, though, we go down the checklists
and tailor the workflow to the environment.</p>

<h2>What more IS there on R10k?</h2>

<p>I do have at least a couple of more posts in me on some specific issues I&rsquo;ve
hit when consulting with companies using R10k, such as:</p>

<ul>
<li>How best to use Hiera and R10k with Puppet &lsquo;environments&rsquo; and internal, long-term &lsquo;environments&rsquo;</li>
<li>Better ideas on &lsquo;what to branch and why&rsquo; with regard to component modules and the puppet_repository</li>
<li>To inherit or not to inherit with Roles</li>
<li>How to name things (note that I work for Puppet Labs, so I&rsquo;m most likely very WRONG with this section)</li>
<li>Other random things I&rsquo;ve noticed&hellip;</li>
</ul>


<p>Also, I apologize if it&rsquo;s been awhile since I&rsquo;ve replied to a couple of
comments. I&rsquo;m booked out 3 months in advance and things are pretty wild at
the moment, but I&rsquo;m REALLY thankful of everyone who cares enough to drop a
note, and I hope I&rsquo;m providing some good info you can actually use! Cheers!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building a Functional Puppet Workflow Part 3: Dynamic Environments with R10k]]></title>
    <link href="http://garylarizza.com/blog/2014/02/18/puppet-workflow-part-3/"/>
    <updated>2014-02-18T12:48:18-05:00</updated>
    <id>http://garylarizza.com/blog/2014/02/18/puppet-workflow-part-3</id>
    <content type="html"><![CDATA[<p>Workflows are like kickball games: everyone knows the general idea of what&rsquo;s
going on, there&rsquo;s an orderly progression towards an end-goal, nobody wants to
be excluded, and people lose their shit when they get hit in the face by a big
rubber ball.  Okay, so maybe it&rsquo;s not a perfect mapping but you get the idea.</p>

<p>The previous two posts (<a href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-1/">one</a> and <a href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-2/">two</a>) focused on
writing modules, wrapping modules, and classification. While BOTH of these
things are very important in the grand scheme of things, one of the biggest
problems people get hung-up on is how do you iterate upon your modules, and,
more importantly, how do you eventually get these changes pushed into production
in a reasonably orderly fashion?</p>

<p>This post is going to be all over the place. We&rsquo;re gonna cover the idea of
separate environments in Puppet, touch on dynamic environments, and round it
out with that mother-of-a-shell-script-turned-personal-savior, R10k. Hold on
to your shit.</p>

<h2>Puppet Environments</h2>

<p><a href="http://docs.puppetlabs.com/guides/environment.html">Puppet has the concept of &lsquo;environments&rsquo;</a> where you can logically
separate your modules and manifest (read: <code>site.pp</code>) into separate folders
to allow for nodes to get entirely separate bits of code based on which
&lsquo;environment&rsquo; the node belongs to.</p>

<p>Puppet environments are statically set in <code>puppet.conf</code>, but,
<a href="http://bit.ly/puppetgit">as other blog posts have noted</a>, you can do some crafty things in
<code>puppet.conf</code> to give you the solution of having &lsquo;dynamic environments&rsquo;.</p>

<p><strong>NOTE</strong>: The solutions in this post are going to rely on Puppet environments,
however environments aren&rsquo;t without their own shortcomings
<a href="http://projects.puppetlabs.com/issues/12173">namely, this bug on Ruby plugins in Puppet</a>). For testing and
promoting Puppet classes written in the DSL, environments will help you out
greatly. For complete separation of Ruby instances and any plugins to Puppet
written in Ruby, however, you&rsquo;ll need separate masters (which is something that
I won&rsquo;t be covering in this article).</p>

<h2>One step further &ndash; &lsquo;dynamic&rsquo; environments</h2>

<p>Adrien Thebo, hitherto known as &lsquo;Finch&rsquo;, &ndash; who is known for building awesome
things and talking like he&rsquo;s fresh from a Redbull binge &ndash; created the
<a href="http://bit.ly/puppetgit">now-famous blog post on creating dynamic environments in Puppet with git.</a>
That post relied upon a post-commit hook to do all the jiggery-pokery necessary
to checkout the correct branches in the correct places, and thus it had a heavy
reliance upon git.</p>

<p>Truly, the only magic in <code>puppet.conf</code> was the inclusion of &lsquo;$environment&rsquo; in
the <code>modulepath</code> configuration entry on the Puppet master (literally that
string and not the evaluated form of your environment). By doing that, the
Puppet master would replace the string &lsquo;$environment&rsquo; with the environment
of the node checking in and would look to that path for Puppet manifests
and modules. If you use something OTHER than git, it would be up to you to
create a post-receive hook that populated those paths, but you could still
replicate the results (albiet with a little work on your part).</p>

<p>People used this pattern and it worked fairly well. Hell, it STILL works
fairly well, nothing has changed to STOP you from using it. What changed,
however, was the ecosystem around modules, the need for individual module
testing, and the further need to automate this whole goddamn process.</p>

<p>Before we deliver the &lsquo;NEW SOLUTION&rsquo;, let&rsquo;s provide a bit of history and
context.</p>

<h2>Module repositories: the one-to-many problem</h2>

<p>I <a href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-1/">touched on this topic in the first post</a>, but one of the first
problems you encounter when putting your modules in version control is whether
or not to have ONE GIANT REPO with all of your modules, or a repository for
every module you create. In the past we recommended putting every module in
one repository (namely because it was easier, the module sharing landscape
was pretty barren, and teams were smaller). Now, we recommend the opposite
for the following reasons:</p>

<ul>
<li>Individual repos mean individual module development histories</li>
<li>Most VCS solutions don&rsquo;t have per-folder ACLs for a single repositories;
having multiple repos allows per-module security settings.</li>
<li>With the one-repository-per-module solution, modules you pull down from the
Forge (or Github) must be committed to your repo. Having multiple
repositories for each module allow you to keep everything separate</li>
<li>Publishing this module to the Forge (or Github/Stash/whatever) is easier
with separate repos (rather than having to split-out the module later).</li>
</ul>


<p>The problem with having a repository for every Puppet module you create is that
you need a way to map every module with every Puppet master (and, also which
version of every module should be installed in which Puppet environment).</p>

<p><a href="https://github.com/rodjek/librarian-puppet">A project called librarian-puppet</a> sprang up that created the
&lsquo;<code>Puppetfile</code>&rsquo;, a file that would map modules and their versions to a
specific directory. Librarian was awesome,
<a href="http://somethingsinistral.net/blog/scaling-puppet-environment-deployment/">but, as Finch noted in his post</a>, it had some shortcomings
when used in an environment with many and fast-changing modules.
<a href="http://somethingsinistral.net/blog/scaling-puppet-environment-deployment/">His solution, that he documented here,</a>, was the tool we now come
to know as R10k.</p>

<h2>Enter R10k</h2>

<p>R10k is essentially a Ruby project that wraps a bunch of shell commands you
would NORMALLY use to maintain an environment of ever-changing Puppet modules.
Its power is in its ability to use Git branches combined with a <code>Puppetfile</code>
to keep your Puppet environments in-sync. Because of this, R10k is CURRENTLY
restricted to git. There have been rumblings of porting it to Hg or svn, but
I know of no serious attempts at doing this (and if you ARE doing this, may
god have mercy on your soul). Great, so how does it work?</p>

<p>Well, you&rsquo;ll need one main repository SIMPLY for tracking the <code>Puppetfile</code>.
<a href="https://github.com/glarizza/puppet_repository">I&rsquo;ve got one right here,</a> and it only has my <code>Puppetfile</code> and a
<code>site.pp</code> file for classification (should you use it).</p>

<p><strong>NOTE</strong>: The Puppetfile and librarian-puppet-like capabilities under the hood
are going to be doing most of the work here &ndash; this repository is solely so you
can create topic branches with changes to your <code>Puppetfile</code> that will
eventually become dynamically-created Puppet environments.</p>

<p>Let&rsquo;s take a look at the <code>Puppetfile</code> and see what&rsquo;s going on:</p>

<p>{% codeblock lang:ruby Puppetfile %}
forge &ldquo;<a href="http://forge.puppetlabs.com">http://forge.puppetlabs.com</a>&rdquo;</p>

<h1>Modules from the Puppet Forge</h1>

<p>mod &ldquo;puppetlabs/stdlib&rdquo;
mod &ldquo;puppetlabs/apache&rdquo;, &ldquo;0.11.0&rdquo;
mod &ldquo;puppetlabs/pe_gem&rdquo;
mod &ldquo;puppetlabs/mysql&rdquo;
mod &ldquo;puppetlabs/firewall&rdquo;
mod &ldquo;puppetlabs/vcsrepo&rdquo;
mod &ldquo;puppetlabs/git&rdquo;
mod &ldquo;puppetlabs/inifile&rdquo;
mod &ldquo;zack/r10k&rdquo;
mod &ldquo;gentoo/portage&rdquo;
mod &ldquo;thias/vsftpd&rdquo;</p>

<h1>Modules from Github using various references</h1>

<p>mod &ldquo;wordpress&rdquo;,
  :git => &ldquo;git://github.com/hunner/puppet-wordpress.git&rdquo;,
  :ref => &lsquo;0.4.0&rsquo;</p>

<p>mod &ldquo;property_list_key&rdquo;,
  :git => &ldquo;git://github.com/glarizza/puppet-property_list_key.git&rdquo;,
  :ref => &lsquo;952a65d9ea2c5809f4e18f30537925ee45548abc&rsquo;</p>

<p>mod &lsquo;redis&rsquo;,
  :git => &lsquo;git://github.com/glarizza/puppet-redis&rsquo;,
  :ref => &lsquo;feature/debian_support&rsquo;
{% endcodeblock %}</p>

<p>This example lists the syntax for dealing with modules from both the
Forge and Github, as well as pulling specific versions of modules (whether
versions in the case of the Forge, or Github references as tags, branches,
or even specific commits). The syntax is not hard to follow &ndash; just remember
that we&rsquo;re mapping modules and their versions to a set/known environment.</p>

<p>For every topic branch on this repository (containing the <code>Puppetfile</code>), R10k
will in turn create a Puppet environment with the same name. For this reason,
it&rsquo;s convention to rename the &lsquo;master&rsquo; branch to &lsquo;production&rsquo; since that&rsquo;s the
default environment in Puppet (note that renaming branches locally is easy &ndash;
renaming the branch on Github can sometimes be a pain in the ass). You will
also note why it&rsquo;s going to be somewhat hard to map R10k to subversion, for
example, due to the lack of lightweight branching schemes.</p>

<p>To explain any more of R10k reads just as if I were describing its installation,
so let&rsquo;s quit screwing around and actually INSTALL/SETUP the damn thing.</p>

<h2>Setting up R10k</h2>

<p>As I mentioned before, we <a href="https://github.com/glarizza/puppet_repository">have the main repository</a> that will be
used to track the <code>Puppetfile</code>, which in turn will track the modules to
be installed (whether from The Forge, Github, or some internal git repo). Like
any good Puppet component, R10k itself can be setup with a Puppet module.
<a href="http://forge.puppetlabs.com/zack/r10k">The module I&rsquo;ll be using</a> was developed by <a href="https://github.com/acidprime">Zack Smith</a>,
and is pretty simple to get started. Let&rsquo;s download it from the forge first:</p>

<p><code>
[root@master1 vagrant]# puppet module install zack/r10k
Notice: Preparing to install into /etc/puppetlabs/puppet/modules ...
Notice: Downloading from https://forge.puppetlabs.com ...
Notice: Installing -- do not interrupt ...
/etc/puppetlabs/puppet/modules
 zack-r10k (v1.0.2)
   gentoo-portage (v2.1.0)
    puppetlabs-concat (v1.0.1)
   mhuffnagle-make (v0.0.2)
   puppetlabs-gcc (v0.1.0)
   puppetlabs-git (v0.0.3)
   puppetlabs-inifile (v1.0.1)
   puppetlabs-pe_gem (v0.0.1)
   puppetlabs-ruby (v0.1.0)
   puppetlabs-vcsrepo (v0.2.0)
</code></p>

<p>The module will be installed into the first path in your modulepath, which in
the case above is <code>/etc/puppetlabs/puppet/modules</code>. This modulepath will change
due to the way we&rsquo;re going to setup our dynamic Puppet environments. For this
example, I&rsquo;m going to have environments dynamically generated at
<code>/etc/puppetlabs/puppet/environments</code>, so let&rsquo;s create that directory first:</p>

<p><code>
[root@master1 vagrant]# mkdir -p /etc/puppetlabs/puppet/environments
</code></p>

<p>Now, we need to setup R10k on this machine. The module we downloaded will
allow us to do that, but we&rsquo;ll need to create a small Puppet manifest that
will allow us to setup R10k out-of-band from a regular Puppet run (you CAN
continuously-enforce R10k configuration in-band with your regular Puppet
run, but if we&rsquo;re setting up a Puppet master to use R10k to serve out dynamic
environments it&rsquo;s possible to create a chicken-and-egg situation.). Let&rsquo;s
generate a file called <code>r10k_installation.pp</code> in <code>/var/tmp</code> and have it look
like the following:</p>

<p>{% codeblock lang:puppet /var/tmp/r10k_installation.pp %}
class { &lsquo;r10k&rsquo;:
  version           => &lsquo;1.1.3&rsquo;,
  sources           => {</p>

<pre><code>'puppet' =&gt; {
  'remote'  =&gt; 'https://github.com/glarizza/puppet_repository.git',
  'basedir' =&gt; "${::settings::confdir}/environments",
  'prefix'  =&gt; false,
}
</code></pre>

<p>  },
  purgedirs         => [&ldquo;${::settings::confdir}/environments&rdquo;],
  manage_modulepath => true,
  modulepath        => &ldquo;${::settings::confdir}/environments/\$environment/modules:/opt/puppet/share/puppet/modules&rdquo;,
}
{% endcodeblock %}</p>

<p>So what is every section of that declaration doing?</p>

<ul>
<li><strong><code>version =&gt; '1.1.3'</code></strong> sets the version of the R10k gem to install</li>
<li><strong><code>sources =&gt; {...}</code></strong> is a hash of sources that R10k is going to track. For
now it&rsquo;s only our <a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a>, but you can also track a Hiera
installation too. This hash accepts key/value pairs for configuration settings
that are going to be written to <code>/etc/r10k.yaml</code>, which is R10k&rsquo;s main
configuration file. The keys in-use are <code>remote</code>, which is the path to the
repository to-be-checked-out by R10k, <code>basedir</code>, which is the path on-disk
to where dynamic environments are to be created (we&rsquo;re using the
<code>$::settings::confdir</code> variable which maps to the Puppet master&rsquo;s configuration
directory, or <code>/etc/puppetlabs/puppet</code>), and <code>prefix</code> which is a boolean
to determine whether to use R10k&rsquo;s source-prefixing feature. <strong>NOTE: the <code>false</code>
value is a BOOLEAN value, and thus SHOULD NOT BE QUOTED. Quoting it turns it
into a string, which matches as a boolean TRUE value. Don&rsquo;t quote <code>false</code> &ndash;
that&rsquo;s bad, mmkay.</strong></li>
<li><strong><code>purgedirs=&gt; ["${::settings::confdir}/environments"]</code></strong> is configuring R10k
to implement purging on the environments directory (so any folders that R10k
doesn&rsquo;t create it will delete). This configuration MAY be moot with newer
versions of R10k as I believe it implements this behavior by default.</li>
<li><strong><code>manage_modulepath =&gt; true</code></strong> will ensure that this module sets the <code>modulepath</code>
configuration item in <code>/etc/puppetlabs/puppet/puppet.conf</code></li>
<li><strong><code>modulepath =&gt; ...</code></strong> sets the <code>modulepath</code> value to be dropped into
<code>/etc/puppetlabs/puppet/puppet.conf</code>. Note that we are interpolating variables
(<code>$::settings::confdir</code> again), AND inserting the LITERAL string of <code>$environment</code>
into the <code>modulepath</code> &ndash; this is because Puppet will replace <code>$environment</code> with
the value of the agent&rsquo;s environment at catalog compilation.</li>
</ul>


<p><strong>JUST IN CASE YOU MISSED IT: Don&rsquo;t quote the <code>false</code> value for the prefix setting
in the <code>sources</code> block. That is all.</strong></p>

<p>Okay, we have our one-time Puppet manifest, and now the only thing left to do
is to run it:</p>

<p><code>
[root@master1 tmp]# puppet apply /var/tmp/r10k_installation.pp
Notice: Compiled catalog for master1 in environment production in 2.05 seconds
Notice: /Stage[main]/R10k::Config/File[r10k.yaml]/ensure: defined content as '{md5}0b619d5148ea493e2d6a5bb205727f0c'
Notice: /Stage[main]/R10k::Config/Ini_setting[R10k Modulepath]/value: value changed '/etc/puppetlabs/puppet/modules:/opt/puppet/share/puppet/modules' to '/etc/puppetlabs/puppet/environments/$environment/modules:/opt/puppet/share/puppet/modules'
Notice: /Package[r10k]/ensure: created
Notice: /Stage[main]/R10k::Install::Pe_gem/File[/usr/bin/r10k]/ensure: created
Notice: Finished catalog run in 10.55 seconds
</code></p>

<p>At this point, it goes without saying that <code>git</code> needs to be installed, but
if you&rsquo;re firing up a new VM that DOESN&rsquo;T have <code>git</code>, then R10k is going to
spit out an awesome error &ndash; so ensure that <code>git</code> is installed.  After that,
let&rsquo;s synchronize R10k with the <code>r10k deploy environment -pv</code> command (<code>-p</code>
for <code>Puppetfile</code> synchronization and <code>-v</code> for verbose mode):</p>

<p><code>
[root@master1 puppet]# r10k deploy environment -pv
[R10K::Task::Deployment::DeployEnvironments - INFO] Loading environments from all sources
[R10K::Task::Environment::Deploy - NOTICE] Deploying environment production
[R10K::Task::Puppetfile::Sync - INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync - INFO] Deploying redis into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying make into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying concat into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying portage into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying git into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying ruby into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying apache into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying redis into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying make into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying concat into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying portage into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying git into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying ruby into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying apache into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync - INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Environment::Deploy - NOTICE] Deploying environment master
[R10K::Task::Puppetfile::Sync - INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync - INFO] Deploying redis into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying portage into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying git into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying apache into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying redis into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying portage into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying git into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying vcsrepo into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying apache into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Module::Sync - INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/master/modules
[R10K::Task::Environment::Deploy - NOTICE] Deploying environment development
[R10K::Task::Puppetfile::Sync - INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync - INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying apache into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying r10k into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying property_list_key into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying wordpress into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying inifile into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying vsftpd into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying firewall into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying pe_gem into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying apache into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Module::Sync - INFO] Deploying stdlib into /etc/puppetlabs/puppet/environments/development/modules
[R10K::Task::Deployment::PurgeEnvironments - INFO] Purging stale environments from /etc/puppetlabs/puppet/environments
</code></p>

<p>I ran this first synchronization with verbose mode so you can see exactly what&rsquo;s
getting copied where. Futher synchronizations don&rsquo;t have to be in verbose mode,
but it&rsquo;s good for debugging. After all of that, we have an
<code>/etc/puppetlabs/puppet/environments</code> folder containing our dynamic Puppet
environments based off of the branches of the <a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a>:</p>

<p>```
[root@master1 puppet]# ls -lah /etc/puppetlabs/puppet/environments/
total 20K
drwxr-xr-x 5 root root 4.0K Feb 19 11:44 .
drwxr-xr-x 7 root root 4.0K Feb 19 11:25 ..
drwxr-xr-x 4 root root 4.0K Feb 19 11:44 development
drwxr-xr-x 5 root root 4.0K Feb 19 11:43 master
drwxr-xr-x 5 root root 4.0K Feb 19 11:42 production</p>

<p>[root@master1 puppet]# cd /etc/puppetlabs/puppet/environments/production/
[root@master1 production]# git branch -a
  master
* production
  remotes/origin/HEAD &ndash;> origin/master
  remotes/origin/development
  remotes/origin/master
  remotes/origin/production
```</p>

<p>As you can see (at the time of this writing), my <a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a>
has three main branches: <code>development</code>, <code>master</code>, and <code>production</code>, and so
R10k created three Puppet environments matching those names. It&rsquo;s somewhat
of a convention to rename the master branch to <code>production</code>, but in this
case I left it alone to demonstrate how this works.</p>

<p><strong>ONE OTHER BIG GOTCHA</strong>: R10k does NOT resolve dependencies, and
so it is UP TO YOU to track them in your Puppetfile.  Check this out:</p>

<p><code>
[root@master1 production]# puppet module list
Warning: Module 'puppetlabs-firewall' (v1.0.0) fails to meet some dependencies:
  'puppetlabs-puppet_enterprise' (v3.1.0) requires 'puppetlabs-firewall' (v0.3.x)
Warning: Module 'puppetlabs-stdlib' (v4.1.0) fails to meet some dependencies:
  'puppetlabs-pe_accounts' (v2.0.1) requires 'puppetlabs-stdlib' (v3.2.x)
  'puppetlabs-pe_mcollective' (v0.1.14) requires 'puppetlabs-stdlib' (v3.2.x)
  'puppetlabs-puppet_enterprise' (v3.1.0) requires 'puppetlabs-stdlib' (v3.2.x)
  'puppetlabs-request_manager' (v0.0.10) requires 'puppetlabs-stdlib' (v3.2.x)
Warning: Missing dependency 'cprice404-inifile':
  'puppetlabs-pe_puppetdb' (v0.0.11) requires 'cprice404-inifile' (&gt;=0.9.0)
  'puppetlabs-puppet_enterprise' (v3.1.0) requires 'cprice404-inifile' (v0.10.x)
  'puppetlabs-puppetdb' (v1.5.1) requires 'cprice404-inifile' (&gt;= 0.10.3)
Warning: Missing dependency 'puppetlabs-concat':
  'puppetlabs-apache' (v0.11.0) requires 'puppetlabs-concat' (&gt;= 1.0.0)
  'gentoo-portage' (v2.1.0) requires 'puppetlabs-concat' (v1.0.x)
Warning: Missing dependency 'puppetlabs-gcc':
  'zack-r10k' (v1.0.2) requires 'puppetlabs-gcc' (&gt;= 0.0.3)
/etc/puppetlabs/puppet/environments/production/modules
 gentoo-portage (v2.1.0)
 mhuffnagle-make (v0.0.2)
 property_list_key (???)
 puppetlabs-apache (v0.11.0)
 puppetlabs-firewall (v1.0.0)  invalid
 puppetlabs-git (v0.0.3)
 puppetlabs-inifile (v1.0.1)
 puppetlabs-mysql (v2.2.1)
 puppetlabs-pe_gem (v0.0.1)
 puppetlabs-ruby (v0.1.0)
 puppetlabs-stdlib (v4.1.0)  invalid
 puppetlabs-vcsrepo (v0.2.0)
 redis (???)
 ripienaar-concat (v0.2.0)
 thias-vsftpd (v0.2.0)
 wordpress (???)
 zack-r10k (v1.0.2)
/opt/puppet/share/puppet/modules
 cprice404-inifile (v0.10.3)
 puppetlabs-apt (v1.1.0)
 puppetlabs-auth_conf (v0.1.7)
 puppetlabs-firewall (v0.3.0)  invalid
 puppetlabs-java_ks (v1.1.0)
 puppetlabs-pe_accounts (v2.0.1)
 puppetlabs-pe_common (v0.1.0)
 puppetlabs-pe_mcollective (v0.1.14)
 puppetlabs-pe_postgresql (v0.0.5)
 puppetlabs-pe_puppetdb (v0.0.11)
 puppetlabs-postgresql (v2.5.0)
 puppetlabs-puppet_enterprise (v3.1.0)
 puppetlabs-puppetdb (v1.5.1)
 puppetlabs-reboot (v0.1.2)
 puppetlabs-request_manager (v0.0.10)
 puppetlabs-stdlib (v3.2.0)  invalid
 ripienaar-concat (v0.2.0)
</code></p>

<p>I&rsquo;ve installed Puppet Enterprise 3.1.0, and so <code>/opt/puppet/share/puppet/modules</code>
reflects the state of the Puppet Enterprise (also known as &lsquo;PE&rsquo;) modules at that
time. You can see that there are some conflicts because certain modules require
certain versions of other modules. This is currently the nature of the beast
with regard to Puppet modules. Some of these errors are loud and incidental
(i.e. someone set a dependency on a version and forgot to update it), some
are due to namespace changes (i.e. <code>cfprice-inifile</code> being ported over to
<code>puppetlabs-inifile</code>), and so on. Basically, ensure that you handle the
dependencies you care about inside the <code>Puppetfile</code> as R10k won&rsquo;t do it for you.</p>

<p>There &ndash; we&rsquo;ve done it!  We&rsquo;ve configured R10k!  Now how the hell do you use it?</p>

<h2>R10k demonstration &ndash; from module iteration to environment iteration</h2>

<p>Let&rsquo;s take the environment we&rsquo;ve setup in the previous steps and walk you
through adding a new module to your production environment, iterating upon
that module, pushing the changes to that module, pushing the changes to a
Puppet environment, and then promoting those changes to production.</p>

<p><strong>NOTES ON THE SETUP OF THIS DEMO:</strong></p>

<ul>
<li>In this demonstration, classification method is going to be left to the user
(i.e. it&rsquo;s not a part of the magic).  So, when I tell you to classify your
node with a specific class, I don&rsquo;t care if you use the Puppet Enterprise
Console, <code>site.pp</code>, or any other manner.</li>
<li>I&rsquo;m using Github for my repositories so that you folk watching and playing
along at home can have something to follow. Feel free to substitute Github
for something like Atlassian Stash/Bitbucket, internal repos, or whatever.</li>
</ul>


<h3>Add the module to an environment</h3>

<p>The module we&rsquo;ll be working with, <a href="https://github.com/glarizza/puppet-notifyme">a simple module called &lsquo;notifyme&rsquo;</a>,
will notify a message that will help us track the module&rsquo;s process through all
phases of iteration.</p>

<p>The first thing we need to do is to add the module to an environment, so let&rsquo;s
dynamically create a NEW environment by creating a new topic branch and pushing
it up to <a href="https://github.com/glarizza/puppet_repository">the main puppet repo</a>. I will perform this step on my laptop
and outside of the VM I&rsquo;m using to test R10k:</p>

<p>```
(~/src/puppet_repository) git branch
  master
* production</p>

<p>(~/src/puppet_repository) git checkout -b notifyme
Switched to a new branch &lsquo;notifyme&rsquo;</p>

<p>(~/src/puppet_repository) vim Puppetfile</p>

<h1>Perform the changes to Puppetfile here</h1>

<p>(~/src/puppet_repository) git add Puppetfile
(~/src/puppet_repository) git commit
[notifyme 5239538] Add the &lsquo;notifyme&rsquo; module
 1 file changed, 3 insertions(+)</p>

<p>(~/src/puppet_repository) git push origin notifyme:notifyme
Counting objects: 5, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 348 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet_repository.git">https://github.com/glarizza/puppet_repository.git</a>
 * [new branch]      notifyme &ndash;> notifyme
```</p>

<p>The contents I added to my <code>Puppetfile</code> look like this:</p>

<p>{% codeblock lang:ruby Puppetfile %}
mod &ldquo;notifyme&rdquo;,
  :git => &ldquo;git://github.com/glarizza/puppet-notifyme.git&rdquo;
{% endcodeblock %}</p>

<h3>Perform an R10k synchronization</h3>

<p>To pull the new dynamic environment down to the Puppet master, do another
R10k synchronization with <code>r10k deploy environment -pv</code>:</p>

<p><code>
[root@master1 production]# r10k deploy environment -pv
[R10K::Task::Deployment::DeployEnvironments - INFO] Loading environments from all sources
[R10K::Task::Environment::Deploy - NOTICE] Deploying environment production
&lt;snip for brevity&gt;
[R10K::Task::Environment::Deploy - NOTICE] Deploying environment notifyme
[R10K::Task::Puppetfile::Sync - INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync - INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/notifyme/modules
&lt;more snipping&gt;
</code></p>

<p>I only included the relevant messages, but you can see that it pulled in a new
environment called &lsquo;notifyme&rsquo; that ALSO pulled in a module called &lsquo;notifyme&rsquo;</p>

<h3>Rename the branch to avoid confusion</h3>

<p>Suddenly I realize that this may get confusing having both an environment called
&lsquo;notifyme&rsquo; with a module/class called &lsquo;notifyme&rsquo;. No worries, how about we rename
that branch?</p>

<p>```
(~/src/puppet_repository) git branch -m notifyme garysawesomeenvironment</p>

<p>(~/src/puppet_repository) git push origin :notifyme
To <a href="https://github.com/glarizza/puppet_repository.git">https://github.com/glarizza/puppet_repository.git</a>
 &ndash; [deleted]         notifyme</p>

<p>(~/src/puppet_repository) git push origin garysawesomeenvironment:garysawesomeenvironment
Counting objects: 5, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 348 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet_repository.git">https://github.com/glarizza/puppet_repository.git</a>
 * [new branch]      garysawesomeenvironment &ndash;> garysawesomeenvironment
```</p>

<p>That bit of <code>git</code> renamed the &lsquo;notifyme&rsquo; branch to &lsquo;garysawesomeenvironment&rsquo;.
The next git command is a bit tricky &ndash; when you <code>git push</code> to a remote, it&rsquo;s
supposed to be:</p>

<p><strong><code>git push name_of_origin local_branch_name:remote_branch_name</code></strong></p>

<p>In our case, the name of our origin is LITERALLY &lsquo;origin&rsquo;, but we actually want
to DELETE a remote branch. The way to delete a local branch is with
<code>git branch -d branch_name</code>, but the way to delete a REMOTE branch is to push
<strong>NOTHING</strong> to it.  So consider the following command:</p>

<p><strong><code>git push origin :notifyme</code></strong></p>

<p>We&rsquo;re pushing to the origin named &lsquo;origin&rsquo;, but providing NO local branch name
and pushing that bit of nothing to the remote branch of &lsquo;notifyme&rsquo;. This
kills (deletes) the remote branch.</p>

<p>Finally, we push to our origin named &lsquo;origin&rsquo; again and push the contents of
the local branch &lsquo;garysawesomeenvironment&rsquo; to the remote branch of
&lsquo;garysawesomeenvironment&rsquo; which in turn CREATES that branch if it doesn&rsquo;t exist.
Whew.  Let&rsquo;s run another damn synchronization:</p>

<p><code>
[root@master1 production]# `r10k deploy environment -pv`
[R10K::Task::Deployment::DeployEnvironments - INFO] Loading environments from all sources
&lt;more snippage&gt;
[R10K::Task::Environment::Deploy - NOTICE] Deploying environment garysawesomeenvironment
[R10K::Task::Puppetfile::Sync - INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync - INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/garysawesomeenvironment/modules
&lt;more of that snipping shit&gt;
R10K::Task::Deployment::PurgeEnvironments - INFO] Purging stale environments from /etc/puppetlabs/puppet/environments
</code></p>

<p>Cool, let&rsquo;s check out our <code>environments</code> folder on our VM:</p>

<p>```
[root@master1 production]# ls -lah /etc/puppetlabs/puppet/environments/
total 24K
drwxr-xr-x 6 root root 4.0K Feb 19 13:34 .
drwxr-xr-x 7 root root 4.0K Feb 19 12:09 ..
drwxr-xr-x 4 root root 4.0K Feb 19 11:44 development
drwxr-xr-x 5 root root 4.0K Feb 19 13:33 garysawesomeenvironment
drwxr-xr-x 5 root root 4.0K Feb 19 11:43 master
drwxr-xr-x 5 root root 4.0K Feb 19 11:42 production</p>

<p>[root@master1 production]# cd /etc/puppetlabs/puppet/environments/garysawesomeenvironment/</p>

<p>[root@master1 garysawesomeenvironment]# git branch
* garysawesomeenvironment
  master
```</p>

<h3>Run Puppet to test the new environment</h3>

<p>Perfect!  Now classify your node to include the &lsquo;notifyme&rsquo; class, and let&rsquo;s run
Puppet to see what we get when we try to join the environment called
&lsquo;garysawesomeenvronment&rsquo;:</p>

<p><code>
[root@master1 garysawesomeenvironment]# puppet agent -t --environment garysawesomeenvironment
Info: Retrieving plugin
&lt;snipping facts loading for brevity&gt;
Info: Caching catalog for master1
Info: Applying configuration version '1392845863'
Notice: This is the notifyme module and its master branch
Notice: /Stage[main]/Notifyme/Notify[This is the notifyme module and its master branch]/message: defined 'message' as 'This is the notifyme module and its master branch'
Notice: Finished catalog run in 11.10 seconds
</code></p>

<p>Cool!  Now let&rsquo;s try to run Puppet with another environment, say &lsquo;production&rsquo;:</p>

<p><code>
[root@master1 garysawesomeenvironment]# puppet agent -t --environment production
Info: Retrieving plugin
&lt;snipping facts loading for brevity&gt;
Error: Could not retrieve catalog from remote server: Error 400 on SERVER: Could not find class notifyme for master1 on node master1
Warning: Not using cache on failed catalog
Error: Could not retrieve catalog; skipping run
</code></p>

<p>We get an error because that module hasn&rsquo;t been loaded by R10k for that
environment.</p>

<h3>Tie a module version to an environment</h3>

<p>Okay, so we added a module to a new environment, but what if we want to test
out a specific commit, branch, or tag of a module and test it in this new
environment? This is frequently what you&rsquo;ll be doing &ndash; making a change to
an existing module, pushing your change to a topic branch of that module&rsquo;s
repository, tying it to an environment (or creating a new environment by
branching the main Puppet repository), and then testing the change.</p>

<p>Let&rsquo;s go back to my &lsquo;notifyme&rsquo; module that I&rsquo;ve cloned to my laptop and push
a change to a BRANCH of that module&rsquo;s Github repository:</p>

<p>```
(~/src/puppet-notifyme) git branch
* master</p>

<p>(~/src/puppet-notifyme) git checkout -b change_the_message
Switched to a new branch &lsquo;change_the_message&rsquo;</p>

<p>(~/src/puppet-notifyme) vim manifests/init.pp</p>

<h2>Make changes to the notify message</h2>

<p>(~/src/puppet-notifyme) git add manifests/init.pp</p>

<p>(~/src/puppet-notifyme) git commit
[change_the_message bc3975b] Change the Message
 1 file changed, 1 insertion(+), 1 deletion(&ndash;)</p>

<p>(~/src/puppet-notifyme) git push origin change_the_message:change_the_message
Counting objects: 7, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (4/4), 448 bytes, done.
Total 4 (delta 0), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet-notifyme.git">https://github.com/glarizza/puppet-notifyme.git</a>
 * [new branch]      change_the_message &ndash;> change_the_message</p>

<p>(~/src/puppet-notifyme) git branch -a
* change_the_message
  master
  remotes/origin/change_the_message
  remotes/origin/master</p>

<p>(~/src/puppet-notifyme) git log
commit bc3975bb5c75ada86bfc2c45db628b5a156f85ce
Author: Gary Larizza <a href="&#x6d;&#x61;&#105;&#x6c;&#116;&#x6f;&#58;&#x67;&#x61;&#x72;&#121;&#64;&#x70;&#x75;&#112;&#x70;&#101;&#116;&#108;&#97;&#x62;&#x73;&#x2e;&#99;&#x6f;&#109;">&#x67;&#x61;&#114;&#x79;&#x40;&#x70;&#117;&#x70;&#112;&#101;&#116;&#108;&#97;&#x62;&#x73;&#46;&#x63;&#111;&#x6d;</a>
Date:   Wed Feb 19 13:55:26 2014 -0800</p>

<pre><code>Change the Message

This commit changes the message to test my workflow.
</code></pre>

<p>```</p>

<p>What I&rsquo;m showing you is the workflow that creates a new local branch called
&lsquo;change_the_message&rsquo; to the notifyme module, changes the message in my notify
resource, commits the change, and pushes the changes to a remote branch ALSO
called &lsquo;change_the_message&rsquo;.</p>

<p>Because I created a topic branch, I can provide that branch name in the
<code>Puppetfile</code> located in the &lsquo;garysawesomeenvironment&rsquo; branch of the
<a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a>. THAT is the piece that ties together the specific
version of the module with the Puppet environment we want on the Puppet master.
Here&rsquo;s that change:</p>

<p>{% codeblock lang:ruby Puppetfile %}
mod &ldquo;notifyme&rdquo;,
  :git => &ldquo;git://github.com/glarizza/puppet-notifyme.git&rdquo;,
  :ref => &lsquo;change_the_message&rsquo;
{% endcodeblock %}</p>

<p>Again, that change gets put into the &lsquo;garysawesomeenvironment&rsquo; branch of the
<a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a> and pushed up to the remote:</p>

<p>```
(~/src/puppet_repository) vim Puppetfile</p>

<h2>Make changes</h2>

<p>(~/src/puppet_repository) git add Puppetfile</p>

<p>(~/src/puppet_repository) git commit
[garysawesomeenvironment 89b139c] Update garysawesomeenvironment
 1 file changed, 2 insertions(+), 1 deletion(&ndash;)</p>

<p>(~/src/puppet_repository) git push origin garysawesomeenvironment:garysawesomeenvironment
Counting objects: 5, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 411 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet_repository.git">https://github.com/glarizza/puppet_repository.git</a>
   5239538..89b139c  garysawesomeenvironment &ndash;> garysawesomeenvironment</p>

<p>(~/src/puppet_repository) git log -p
commit 89b139c8c2faa888a402b98ea76e4ca138b3463d
Author: Gary Larizza <a href="&#109;&#x61;&#105;&#108;&#116;&#111;&#58;&#x67;&#97;&#114;&#121;&#64;&#x70;&#x75;&#112;&#112;&#101;&#x74;&#x6c;&#x61;&#x62;&#x73;&#46;&#x63;&#x6f;&#x6d;">&#x67;&#x61;&#x72;&#x79;&#x40;&#x70;&#x75;&#x70;&#x70;&#x65;&#x74;&#x6c;&#97;&#x62;&#x73;&#46;&#99;&#111;&#x6d;</a>
Date:   Wed Feb 19 14:04:18 2014 -0800</p>

<pre><code>Update garysawesomeenvironment

Tie this environment to the 'change_the_message' branch of my notifyme module.
</code></pre>

<p>diff &mdash;git a/Puppetfile b/Puppetfile
index 5e5d091..27fc06e 100644
&mdash;&ndash; a/Puppetfile
+++ b/Puppetfile
@@ -31,4 +31,5 @@ mod &lsquo;redis&rsquo;,
   :ref => &lsquo;feature/debian_support&rsquo;</p>

<p> mod &ldquo;notifyme&rdquo;,
&ndash;  :git => &ldquo;git://github.com/glarizza/puppet-notifyme.git&rdquo;
+  :git => &ldquo;git://github.com/glarizza/puppet-notifyme.git&rdquo;,
+  :ref => &lsquo;change_the_message&rsquo;
```</p>

<p>Now let&rsquo;s synchronize again!!</p>

<p><code>
[root@master1 garysawesomeenvironment]# `r10k deploy environment -pv`
[R10K::Task::Deployment::DeployEnvironments - INFO] Loading environments from all sources
&lt;snip&gt;
[R10K::Task::Environment::Deploy - NOTICE] Deploying environment garysawesomeenvironment
[R10K::Task::Puppetfile::Sync - INFO] Loading modules from Puppetfile into queue
&lt;snip&gt;
</code></p>

<p>Cool, let&rsquo;s check our work on the VM:</p>

<p><code>
[root@master1 garysawesomeenvironment]# pwd
/etc/puppetlabs/puppet/environments/garysawesomeenvironment
[root@master1 garysawesomeenvironment]# git branch
* garysawesomeenvironment
  master
</code></p>

<p>And finally, let&rsquo;s run Puppet:</p>

<p><code>
root@master1 garysawesomeenvironment]# puppet agent -t --environment garysawesomeenvironment
Info: Retrieving plugin
&lt;snip fact loading&gt;
Info: Caching catalog for master1
Info: Applying configuration version '1392847743'
Notice: This is the changed message in the change_the_message branch
Notice: /Stage[main]/Notifyme/Notify[This is the changed message in the change_the_message branch]/message: defined 'message' as 'This is the changed message in the change_the_message branch'
Notice: Finished catalog run in 12.10 seconds
</code></p>

<p>TADA! We&rsquo;ve successfully tied a specific version of a module to a specific
dynamic environment, deployed it to a master, and tested it out! Smell that?
That&rsquo;s the smell of awesome. Or Jeff in the next cubicle eating a burrito.
Either way, I like it.</p>

<h3>Merge your changes with master/production</h3>

<p>It&rsquo;s green &ndash; fuck it; ship it! NOW you&rsquo;re speaking &lsquo;agile&rsquo;! Assuming everything
went according to plan, let&rsquo;s merge our changes in with the production
environment and synchronize.  This is up to your company&rsquo;s workflow docs
(whether you use pull requests, a merge master, or poke Patrick and tell
him to tell Andy to merge in your change). I&rsquo;m using git and Github, so
let&rsquo;s merge.</p>

<p>First, do the Module:</p>

<p>```
(~/src/puppet-notifyme) git checkout master
Switched to branch &lsquo;master&rsquo;</p>

<p>(~/src/puppet-notifyme) git merge change_the_message
Updating d44a790..bc3975b
Fast-forward
 manifests/init.pp | 2 +&ndash;
 1 file changed, 1 insertion(+), 1 deletion(&ndash;)</p>

<p>(~/src/puppet-notifyme) git push origin master:master
Total 0 (delta 0), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet-notifyme.git">https://github.com/glarizza/puppet-notifyme.git</a>
   d44a790..bc3975b  master &ndash;> master</p>

<p>(~/src/puppet-notifyme) cat manifests/init.pp
class notifyme {
  notify { &ldquo;This is the changed message in the change_the_message branch&rdquo;: }
}
```</p>

<p>So now we have an issue, and that issue is that the production environment
has YET to have the &lsquo;notifyme&rsquo; module added to it.  If we merge the contents
of the &lsquo;garysawesomeenvironment&rsquo; branch with the &lsquo;production&rsquo; branch of the
<a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a>, then we&rsquo;re going to be pointing at the
&lsquo;change_the_message&rsquo; branch of the &lsquo;notifyme&rsquo; module (because that was our last
commit).</p>

<p>Because of this, I can&rsquo;t do a straight merge, can I? For posterity&rsquo;s sake (in
the event that someone in the future wants to look for that branch on my Github
repo), I&rsquo;m going to keep that branch alive. In a production environment, I
most likely would NOT have additional branches open for all my component modules
as that would get pretty annoying/confusing. Understand that this is a one-off
case because I&rsquo;m doing a demo. BECAUSE of this, I&rsquo;m going to modify the
<code>Puppetfile</code> in the &lsquo;production&rsquo; branch of the <a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a>:</p>

<p>```
(~/src/puppet_repository) git checkout production
Switched to branch &lsquo;production&rsquo;</p>

<p>(~/src/puppet_repository) vim Puppetfile</p>

<h2>Make changes here</h2>

<p>(~/src/puppet_repository) git add Puppetfile</p>

<p>(~/src/puppet_repository) git commit
[production a74f269] Add notifyme module to Production environment
 1 file changed, 4 insertions(+)</p>

<p>(~/src/puppet_repository) git push origin production:production
Counting objects: 5, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 362 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet_repository.git">https://github.com/glarizza/puppet_repository.git</a>
   5ecefc8..a74f269  production &ndash;> production</p>

<p>(~/src/puppet_repository) git log -p
commit a74f26975102f3786eedddace89bda086162d801
Author: Gary Larizza <a href="&#109;&#x61;&#x69;&#108;&#116;&#111;&#x3a;&#x67;&#97;&#x72;&#x79;&#64;&#112;&#117;&#x70;&#x70;&#x65;&#116;&#108;&#97;&#x62;&#x73;&#46;&#x63;&#x6f;&#x6d;">&#103;&#x61;&#x72;&#x79;&#64;&#112;&#117;&#x70;&#112;&#101;&#116;&#x6c;&#x61;&#98;&#115;&#46;&#99;&#111;&#x6d;</a>
Date:   Wed Feb 19 14:24:05 2014 -0800</p>

<pre><code>Add notifyme module to Production environment
</code></pre>

<p>diff &mdash;git a/Puppetfile b/Puppetfile
index 0b1da68..9168a81 100644
&mdash;&ndash; a/Puppetfile
+++ b/Puppetfile
@@ -29,3 +29,7 @@ mod &ldquo;property_list_key&rdquo;,
 mod &lsquo;redis&rsquo;,
   :git => &lsquo;git://github.com/glarizza/puppet-redis&rsquo;,
   :ref => &lsquo;feature/debian_support&rsquo;
+
+mod &lsquo;notifyme&rsquo;,
+  :git => &lsquo;git://github.com/glarizza/puppet-notifyme&rsquo;
+
```</p>

<p>Alright, we&rsquo;ve updated the production environment, now synchronize again
(I&rsquo;ll spare you and do it WITHOUT verbose mode):</p>

<p><code>
[root@master1 garysawesomeenvironment]# r10k deploy environment -p
</code></p>

<p>Okay, now run Puppet with the PRODUCTION environment:</p>

<p><code>
[root@master1 garysawesomeenvironment]# puppet agent -t --environment production
Info: Retrieving plugin
&lt;snipping fact loading&gt;
Info: Caching catalog for master1
Info: Applying configuration version '1392848588'
Notice: This is the changed message in the change_the_message branch
Notice: /Stage[main]/Notifyme/Notify[This is the changed message in the change_the_message branch]/message: defined 'message' as 'This is the changed message in the change_the_message branch'
Notice: Finished catalog run in 12.66 seconds
</code></p>

<p>Beautiful, we&rsquo;re synchronized!!!</p>

<h3>Making a change to an EXISTING module in an environment</h3>

<p>Okay, so we saw previously how to add a NEW module to an environment, but what
if we already HAVE a module in an environment and we want to make an update/change
to it?  Well, it&rsquo;s largely the same process:</p>

<ul>
<li>Cut a branch to the module</li>
<li>Commit your code and push it up to the module&rsquo;s repo</li>
<li>Cut a branch to the <a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a></li>
<li>Push that branch up to the <a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a></li>
<li>Perform an R10k synchronization to sync the environments</li>
<li>Test your changes</li>
<li>Merge the changes with the master branch of the module</li>
<li>DONE!</li>
</ul>


<p>Let&rsquo;s go back and change that notify message again, shall we?</p>

<p>```
(~/src/puppet-notifyme) git checkout -b &lsquo;another_change&rsquo;
Switched to a new branch &lsquo;another_change&rsquo;</p>

<p>(~/src/puppet-notifyme) vim manifests/init.pp</p>

<h2>Make changes to the message</h2>

<p>(~/src/puppet-notifyme) git add manifests/init.pp</p>

<p>(~/src/puppet-notifyme) git commit
[another_change 608166e] Change the message that already exists!
 1 file changed, 1 insertion(+), 1 deletion(&ndash;)</p>

<p>(~/src/puppet-notifyme) git push origin another_change:another_change
Counting objects: 7, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (4/4), 426 bytes, done.
Total 4 (delta 0), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet-notifyme.git">https://github.com/glarizza/puppet-notifyme.git</a>
 * [new branch]      another_change &ndash;> another_change
```</p>

<p>Okay, let&rsquo;s re-use &lsquo;garysawesomeenvironment&rsquo; because I like the name, but
tie it to the new &lsquo;another_change&rsquo; branch of the &lsquo;notifyme&rsquo; module:</p>

<p>```
(~/src/puppet_repository) git checkout garysawesomeenvironment
Switched to branch &lsquo;garysawesomeenvironment&rsquo;</p>

<p>(~/src/puppet_repository) vim Puppetfile</p>

<h2>Make change to Puppetfile to tie it to &lsquo;another_change&rsquo; branch</h2>

<p>(~/src/puppet_repository) git add Puppetfile</p>

<p>(~/src/puppet_repository) git commit
[garysawesomeenvironment ce84a30] Tie garysawesomeenvironment to &lsquo;another_change&rsquo;
 1 file changed, 1 insertion(+), 1 deletion(&ndash;)</p>

<p>(~/src/puppet_repository) git push origin garysawesomeenvironment:garysawesomeenvironment
Counting objects: 5, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 386 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet_repository.git">https://github.com/glarizza/puppet_repository.git</a>
   89b139c..ce84a30  garysawesomeenvironment &ndash;> garysawesomeenvironment
```</p>

<p>The <code>Puppetfile</code> for that branch now has an entry for the &lsquo;notifyme&rsquo; module
that looks like this:</p>

<p>{% codeblock lang:ruby Puppetfile %}
mod &ldquo;notifyme&rdquo;,
  :git => &ldquo;git://github.com/glarizza/puppet-notifyme.git&rdquo;,
  :ref => &lsquo;another_change&rsquo;
{% endcodeblock %}</p>

<p>Okay, synchronize again!</p>

<p><code>
[root@master1 garysawesomeenvironment]# r10k deploy environment -p
</code></p>

<p>And now run Puppet in the &lsquo;garysawesomeenvironment&rsquo; environment:</p>

<p><code>
[root@master1 garysawesomeenvironment]# puppet agent -t --environment garysawesomeenvironment
Info: Retrieving plugin
&lt;snip fact loading&gt;
Info: Caching catalog for master1
Info: Applying configuration version '1392849521'
Notice: This changes the message that already exists!!!!
Notice: /Stage[main]/Notifyme/Notify[This changes the message that already exists!!!!]/message: defined 'message' as 'This changes the message that already exists!!!!'
Notice: Finished catalog run in 12.54 seconds
</code></p>

<p>There&rsquo;s the message that I changed in the &lsquo;another_change&rsquo; branch of my &lsquo;notifyme&rsquo;
module!  What&rsquo;s it look like if I run in the &lsquo;production&rsquo; environment, though?</p>

<p>```</p>

<p>ot@master1 garysawesomeenvironment]# puppet agent -t &mdash;environment production
Info: Retrieving plugin
<snip fact loading>
Info: Caching catalog for master1
Info: Applying configuration version &lsquo;1392848588&rsquo;
Notice: This is the changed message in the change_the_message branch
Notice: /Stage[main]/Notifyme/Notify[This is the changed message in the change_the_message branch]/message: defined &lsquo;message&rsquo; as &lsquo;This is the changed message in the change_the_message branch&rsquo;
Notice: Finished catalog run in 14.11 seconds
```</p>

<p>There&rsquo;s the old message that&rsquo;s in the &lsquo;master&rsquo; branch of the &lsquo;notifyme&rsquo;
module (which is where the &lsquo;production&rsquo; branch <code>Puppetfile</code> is pointing).
To merge the changes into the production environment, we now only have to
do one thing: that&rsquo;s merge the changes in the &lsquo;another_change&rsquo; branch of
the &lsquo;notifyme&rsquo; module to the &lsquo;master&rsquo; branch &ndash; that&rsquo;s it!  Why? Because
the <code>Puppetfile</code> in the <code>production</code> branch of the <a href="https://github.com/glarizza/puppet_repository">main Puppet repo</a>
(and thus the production Puppet ENVIRONMENT) is already POINTING at the
master branch of the &lsquo;notifyme&rsquo; module.  Let&rsquo;s do the merge:</p>

<p>```
(~/src/puppet-notifyme) git checkout master
Switched to branch &lsquo;master&rsquo;</p>

<p>(~/src/puppet-notifyme) git merge another_change
Updating bc3975b..608166e
Fast-forward
 manifests/init.pp | 2 +&ndash;
 1 file changed, 1 insertion(+), 1 deletion(&ndash;)</p>

<p>(~/src/puppet-notifyme) git push origin master:master
Total 0 (delta 0), reused 0 (delta 0)
To <a href="https://github.com/glarizza/puppet-notifyme.git">https://github.com/glarizza/puppet-notifyme.git</a>
   bc3975b..608166e  master &ndash;> master
```</p>

<p>Another R10k synchronization is needed on the master:</p>

<p><code>
[root@master1 garysawesomeenvironment]# r10k deploy environment -p
</code></p>

<p>And now let&rsquo;s run Puppet in the production environment:</p>

<p><code>
[root@master1 garysawesomeenvironment]# puppet agent -t --environment production
Info: Retrieving plugin
&lt;snip fact loading&gt;
Info: Caching catalog for master1
Info: Applying configuration version '1392850004'
Notice: This changes the message that already exists!!!!
Notice: /Stage[main]/Notifyme/Notify[This changes the message that already exists!!!!]/message: defined 'message' as 'This changes the message that already exists!!!!'
Notice: Finished catalog run in 11.82 seconds
</code></p>

<p>There&rsquo;s the message that was previously in the &lsquo;another_change&rsquo; branch that&rsquo;s
been merged to the &lsquo;master&rsquo; branch (and thus is entered into the production
Puppet environment).</p>

<h3>OR, use tags</h3>

<p>One more note &ndash; for production environments that want a BIT more stability
(rather than hoping that someone follows the policy of pushing commits to
a BRANCH of a module rather than pushing directly to master &ndash; by accident or
otherwise &ndash; and allowing that commit to make DIRECTLY it into production), the
better way is to tie all modules to some sort of release version. For modules
released to the Puppet Forge, that&rsquo;s a version, for modules stored in git
repositories, that would be a tag. Tying all modules in your production
environment (and thus production <code>Puppetfile</code>) to specific tags in git
repositories IS a &ldquo;best practice&rdquo; to ensure that the code that&rsquo;s executed in
production has some sort of &lsquo;safe guard&rsquo;.</p>

<p>TL;DR: Example tied to &lsquo;master&rsquo; branch above was demo, and not necessarily
recommended for your production needs.</p>

<h2>Holy crap, that&rsquo;s a lot to take in&hellip;</h2>

<p>Yeah, tell me about it. And, believe it or not, I&rsquo;m STILL not done with
everything that I want to talk about regarding R10k &ndash; there&rsquo;s still more
info on:</p>

<ul>
<li>Using R10k with a monolithic modules repo</li>
<li>Incorporating Hiera data</li>
<li>Triggering R10k with MCollective</li>
<li>Tying R10k to CI workflow</li>
</ul>


<p>Those will come in a later post once I have time to decide how to tackle them.
Until then, this should give you more than enough information to get started
with R10k in your own environment.</p>

<p>If you have any questions/comments/corrections, PLEASE enter them in the
comments below and I&rsquo;ll be happy to respond when I&rsquo;m not flying from gig to
gig! :)  Cheers!</p>

<p><strong>EDIT</strong>: 2/19/2014 &ndash; correct librarian-puppet assumption thanks to Reid Vandewiele</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building a Functional Puppet Workflow Part 2: Roles and Profiles]]></title>
    <link href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-2/"/>
    <updated>2014-02-17T17:01:37-05:00</updated>
    <id>http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-2</id>
    <content type="html"><![CDATA[<p>In my <a href="http://www.garylarizza.com/blog/2014/02/17/puppet-workflow-part-1/">first post</a>, I talked about writing functional component
modules. Well, I didn&rsquo;t really do much detailing other than pointing out
key bits of information that tend to cause problems. In this post, I&rsquo;ll
describe the next layer to the functional Puppet module workflow.</p>

<p>People usually stop once they have a library of component modules (whether
hand-written, taken from Github, or pulled from <a href="http://forge.puppetlabs.com">The Forge</a>). The idea
is that you can classify all of your nodes in <code>site.pp</code>, the Puppet
Enterprise Console, The Foreman, or with some other ENC, so why not just
declare all your classes for every node when you need them?</p>

<p>Because that&rsquo;s a lot of extra work and opportunities for fuckups.</p>

<p>People recognized this, so in the EARLY days of Puppet they would create node
blocks in <code>site.pp</code> and use inheritance to inherit from those blocks. This was
the right IDEA, but probably not the best PLACE for it. Eventually, &lsquo;Profiles&rsquo;
were born.</p>

<p>The idea of &lsquo;Roles and Profiles&rsquo; originally came from a piece that
<a href="http://www.craigdunn.org/2012/05/239/">Craig Dunn wrote</a> while he worked for the BBC, and then
<a href="http://sysadvent.blogspot.com/2012/12/day-13-configuration-management-as-legos.html">Adrien Thebo also wrote a piece</a> that documents the same sort of pattern.
So why am I writing about it a THIRD time? Well, because I feel it&rsquo;s only a PIECE
of an overall puzzle. The introduction of Hiera and other awesome tools (like R10k,
which we will get to on the next post) still make Roles and Profiles VIABLE, but
they also extend upon them.</p>

<p>One final note before we move on &ndash; the terms &lsquo;Roles&rsquo; and &lsquo;Profiles&rsquo; are ENTIRELY
ARBITRARY. They&rsquo;re not magic reserve words in Puppet, and you can call them
whatever the hell you want. It&rsquo;s also been pointed out that Craig MIGHT have
misnamed them (a ROLE should be a model for an individual piece of tech, and a
PROFILE should probably be a group of roles), but, like all good Puppet Labs
employees &ndash; we suck at naming things.</p>

<h2>Profiles: technology-specific wrapper classes</h2>

<p>A profile is simply a wrapper class that groups Hiera lookups and class
declarations into one functional unit. For example, if you wanted Wordpress
installed on a machine, you&rsquo;d probably need to declare the apache class to
get Apache setup, declare an <code>apache::vhost</code> for the Wordpress directory,
setup a MySQL database with the appropriate classes, and so on. There are
a lot of components that go together when you setup a piece of technology,
it&rsquo;s not just a single class.</p>

<p>Because of this, a profile exists to give you a single class you can include
that will setup all the necessary bits for that piece of technology (be it
Wordpress, or Tomcat, or whatever).</p>

<p>Let&rsquo;s look at a simple profile for Wordpress:</p>

<p>{% codeblock lang:puppet profiles/manifests/wordpress.pp %}
class profiles::wordpress {</p>

<p>  ## Hiera lookups
  $site_name               = hiera(&lsquo;profiles::wordpress::site_name&rsquo;)
  $wordpress_user_password = hiera(&lsquo;profiles::wordpress::wordpress_user_password&rsquo;)
  $mysql_root_password     = hiera(&lsquo;profiles::wordpress::mysql_root_password&rsquo;)
  $wordpress_db_host       = hiera(&lsquo;profiles::wordpress::wordpress_db_host&rsquo;)
  $wordpress_db_name       = hiera(&lsquo;profiles::wordpress::wordpress_db_name&rsquo;)
  $wordpress_db_password   = hiera(&lsquo;profiles::wordpress::wordpress_db_password&rsquo;)
  $wordpress_user          = hiera(&lsquo;profiles::wordpress::wordpress_user&rsquo;)
  $wordpress_group         = hiera(&lsquo;profiles::wordpress::wordpress_group&rsquo;)
  $wordpress_docroot       = hiera(&lsquo;profiles::wordpress::wordpress_docroot&rsquo;)
  $wordpress_port          = hiera(&lsquo;profiles::wordpress::wordpress_port&rsquo;)</p>

<p>  ## Create user
  group { &lsquo;wordpress&rsquo;:</p>

<pre><code>ensure =&gt; present,
name   =&gt; $wordpress_group,
</code></pre>

<p>  }
  user { &lsquo;wordpress&rsquo;:</p>

<pre><code>ensure   =&gt; present,
gid      =&gt; $wordpress_group,
password =&gt; $wordpress_user_password,
name     =&gt; $wordpress_group,
home     =&gt; $wordpress_docroot,
</code></pre>

<p>  }</p>

<p>  ## Configure mysql
  class { &lsquo;mysql::server&rsquo;:</p>

<pre><code>root_password =&gt; $wordpress_root_password,
</code></pre>

<p>  }</p>

<p>  class { &lsquo;mysql::bindings&rsquo;:</p>

<pre><code>php_enable =&gt; true,
</code></pre>

<p>  }</p>

<p>  ## Configure apache
  include apache
  include apache::mod::php
  apache::vhost { $::fqdn:</p>

<pre><code>port    =&gt; $wordpress_port,
docroot =&gt; $wordpress_docroot,
</code></pre>

<p>  }</p>

<p>  ## Configure wordpress
  class { &lsquo;::wordpress&rsquo;:</p>

<pre><code>install_dir =&gt; $wordpress_docroot,
db_name     =&gt; $wordpress_db_name,
db_host     =&gt; $wordpress_db_host,
db_password =&gt; $wordpress_db_password,
</code></pre>

<p>  }
}
{% endcodeblock %}</p>

<h3>Name your profiles according to the technology they setup</h3>

<p>Profiles are technology-specific, so you&rsquo;ll have one to setup wordpress, and
tomcat, and jenkins, and&hellip;well, you get the picture. You can also namespace
your profiles so that you have <code>profiles::ssh::server</code> and
<code>profiles::ssh::client</code> if you want. You can even have
<code>profiles::jenkins::tomcat</code> and <code>profiles::jenkins::jboss</code> or however you need
to namespace according to the TECHNOLOGIES you use. You don&rsquo;t need to include
your environment in the profile name (a la <code>profiles::dev::tomcat</code>) as the bits
of data that make the dev environment different from production should come
from <strong>HIERA</strong>, and thus aren&rsquo;t going to be different on a per-profile basis.
You CAN setup profiles according to your business unit if multiple units use
Puppet and have different setups (a la <code>security::profiles::tomcat</code> versus
<code>ops::profiles::tomcat</code>), but the GOAL of Puppet is to have one main set of
modules that every group uses (and the Hiera data being different for every
group). That&rsquo;s the GOAL, but I&rsquo;m pragmatic enough to understand that not
everywhere is a shiny, happy &lsquo;DevOps Garden.&rsquo;</p>

<h3>Do all Hiera lookups in the profile</h3>

<p>You&rsquo;ll see that I declared variables and set their values with Hiera lookups.
The profile is the place for these lookups because the profile collects all
external data and declares all the classes you&rsquo;ll need. In reality, you&rsquo;ll
<strong>USUALLY</strong> only see profiles looking up parameters and declaring classes
(i.e. declaring users and groups like I did above will USUALLY be left to
component classes).</p>

<p>I do the Hiera lookups first to make it easy to debug from where those values
came. I don&rsquo;t rely on <a href="http://docs.puppetlabs.com/hiera/1/puppet.html#automatic-parameter-lookup">&lsquo;Automatic Parameter Lookup&rsquo;</a> in Puppet
3.x.x because it can be &lsquo;magic&rsquo; for people who aren&rsquo;t aware of it (for people
new to Puppet, it&rsquo;s much easier to see a function call and trace back what it
does rather than experience Puppet doing something unseen and wondering what
the hell happened).</p>

<p>Finally, you&rsquo;ll notice that my Hiera lookups have <strong>NO DEFAULT VALUES</strong> &ndash; this
is <strong>BY DESIGN!</strong>  For most people, their Hiera data is <strong>PROBABLY</strong> located in
a separate repository as their Puppet module data. Imagine making a change to
your profile to have it lookup a bit of data from Hiera, and then imagine you
FORGOT to put that data into Hiera. What happens if you provide a default value
to Hiera? The catalog compiles, that default value gets passed down to the
component module, and gets enforced on disk. If you have good tests, you MIGHT
see that the component you configured has a bit of data that&rsquo;s not correct, but
what if you don&rsquo;t have a great post-Puppet testing workflow? Puppet will
correctly set this default value, according to Puppet everything is green and
worked just fine, but now your component is setup incorrectly. That&rsquo;s one of
the WORST failures &ndash; the ones that you don&rsquo;t catch.  Now, imagine you DON&rsquo;T
provide a default value. In THIS case, Puppet will raise a compilation error
because a Hiera lookup didn&rsquo;t return a value. You&rsquo;ll catch your error before
anything gets pushed to Production and you can catch the screwup. This is
a MUCH better solution.</p>

<h3>Use parameterized class declarations and explicitly pass values you care about</h3>

<p>The parameterized class declaration syntax can be dangerous. The difference
between the <code>include</code> function and the parameterized class syntax is that
the <code>include</code> function is idempotent. You can do the following in a Puppet
manifest, and Puppet doesn&rsquo;t raise an error:</p>

<p><code>
include apache
include apache
include apache
</code></p>

<p>This is because the <code>include</code> function checks to see if the class is in the
catalog. If it ISN&rsquo;T, then it adds it. If it IS, then it exits cleanly. The
<code>include</code> function is your pal.</p>

<p>Consider THIS manifest:</p>

<p><code>
class { 'apache': }
include apache
include apache
</code></p>

<p>Does this work?  Yep.  The parameterized class syntax adds the class to the
catalog, the include function detects this and exits cleanly twice.  What
about THIS manifest:</p>

<p><code>
include apache
class { 'apache': }
include apache
</code></p>

<p>Does THIS work?  Nope!  Puppet raises a compilation error because a class was
declared more than once in a catalog.  Why?  Well, consider that Puppet is
&lsquo;declarative&rsquo;&hellip;all the way up until it isn&rsquo;t.  Puppet&rsquo;s PARSER reads from the
top of the file to the bottom of the file, and we have a single-pass parser
when it comes to things like setting variables and declaring classes. When
the parser hits the first include function, it adds the class to the catalog.
The parameterized class syntax, however, is a honey badger: it doesn&rsquo;t give
a shit. It adds a class to the catalog regardless of whether it already exists
or not. So why would we EVER use the parameterized class declaration syntax?
We need to use it because the include function doesn&rsquo;t allow you to pass
parameters when you declare a class.</p>

<p>So wait &ndash; why did I spend all this time explaining why the parameterized class
syntax is more dangerous than the include function <strong>ONLY</strong> to recommend its
use in profiles?  For two reasons:</p>

<ul>
<li>We need to use it to pass parameters to classes</li>
<li>We&rsquo;re wrapping its use in a class that we can <strong>IN TURN</strong> declare with the <code>include</code> function</li>
</ul>


<p>Yes, we can get the best of BOTH worlds, the ability to pass parameters and
the use of our pal the <code>include</code> function, with this wrapper class. We&rsquo;ll see
the latter usage when we come to roles, but for now let&rsquo;s focus on passing
parameter values.</p>

<p>In the first section, we set variables with Hiera lookups, now we can pass
those variables to classes we&rsquo;re declaring with the parameterized class syntax.
This allows the declaration of the class to be static, but the parameters we
pass to that class to change according to the Hiera hierarchy. We&rsquo;ve explicitly
called the <code>hiera</code> function, so it makes it easier to debug, and we&rsquo;re explicitly
passing parameter values so we know definitively which parameters are being
passed (and thus are overriding default values) to the component module. Finally,
since our component modules do NOT use Hiera at all, we can be sure that if we&rsquo;re
not passing a parameter that it&rsquo;s getting its value from the default set in the
module&rsquo;s <code>::params</code> class.</p>

<p>Everything we do here is meant to make things easier to debug when it&rsquo;s 3am and
things aren&rsquo;t working. Any asshole can do crazy shit in Puppet, but a seasoned
sysadmin writes their code for ease of debugging during 3am pages.</p>

<h3>An annoying Puppet bug &ndash; top-level class declarations and profiles</h3>

<p><a href="http://projects.puppetlabs.com/issues/2053">Oh, ticket 2053</a>, how terrible are you? This is one of those bug numbers
that I can remember by heart (like <a href="http://projects.puppetlabs.com/issues/8040">8040</a> and <a href="http://projects.puppetlabs.com/issues/86">86</a>). Puppet has
the ability to do &lsquo;relative namespacing&rsquo;, which allows you to declare a variable
called <code>$port</code> in a class called <code>$apache</code> and refer to it as <code>$port</code> instead
of fully-namespacing the variable, and thus having to call it <code>$apache::port</code>
inside the <code>apache</code> class. It&rsquo;s a shortcut &ndash; you can STILL refer to the variable
as <code>$apache::port</code> in the class &ndash; but it comes in handy. The PROBLEM occurs when
you create a profile, as we did above, called <code>profiles::wordpress</code> and you try
to declare a class called <code>wordpress</code>.  If you do the following inside the
<code>profiles::wordpress</code> class, what class is being declared:</p>

<p><code>
include wordpress
</code></p>

<p>If you think you&rsquo;re declaring a wordpress class from within a wordpress module
in your Puppet modulepath, you would be wrong.  Puppet ACTUALLY thinks you&rsquo;re
trying to declare <code>profiles::wordpress</code> because you&rsquo;re INSIDE the <code>profiles::wordpress</code>
class and it&rsquo;s doing relative namespacing (i.e. in the same way you refer to <code>$port</code>
and ACTUALLY mean <code>$apache::port</code> it thinks you&rsquo;re referring to <code>wordpress</code> and
ACTUALLY mean <code>profiles::wordpress</code>.</p>

<p>Needless to say, this causes LOTS of confusion.</p>

<p>The solution here is to declare a class called <code>::wordpress</code> which tells Puppet
to go to the top-level namespace and look for a module called <code>wordpress</code> which
has a top-level class called <code>wordpress</code>. It&rsquo;s the same reason that we refer to
Facter Fact values as <code>$::osfamily</code> instead of <code>$osfamily</code> in class definitions
(because you can declare a local variable called <code>$osfamily</code> in your class).
This is why in the profile above you see this:</p>

<p><code>
class { '::wordpress':
  install_dir =&gt; $wordpress_docroot,
  db_name     =&gt; $wordpress_db_name,
  db_host     =&gt; $wordpress_db_host,
  db_password =&gt; $wordpress_db_password,
}
</code></p>

<p>When you use profiles and roles, you&rsquo;ll need to do this namespacing trick when
declaring classes because you&rsquo;re frequently going to have a <code>profile::&lt;sometech&gt;</code>
that will declare the <code>&lt;sometech&gt;</code> top-level class.</p>

<h2>Roles: business-specific wrapper classes</h2>

<p>How do you refer to your machines? When I ask you about that cluster over
there, do you say &ldquo;Oh, you mean the machines with java 1.6, apache, mysql,
etc&hellip;&rdquo;?  I didn&rsquo;t think so. You usually have names for them, like the
&ldquo;internal compute cluster&rdquo; or &ldquo;app builder nodes&rdquo; or &ldquo;DMZ repo machines&rdquo; or
whatever. These names are your Roles. Roles are just the mapping of your
machine&rsquo;s names to the technology that should be ON them. In the past we had
descriptive hostnames that afforded us a code for what the machine &lsquo;did&rsquo; &ndash;
roles are just that mapping for Puppet.</p>

<p>Roles are namespaced just like profiles, but now it&rsquo;s up to your organization
to fill in the blanks. Some people immediately want to put environments into
the roles (a la <code>roles::uat::compute_cluster</code>), but that&rsquo;s usually not necessary
(as MOST LIKELY the compute cluster nodes have the SAME technology on them
when they&rsquo;re in dev versus when they&rsquo;re in prod, it&rsquo;s just the DATA &ndash; like
database names, VIP locations, usernames/passwords, etc &ndash; that&rsquo;s different.
Again, these data differences will come from Hiera, so there should be no reason
to put the environment name in your role). You still CAN put the environment
name in the role if it makes you feel better, but it&rsquo;ll probably be useless.</p>

<h3>Roles ONLY include profiles</h3>

<p>So what exactly is in the role wrapper class? That depends on what technology
is on the node that defines that role. What I can tell you for CERTAIN is that
roles should ONLY use the <code>include</code> function and should ONLY include profiles.
What does this give us? This gives us our pal the <code>include</code> function back! You
can include the same profile 100 times if you want, and Puppet only puts it in
the catalog once.</p>

<h3>Every node is classified with one role. Period.</h3>

<p>The beautiful thing about roles and profiles is that the GOAL is that you
should be able to classify a node with a SINGLE role and THAT&rsquo;S IT. This makes
classification simple and static &ndash; the node gets its role, the role includes
profiles, profiles call out to Hiera for data, that data is passed to component
modules, and away we go. Also, since classification is static, you can use
version control to see what changes were introduced to the role (i.e. what
profiles were added or removed).  In my opinion, if you need to apply more
than one role to a node, you&rsquo;ve introduced a new role (see below).</p>

<h3>Roles CAN use inheritance&hellip;if you like</h3>

<p>I&rsquo;ve seen people implement roles a couple of different ways, and one of them
is to use inheritance to build a catalog.  For example, you can define a base
<code>roles</code> class that includes something like a base security profile (i.e.
something that EVERY node in your infrastructure should have). Moving down the
line, you COULD namespace according to function like <code>roles::app</code> for your
application server machines. The <code>roles::app</code> class could inherit from the <code>roles</code>
class (which gets the base security profile), and could then include the profiles
necessary to setup an application server. Next, you could subclass down to
<code>roles::app::site_foo</code> for an application server that supports some site in
your organization.  That class inherits from the <code>roles::app</code> class, and then
adds profiles that are specific to that site (maybe they use Jboss instead of
Tomcat, and thus that&rsquo;s where the differentiation occurs). This is great
because you don&rsquo;t have a lot of repeated use of the <code>include</code> function, but
it also makes it hard to definitively look at a specific role to see exactly
what&rsquo;s being declared (i.e. all the profiles). You have to weigh what you
value more: less typing or greater visibility. I will err on the side of
greater visibility (just due to that whole 3am outage thing), but it&rsquo;s up
to you to decide what to optimize for.</p>

<h3>A role similar, yet different, from another role is: a new role</h3>

<p>EVERYBODY says to me &ldquo;Gary, I have this machine that&rsquo;s an AWFUL LOT like
this role over here, but&hellip;it&rsquo;s different.&rdquo; My answer to them is: &ldquo;Great,
that&rsquo;s another role.&rdquo;  If the thing that&rsquo;s different is data (i.e. which
database to connect to, or what IP address to route traffic through),
then that difference should be put in HIERA and the classification should
remain the same. If that difference is technology-specific (i.e. this server
uses JBoss instead of Tomcat) then first look and see if you can isolate
how you know this machine is different (maybe it&rsquo;s on a different subnet,
maybe it&rsquo;s at a different location, something like that). If you can figure
that out and write a Fact for it (or use similar conditional logic to determine
this logically), then you can just drop that conditional logic in your role
and let it do the heavy lifting. If, in the end, this bit of data is totally
arbitrary, then you&rsquo;ll need to create another role (perhaps a subclass using
the above namespacing) and assign it to your node.</p>

<p>The hardest thing about this setup is naming your roles. Why? Every site is
different.  It&rsquo;s hard for me to account for differences in your setup because
your workplace is dysfunctional (seriously).</p>

<h2>Review: what does this get you?</h2>

<p>Let&rsquo;s walk through every level of this setup from the top to the bottom and see
what it gets you. Every node is classified to a single role, and, for the most
part, that classification isn&rsquo;t going to change. Now you can take all the extra
work off your classifier tool and put it back into the manifests (that are
subject to version control, so you can <code>git blame</code> to your heart&rsquo;s content and
see who last changed the role/profile). Each role is going to include one or
more profile, which gives us the added idempotent protection of the include
function (of course, if profiles have collisions with classes you&rsquo;ll have to
resolve those. Say one or more profiles tries to include an apache class &ndash;
simply break that component out into a separate profile, extract the parameters
from Hiera, and include that profile at a higher level). Each profile is going
to do Hiera lookups which should give you the ability to provide different data
for different host types (i.e. different data on a per-environment level, or
however you lay out your Hiera hierarchy), and that data will be passed
directly to class that is declared. Finally, each component module will
accept parameters as variables internal to that module, default
parameters/variables to sane values in the <code>::params</code> class, and use those
variables when declaring each resource throughtout its classes.</p>

<ul>
<li>Roles abstract profiles</li>
<li>Profiles abstract component modules</li>
<li>Hiera abstracts configuration data</li>
<li>Component modules abstract resources</li>
<li>Resources abstract the underlying OS implementation</li>
</ul>


<h2>Choose your level of comfortability</h2>

<p>The roles and profiles pattern also buys you something else &ndash; the ability for
less-skilled and more-skilled Puppet users to work with the same codebase.
Let&rsquo;s say you use some GUI classifier (like the Puppet Enterprise Console),
someone who&rsquo;s less skilled at Puppet looks and sees that a node is classified
with a certain role, so they open the role file and see something like this:</p>

<p><code>
include profiles::wordpress
include profiles::tomcat
include profiles::git::repo_server
</code></p>

<p>That&rsquo;s pretty legible, right? Someone who doesn&rsquo;t regularly use Puppet can
probably make a good guess as to what&rsquo;s on the machine. Need more information?
Open one of the profiles and look specifically at the classes that are being
declared. Need to know the data being passed? Jump into Hiera. Need to know
more information? Dig into each component module and see what&rsquo;s going on there.</p>

<p>When you have everything abstracted correctly, you can have developers
providing data (like build versions) to Hiera, junior admins grouping nodes for
classification, more senior folk updating profiles, and your best Puppet people
creating/updating component modules and building plugins like custom
facts/functions/whatever.</p>

<h2>Great! Now go and refactor&hellip;</h2>

<p>If you&rsquo;ve used Puppet for more than a month, you&rsquo;re probably familiar with the
&ldquo;Oh shit, I should have done it THAT way&hellip;let me refactor this&rdquo; game. I know,
it sucks, and we at Puppet Labs haven&rsquo;t been shy of incorporating something that
we feel will help people out (but will also require some refactoring). This
pattern, though, has been in use by the Professional Services team at Puppet Labs
for over a year without modification. I&rsquo;ve used this on sites GREAT and small,
and every site with which I&rsquo;ve consulted and implemented this pattern has been
able to both understand its power and derive real value within a week. If you&rsquo;re
contemplating a refactor, you can&rsquo;t go wrong with Roles and Profiles (or
whatever names you decide to use).</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Building a Functional Puppet Workflow Part 1: Module Structure]]></title>
    <link href="http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-1/"/>
    <updated>2014-02-17T17:01:37-05:00</updated>
    <id>http://garylarizza.com/blog/2014/02/17/puppet-workflow-part-1</id>
    <content type="html"><![CDATA[<p>Working as a professional services engineer for <a href="http://www.puppetlabs.com">Puppet Labs</a>,
my life consists almost entirely of either correcting some of the worst code
atrocities you&rsquo;ve seen in your life, or helping people get started with Puppet
so that they don&rsquo;t need to call us again due to: A.) Said code atrocities or
B.) Refactor the work we JUST helped them start.  It wasn&rsquo;t ALWAYS like this &ndash;
I can remember some of my earliest gigs, and I almost feel like I should go
revisit them if only to correct some of the previous &lsquo;best practices&rsquo; that
didn&rsquo;t quite pan out.</p>

<p>This would be exactly why I&rsquo;m wary of &lsquo;Best Practices&rsquo; &ndash; because one person&rsquo;s
&lsquo;Best Practice&rsquo; is another person&rsquo;s &lsquo;What the fuck did you just do?!&rsquo;</p>

<p>Having said that, I&rsquo;m finding myself repeating a story over and over again when
I train/consult, and that&rsquo;s the story of &lsquo;The Usable Puppet Workflow.&rsquo;  Everybody
wants to know &lsquo;The Right Way&rsquo;, and I feel like we finally have a way that survives
a reasonable test of time. I&rsquo;ve been promoting this workflow for over a year (which
is a HELL of a long time in Startup time), and I&rsquo;ve yet to really see an edge case
it couldn&rsquo;t handle.</p>

<p>(If you&rsquo;re already savvy: yes, this is the Roles and Profiles talk)</p>

<p>I&rsquo;ll be breaking this workflow down into separate blog posts for every component,
and, as always, your comments are welcome&hellip;</p>

<h2>It all starts with the component module</h2>

<p>The first piece of a functional Puppet deployment starts with what we call
&lsquo;component modules&rsquo;.  Component modules are the lowest level in your
deployment, and are modules that configure specific pieces of technology (like
apache, ntp, mysql, and etc&hellip;).  Component modules are well-encapsulated, have
a reasonable API, and focus on doing small, specific things really well (i.e.
the *nix way).</p>

<p>I don&rsquo;t want to write thousands of words on building component modules because
I feel like others have done this better than I. As examples, check out
<a href="http://www.devco.net/archives/2012/12/13/simple-puppet-module-structure-redux.php">RI&rsquo;s Post on a simple module structure</a>,
<a href="http://docs.puppetlabs.com/guides/module_guides/bgtm.html">Puppet Labs' very own docs on the subject</a>,
<a href="http://www.confreaks.com/videos/1651-puppetconf2012-puppet-modules-for-fun-and-profit">and even Alessandro&rsquo;s Puppetconf 2012 session.</a> Instead, I&rsquo;d like to
provide some pointers on what I feel makes a good component module, and some
&lsquo;gotchas&rsquo; we&rsquo;ve noticed.</p>

<h3>Parameters are your API</h3>

<p>In the current world of Puppet, you MUST define the parameters your module will
accept in the Puppet DSL. Also, every parameter MUST ultimately have a value
when Puppet compiles the catalog (whether by explicitly passing this parameter
value when declaring the class, or by assuming a default value). Yes, it&rsquo;s
funny that, when writing a Puppet class, if you typo a VARIABLE Puppet will
not alert you to this (in a NON <code>use strict</code>-ian sort of approach) and will
happily accept a variable in an undefined state, but the second you don&rsquo;t pass
a value to your class parameter you&rsquo;re in for a rude compilation error.
This is the way of Puppet classes at the time of this writing, so you&rsquo;re going
to see Puppet classes with LINES of defined parameters. I expect this to change
in the future (please let this change in the near future), but for now, it&rsquo;s
a necessary evil.</p>

<p>The parameters you expose to your top-level class (i.e. given class names like
<code>apache</code> and <code>apache::install</code>, I&rsquo;m talking specifically about <code>apache</code>) should
be treated as an API to your module. IDEALLY, they&rsquo;re the ONLY THING that
a user needs to modify when using your module. Also, whenever possible, it
should be the case that a user need ONLY interact with the top-level class when
using your module (of course, defined resource types like <code>apache::vhost</code> are
used on an ad-hoc basis, and thus are the exception here).</p>

<h3>Inherit the <code>::params</code> class</h3>

<p>We&rsquo;re starting to make enemies at this point. It&rsquo;s been a convention for modules
to use a <code>::params</code> class to assign values to all variables that are going to
be used for all classes inside the module. The idea is that the <code>::params</code> class
is the one-stop-shop to see where a variable is set. Also, to get access to a
variable that&rsquo;s set in a Puppet class, you have to declare the class (i.e. use
the <code>include()</code> function or inherit from that class). When you declare a class
that has both variables AND resources, those resources get put into the catalog,
which means that Puppet ENFORCES THE STATE of those resources. What if you only
needed a variable&rsquo;s value and didn&rsquo;t want to enforce the rest of the resources
in that class? There&rsquo;s no good way in Puppet to do that. Finally, when you inherit
from a class in Puppet that has assigned variable values, you ALSO get access
to those variables in the parameter definition section of your class (i.e. the
following section of the class:</p>

<pre><code>class apache (
  $port = $apache::params::port,
  $user = $apache::params::user,
) inherits apache::params {
</code></pre>

<p>See how I set the default value of <code>$apache::port</code> to <code>$apache::params::port</code>?
I could only access the value of the variable <code>$apache::params::port</code> in that
section by inheriting from the <code>apache::params</code> class.  I couldn&rsquo;t insert
<code>include apache::params</code> below that section and be allowed access to the variable
up in the parameter defaults section (due to the way that Puppet parses classes).</p>

<p><strong>FOR THIS REASON, THIS IS THE </strong><em>ONLY</em><strong> RECOMMENDED USAGE OF INHERITANCE IN
PUPPET!</strong></p>

<p>We do NOT recommend using inheritance anywhere else in Puppet and for any other
reason because there are better ways to achieve what you want to do INSTEAD of
using inheritance.  Inheritance is a holdover from a scarier, more lawless time.</p>

<p><strong>NOTE: Data in Modules</strong> &ndash; There&rsquo;s a &lsquo;Data in Modules&rsquo; pattern out there that
attempts to eliminate the <code>::params</code> class.  <a href="http://garylarizza.com/blog/2013/12/08/when-to-hiera/">I wrote about it in a previous post</a>,
and I recommend you read that post for more info (it&rsquo;s near the bottom).</p>

<h3>Do <strong>NOT</strong> do Hiera lookups in your component modules!</h3>

<p>This is something that&rsquo;s really only RECENTLY been pushed. When Hiera was
released, we quickly recognized that it would be the answer to quite a few
problems in Puppet. In the rush to adopt Hiera, many people started adding
Hiera calls to their modules, and suddenly you had &lsquo;Hiera-compatible&rsquo; modules
out there. This caused all kinds of compatibility problems, and it was largely
because there wasn&rsquo;t a better module structure and workflow by which to integrate
Hiera. The pattern that I&rsquo;ll be pushing DOES INDEED use Hiera, <strong>BUT</strong> it
confines all Hiera calls to a higher-level wrapper class we call a &lsquo;profile&rsquo;.
The reasons for NOT using Hiera in your module are:</p>

<ul>
<li>By doing Hiera calls at a higher level, you have a greater visibility on
exactly what parameters were set by Hiera and which were set explicitly or by
default values.</li>
<li>By doing Hiera calls elsewhere, your module is backwards-compatible for
those folks who are NOT using Hiera</li>
</ul>


<p>Remember &ndash; your module should just accept a value and use it somewhere. Don&rsquo;t
get <strong>TOO</strong> smart with your component module &ndash; leave the logic for other
places.</p>

<h3>Keep your component modules generic</h3>

<p>We always get asked &ldquo;How do I know if I&rsquo;m writing a good module?&rdquo; We USED to
say &ldquo;Well, does it work?&rdquo; (and trust me, that was a BIG hurdle). Now, with
data separation models out there like Hiera, I have a couple of other questions
that I ask (you know, BEYOND asking if it compiles and actually installs the
thing it&rsquo;s supposed to install). The best way I&rsquo;ve found to determine if your
module is &lsquo;generic enough&rsquo; is if I asked you TODAY to give me your module,
would you give it to me, or would you be worried that there was some
company-specific data locked in there? If you have company-specific data in
your module, then you need to refactor the module, store the data in Hiera, and
make your module more generic/reusable. Also, does your module focus on installing
one piece of technology, or are you declaring packages for shared libraries
or other components (like gcc, apache, or other common components)? You&rsquo;re
not going to win any prizes for having the biggest, most monolithic module
out there. Rather, if your module is that large and that complex, you&rsquo;re
going to have a hell of a time debugging it. Err on the side of making your
modules smaller and more task-specific. So what if you end up needing to
declare 4 classes where you previously declared 1? In the roles and profiles
pattern we will show you in the next blog post, you can abstract that away
ANYHOW.</p>

<h3>Don&rsquo;t play the &ldquo;what if&rdquo; game</h3>

<p>I&rsquo;ve had more than a couple of gigs where the customer says something along the
lines of &ldquo;What if we need to introduce FreeBSD/Solaris/etc&hellip; nodes into our
organization, shouldn&rsquo;t I account for them now?&rdquo; This leads more than a few
people down a path of entirely too-complex modules that become bulky and
unwieldy. Yes, your modules should be formatted so that you can simply add
another case in your <code>::params</code> class for another OS&rsquo;s parameters, and yes,
your module should be formatted so that your <code>::install</code> or <code>::config</code>
class can handle another OS, but if you currently only manage Redhat, and
you&rsquo;ve only EVER managed Redhat, then don&rsquo;t start adding Debian parameters
RIGHT NOW just because you&rsquo;re afraid you might inherit Ubuntu machines. The
goal of Puppet is to automate the tasks that eat up the MAJORITY of your time
so you can focus on the edge cases that really demand your time. If you can
eventually automate those edge cases, then AWESOME! Until then, don&rsquo;t spend
the majority of your time trying to automate the edge cases only to drown
under the weight of deadlines from simple work that you COULD have already
automated (but didn&rsquo;t, because you were so worried about the exceptions)!</p>

<h3>Store your modules in version control</h3>

<p>This should go without saying, but your modules should be stored in version
control (a la git, svn, hg, whatever). We tend to prefer git due to its lightweight
branching and merging (most of our tooling and solutions will use git because
we&rsquo;re big git users), but you&rsquo;re free to use whatever you want. The bigger
question is HOW to store your modules in version control. There are usually
two schools of thought:</p>

<ul>
<li>One repository per module</li>
<li>All modules in a single repository</li>
</ul>


<p>Each model has its pros and cons, but we tend to recommend one module per
repository for the following reasons:</p>

<ul>
<li>Individual repos mean individual module development histories</li>
<li>Most VCS solutions don&rsquo;t have per-folder ACLs for a single repositories;
having multiple repos allows per-module security settings.</li>
<li>With the one-repository-per-module solution, modules you pull down from the
Forge (or Github) must be committed to your repo. Having multiple
repositories for each module allow you to keep everything separate</li>
</ul>


<p><strong>NOTE:</strong> This becomes important in the third blog post in the series when we
talk about moving changes to each Puppet Environment, but it&rsquo;s important to
introduce it NOW as a &lsquo;best practice&rsquo;. If you use our recommended module/environment
solution, then one-module-per-repo is the best practice. If you DON&rsquo;T use our
solution, then the single repository per for all modules will STILL work,
but you&rsquo;ll have to manage the above issues. Also note that even if you currently
have every module in a single repository, you can STILL use our solution in
part 3 of the series (you&rsquo;ll just need to perform a couple of steps to conform).</p>

<h2>Best practices are shit</h2>

<p>In general, &lsquo;best practices&rsquo; are only recommended if they fit into your organizational
workflow. The best and worst part of Puppet is that it&rsquo;s infinitely customizable,
so &lsquo;best practices&rsquo; will invariably be left wanting for a certain subset of the
community. As always, take what I say under consideration; it&rsquo;s quite possible
that I could be entirely full of shit.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Seriously, what is this provider doing?]]></title>
    <link href="http://garylarizza.com/blog/2013/12/15/seriously-what-is-this-provider-doing/"/>
    <updated>2013-12-15T11:44:17-05:00</updated>
    <id>http://garylarizza.com/blog/2013/12/15/seriously-what-is-this-provider-doing</id>
    <content type="html"><![CDATA[<p>Clarke&rsquo;s third law states: &ldquo;Any sufficiently advanced technology is
indistinguishable from magic.&rdquo; In the case of Ruby and Puppet provider
interaction, I&rsquo;m inclined to believe it. If you want proof, take a look at some
of the native Puppet types &ndash; no amount of &lsquo;Expecto Patronum&rsquo; will free you from
the Ruby metaprogramming dementors that hover around
<code>lib/puppet/provider/exec</code>-land.</p>

<p>In my <a href="http://garylarizza.com/blog/2013/11/25/fun-with-providers/">first post tackling Puppet types and providers</a>, I introduced
the concept of Puppet types and the utility they provide. <a href="http://garylarizza.com/blog/2013/11/26/fun-with-providers-part-2/">In the second post,</a>
I brought you to the great plain of Puppet providers and introduced the core
methods necessary for creating a very basic Puppet provider with a single property
(HINT: if you&rsquo;ve not read either of those posts, or you&rsquo;ve never dealt with basic
types and providers, you might want to stop here and read up a bit on the topics).
The problems with a provider like the one created in that post were:</p>

<ul>
<li><code>puppet resource</code> support wasn&rsquo;t implemented, so you couldn&rsquo;t query for existing instances of the type on the system (and their corresponding values)</li>
<li>The getter method would be called for EVERY instance of the type on the system, which would mean shelling-out multiple times during a run</li>
<li>Ditto for the setter method (if changes to multiple instances of the type were necessary)</li>
<li>That type was VERY basic (i.e. ensurable with a single property)</li>
</ul>


<p>Unfortunately, when most of us have the need of a Puppet type and provider, we
usually require multiple properties and reasonably complex system interaction. When
it comes to creating both a getter and a setter method for every property (including
the potential performance hit that could come from shelling-out many times during
a Puppet run), ain&rsquo;t nobody got time for that. And finally, <code>puppet resource</code> is a
REALLY handy tool for querying the current state of your resources on a system.
These problems all have solutions, but up until recently there was just one more
problem:</p>

<p><strong>Good luck finding documentation for those solutions.</strong></p>

<p>NOTE: The <a href="http://www.amazon.com/Puppet-Types-Providers-Dan-Bode/dp/1449339328/ref=sr_1_1?ie=UTF8&amp;qid=1387136838&amp;sr=8-1&amp;keywords=types+and+providers+puppet+book">Puppet Types and Providers book written by Nan and Dan</a>
is a great resource that provides a bit of a deeper dive than I&rsquo;ll be doing in this
post &ndash; DO check it out if you want to know more</p>

<h2>Something, something, <code>puppet resource</code></h2>

<p>The <code>puppet resource</code> command (or <code>ralsh</code>, as it used to be known), is a very
handy command for querying a system and returning the current state of resources
for a specific Puppet type.  Try it out if you never have (note that the following
is being run on CentOS 6.4):</p>

<pre><code>[root@linux ~]# puppet resource user
user { 'abrt':
  ensure           =&gt; 'present',
  gid              =&gt; '173',
  home             =&gt; '/etc/abrt',
  password         =&gt; '!!',
  password_max_age =&gt; '-1',
  password_min_age =&gt; '-1',
  shell            =&gt; '/sbin/nologin',
  uid              =&gt; '173',
}
user { 'adm':
  ensure           =&gt; 'present',
  comment          =&gt; 'adm',
  gid              =&gt; '4',
  groups           =&gt; ['sys', 'adm'],
  home             =&gt; '/var/adm',
  password         =&gt; '*',
  password_max_age =&gt; '99999',
  password_min_age =&gt; '0',
  shell            =&gt; '/sbin/nologin',
  uid              =&gt; '3',
}
&lt; ... and more users below ... &gt;
</code></pre>

<p>The <code>puppet resource</code> command returns a list of all users on the system
and their current property values (note you can only see the password
hash if you&rsquo;re running Puppet with sufficient privileges). You can even
query <code>puppet resource</code> for the values of a specific resource:</p>

<pre><code>[root@gary ~]# puppet resource user glarizza
user { 'glarizza':
  ensure           =&gt; 'present',
  gid              =&gt; '502',
  home             =&gt; '/home/glarizza',
  password         =&gt; '$1$hsUuCygh$kgLKG5epuRaXHMX5KmxrL1',
  password_max_age =&gt; '99999',
  password_min_age =&gt; '0',
  shell            =&gt; '/bin/bash',
  uid              =&gt; '502',
}
</code></pre>

<p><code>puppet resource</code> seems magical, and you might think that if you create a
custom type and sync it to your machine then <code>puppet resource</code> will automatically
work for you.</p>

<p><strong>And you would be wrong.</strong></p>

<p><code>puppet resource</code> will only work if you&rsquo;ve implemented a special method in your
provider called <code>self.instances</code>.</p>

<h2><code>self.instances</code></h2>

<p>The <code>self.instances</code> method is pretty sparsely documented, so let&rsquo;s go straight
to the source&hellip;code, that is:</p>

<p>{% codeblock lang:ruby lib/puppet/provider.rb %}
  # Returns a list of system resources (entities) this provider may/can manage.
  # This is a query mechanism that lists entities that the provider may manage on a given system. It is
  # is directly used in query services, but is also the foundation for other services; prefetching, and
  # purging.
  #
  # As an example, a package provider lists all installed packages. (In contrast, the File provider does
  # not list all files on the file-system as that would make execution incredibly slow). An implementation
  # of this method should be made if it is possible to quickly (with a single system call) provide all
  # instances.
  #
  # An implementation of this method should only cache the values of properties
  # if they are discovered as part of the process for finding existing resources.
  # Resource properties that require additional commands (than those used to determine existence/identity)
  # should be implemented in their respective getter method. (This is important from a performance perspective;
  # it may be expensive to compute, as well as wasteful as all discovered resources may perhaps not be managed).
  #
  # An implementation may return an empty list (naturally with the effect that it is not possible to query
  # for manageable entities).
  #
  # By implementing this method, it is possible to use the `resources resource type to specify purging
  # of all non managed entities.
  #
  # @note The returned instances are instance of some subclass of Provider, not resources.
  # @return [Array&lt;Puppet::Provider>] a list of providers referencing the system entities
  # @abstract this method must be implemented by a subclass and this super method should never be called as it raises an exception.
  # @raise [Puppet::DevError] Error indicating that the method should have been implemented by subclass.
  # @see prefetch
  def self.instances</p>

<pre><code>raise Puppet::DevError, "Provider #{self.name} has not defined the 'instances' class method"
</code></pre>

<p>  end
{% endcodeblock %}</p>

<p>You&rsquo;ll find that method around lines 348 &ndash; 377 of the <code>lib/puppet/provider.rb</code>
file in Puppet&rsquo;s source code (as of this writing, which is a Friday&hellip;
on a flight from DC to Seattle). To summarize, implementing <code>self.instances</code>
in your provider means that you need to return an array of provider instances
that have been discovered on the current system and all the current property
values (we call these values the &lsquo;is&rsquo; values for the properties, since each
value IS the current value of the property on the system). It&rsquo;s recommended to only
implement <code>self.instances</code> if you can gather all resource property values in a reasonably
&lsquo;cheap&rsquo; manner (i.e. a single system call, read from a single file, or some
similar low-IO means). Implementing <code>self.instances</code> not only gives you the
ability to run <code>puppet resource</code> (which also affords you a quick-and-dirty
way of testing your provider without creating unit tests by simply running
<code>puppet resource</code> in debug mode and checking the output), but it also allows
the <a href="http://docs.puppetlabs.com/references/latest/type.html#resources">&lsquo;resources&rsquo; resource</a> to work its magic (If you&rsquo;ve
never heard of the &lsquo;resources&rsquo; resource, <a href="http://docs.puppetlabs.com/references/latest/type.html#resources">check this link</a>
for more information on this terribly/awesomely named resource type).</p>

<h3>An important note about scope and <code>self.instances</code></h3>

<p>The <code>self.instances</code> method is a method of the PROVIDER, which is why it is
prefixed with <code>self.</code>  Even though it may be located in the provider file
itself, and even though it sits among other methods like <code>create</code>, <code>exists?</code>,
and <code>destroy</code> (which are methods of the INSTANCE of the provider), it does
NOT have the ability to directly access or call those methods. It DOES have
the ability to access other methods of the provider directly (i.e. other
methods prefixed with <code>self.</code>).  This means that if you were to define a
method like:</p>

<p>{% codeblock lang:ruby %}
def self.proxy_type
  &lsquo;web&rsquo;
end
{% endcodeblock %}</p>

<p>You could access that directly from <code>self.instances</code> by simply calling it:</p>

<p>{% codeblock lang:ruby %}
type_of_proxy = proxy_type()
{% endcodeblock %}</p>

<p>Let&rsquo;s say you had a method of the INSTANCE of the provider, like so:</p>

<p>{% codeblock lang:ruby %}
def system_type
  &lsquo;OS X&rsquo;
end
{% endcodeblock %}</p>

<p>You COULD NOT access this method from <code>self.instances</code> directly (there are
always hacky ways around EVERYTHING in Ruby, sure, but there is no easy/straightforward
way to access this method).</p>

<p><strong>And here&rsquo;s where it gets confusing&hellip;</strong></p>

<p>Methods of the INSTANCE of the provider CAN access provider methods directly.
Given our previous example, what if the <code>system_type</code> method wanted to access
<code>self.proxy_type</code> for some reason?  It could be done like so:</p>

<p>{% codeblock lang:ruby %}
def system_type
  type_of_proxy = self.class.proxy_type()
  &lsquo;OS X&rsquo;
end
{% endcodeblock %}</p>

<p>A method of the instance of the provider can access provider methods by simply
calling the <code>class</code> method on itself (which returns the provider object). This
is a one-way street for method creation that needs to be heeded when designing
your provider.</p>

<h2>Building a provider that uses <code>self.instances</code> (or: more Mac problems)</h2>

<p>In the previous two posts on types/providers, I created a type and provider
for managing bypass domains for network proxies on OS X. For this post, let&rsquo;s
create a provider for actually MANAGING the proxy settings for a given
network interface.  Here&rsquo;s a quick type for managing a web proxy on a network
interface on OS X:</p>

<p>{% codeblock lang:ruby puppet-mac_proxy/lib/puppet/type/mac_web_proxy.rb %}
Puppet::Type.newtype(:mac_web_proxy) do
  desc &ldquo;Puppet type that models a network interface on OS X&rdquo;</p>

<p>  ensurable</p>

<p>  newparam(:name, :namevar => true) do</p>

<pre><code>desc "Interface name - currently must be 'friendly' name (e.g. Ethernet)"
munge do |value|
  value.downcase
end
def insync?(is)
  is.downcase == should.downcase
end
</code></pre>

<p>  end</p>

<p>  newproperty(:proxy_server) do</p>

<pre><code>desc "Proxy Server setting for the interface"
</code></pre>

<p>  end</p>

<p>  newparam(:authenticated_username) do</p>

<pre><code>desc "Username for proxy authentication"
</code></pre>

<p>  end</p>

<p>  newparam(:authenticated_password) do</p>

<pre><code>desc "Password for proxy authentication"
</code></pre>

<p>  end</p>

<p>  newproperty(:proxy_authenticated) do</p>

<pre><code>desc "Proxy Server setting for the interface"
newvalues(:true, :false)
</code></pre>

<p>  end</p>

<p>  newproperty(:proxy_port) do</p>

<pre><code>desc "Proxy Server setting for the interface"
newvalues(/^\d+$/)
</code></pre>

<p>  end
end
{% endcodeblock %}</p>

<p>This type has three properties, is ensurable, and a namevar called &lsquo;name&rsquo;. As
for the provider, let&rsquo;s start with <code>self.instances</code> and get the web proxy
values for all interfaces.  To do that we&rsquo;re going to need to know how to get
a list of all network interfaces, and also how to get the current proxy state
for every interface. Fortunately, both of those tasks are accomplished with the
<code>networksetup</code> binary:</p>

<pre><code> networksetup -listallnetworkservices
An asterisk (*) denotes that a network service is disabled.
Bluetooth DUN
Display Ethernet
Ethernet
FireWire
Wi-Fi
iPhone USB
Bluetooth PAN

 networksetup -getwebproxy Ethernet
Enabled: No
Server: proxy.corp.net
Port: 1234
Authenticated Proxy Enabled: 0
</code></pre>

<p>Cool, so one binary will do both tasks and they&rsquo;re REASONABLY low-cost to run.</p>

<h3>Helper methods</h3>

<p>To keep things separated and easier to test, let&rsquo;s create separate helper methods
for each task. Since these methods are going to be called by <code>self.instances</code>,
they will be provider methods.</p>

<p>The first method will simply return an array of network interfaces:</p>

<p>{% codeblock lang:ruby %}
def self.get_list_of_interfaces
  interfaces = networksetup(&lsquo;-listallnetworkservices&rsquo;).split(&ldquo;\n&rdquo;)
  interfaces.shift
  interfaces.sort
end
{% endcodeblock %}</p>

<p>Remember from above that the <code>networksetup -listallnetworkservices</code> command
returns an info line before each interface, so this code strips that line
off and returns a sorted list of interfaces based on a one-line-per-interface
assumption.</p>

<p>The next method we need will accept a network interface name as an argument,
will run the <code>networksetup -getwebproxy (interface)</code> command, and will use
its output to return all the current property values (including the ensure
value) for every instance of the type on the system (i.e. every interface&rsquo;s
proxy settings and whether the proxy is enabled, which means the resource
is ensured as &lsquo;present&rsquo;, or disabled, which means the resource is ensured
as &lsquo;absent&rsquo;.</p>

<p>{% codeblock lang:ruby %}
def self.get_proxy_properties(int)
  interface_properties = {}</p>

<p>  begin</p>

<pre><code>output = networksetup(['-getwebproxy', int])
</code></pre>

<p>  rescue Puppet::ExecutionFailure => e</p>

<pre><code>raise Puppet::Error, "#mac_web_proxy tried to run `networksetup -getwebproxy #{int}` and the command returned non-zero. Failing here..."
</code></pre>

<p>  end</p>

<p>  output_array = output.split(&ldquo;\n&rdquo;)
  output_array.each do |line|</p>

<pre><code>line_values = line.split(':')
line_values.last.strip!
case line_values.first
when 'Enabled'
  interface_properties[:ensure] = line_values.last == 'No' ? :absent : :present
when 'Server'
  interface_properties[:proxy_server] = line_values.last.empty? ? nil : line_values.last
when 'Port'
  interface_properties[:proxy_port] = line_values.last == '0' ? nil : line_values.last
when 'Authenticated Proxy Enabled'
  interface_properties[:proxy_authenticated] = line_values.last == '0' ? nil : line_values.last
end
</code></pre>

<p>  end</p>

<p>  interface_properties[:provider] = :ruby
  interface_properties[:name]     = int.downcase
  interface_properties
end
{% endcodeblock %}</p>

<p>A couple of notes on the method itself &ndash; first, the <code>networksetup</code> command must
exit zero on success or non-zero on failure (which it does). If ever the <code>networksetup</code>
command were to return non-zero, we&rsquo;re raising our own Puppet::Error, documenting what
happened, and bailing out.</p>

<p>This method is going to return a hash of properties and values that is going
to be used by <code>self.instances</code> &ndash; so the case statement needs to account for that.
HOWEVER you populate that hash is up to you (in my case, I&rsquo;m checking for specific
output that <code>networksetup</code> returns), but make sure that the hash has a value for
the <code>:ensure</code> key at the VERY least.</p>

<h3>Assembling <code>self.instances</code></h3>

<p>Once the helper provider methods have been defined, <code>self.instances</code> becomes
reasonably simple:</p>

<p>{% codeblock lang:ruby %}
def self.instances
  get_list_of_interfaces.collect do |int|</p>

<pre><code>proxy_properties = get_proxy_properties(int)
new(proxy_properties)
</code></pre>

<p>  end
end
{% endcodeblock %}</p>

<p>Remember that <code>self.instances</code> must return an array of provider instances,
and each one of these instances must include the <code>namevar</code> and ensure value
at the very least. Since <code>self.get_proxy_properties</code> returns a hash containing
all the property &lsquo;is&rsquo; values for a resource, declaring a new provider instance
is as easy as calling the <code>new()</code> method on the return value of
<code>self.get_proxy_properties</code> for every network interface. In the end, the
return value of the <code>collect</code> method on <code>get_list_of_interfaces</code> will be an
array of provider instances.</p>

<h2>Existance, <code>@property_hash</code>, and more magical methods</h2>

<p>Even though we have assembled a functional <code>self.instances</code> method, we don&rsquo;t have
complete implementation that will work with <code>puppet resource</code>.  The problem is
that Puppet can&rsquo;t yet determine the existance of a resource (even though the
resource&rsquo;s <code>ensure</code> value has been set by <code>self.instances</code>). If you were to
execute the code with <code>puppet resource mac_web_proxy</code>, you would get the error:</p>

<pre><code>Error: Could not run: No ability to determine if mac_web_proxy exists
</code></pre>

<p>To satisfy Puppet, we need to implement an <code>exists?()</code> method for the instance
of the provider. Fortunately, we don&rsquo;t need to re-implement any existing logic
and can instead use <code>@property_hash</code></p>

<h3>A <code>@property_hash</code> is born&hellip;</h3>

<p>I&rsquo;ve omitted one last thing that is borne out of <code>self.instances</code>, and that&rsquo;s
the <code>@property_hash</code> instance variable. <code>@property_hash</code> is populated by
<code>self.instances</code> as an instance variable that&rsquo;s available to methods of the
INSTANCE of the provider (i.e. methods that ARE NOT prefixed with <code>self.</code>)
containing all the &lsquo;is&rsquo; values for a resource. Do you need to get the &lsquo;is&rsquo;
value for a property?  Just use <code>@property_hash[:property_name]</code>. Since the
<code>exists?</code> method is a method of the instance of the provider, and it&rsquo;s
essentially the same thing as the <code>ensure</code> value for a resource, let&rsquo;s implement
<code>exists?</code> by doing a check on the ensure value from the <code>@property_hash</code>
variable:</p>

<p>{% codeblock lang:ruby %}
def exists?
  @property_hash[:ensure] == :present
end
{% endcodeblock %}</p>

<p>Perfect, now <code>exists?</code> will return true or false accordingly and Puppet will be
satisfied.</p>

<h3>Getter methods &ndash; the slow way</h3>

<p>Puppet may be happy that you have an <code>exists?</code> method, but <code>puppet resource</code>
won&rsquo;t successfully run until you have a method that returns an &lsquo;is&rsquo; value for
every property of the type (i.e. the <code>proxy_server</code>, <code>proxy_authenticated</code>,
and <code>proxy_port</code> attributes for the mac_web_proxy type). These &lsquo;is value methods&rsquo; are
called &lsquo;getter&rsquo; methods: they&rsquo;re methods of the instance of the provider, and
are named exactly the same as the properties they represent.</p>

<p>You SHOULD be thinking: &ldquo;Hey, we already have <code>@property_hash</code>, why can&rsquo;t we
just use it again? We can, and you COULD implement all the getter methods
like so:</p>

<p>{% codeblock lang:ruby %}
def proxy_server
  @property_hash[:proxy_server]
end
{% endcodeblock %}</p>

<p>If you did that, you would be TECHNICALLY correct, but it would seem to be a
waste of lines in a provider (especially if you have many properties).</p>

<h3>Getter methods &ndash; the quicker &lsquo;method&rsquo;</h3>

<p>Because uncle Luke hated excess lines of code, he made available a method called
<code>mk_resource_methods</code> which works very similarly to Ruby&rsquo;s <code>attr_accessor</code>
method. Adding <code>mk_resource_methods</code> to your provider will AUTOMATICALLY
create getter methods that pull values out of <code>@property_hash</code> in the similar
way that I just demonstrated (it will also create SETTER methods too, but we&rsquo;ll
look at those later). Long story short &ndash; don&rsquo;t make getter/setter methods if
you&rsquo;re using self.instances &ndash; just implement <code>mk_resource_methods</code>.</p>

<h2>JUST enough for <code>puppet resource</code></h2>

<p>Putting everything that we&rsquo;ve learned up until now, we should have a provider
that looks like this:</p>

<p>{% codeblock lang:ruby lib/puppet/provider/mac_web_proxy/ruby.rb %}
Puppet::Type.type(:mac_web_proxy).provide(:ruby) do
  commands :networksetup => &lsquo;networksetup&rsquo;</p>

<p>  mk_resource_methods</p>

<p>  def self.get_list_of_interfaces</p>

<pre><code>interfaces = networksetup('-listallnetworkservices').split("\n")
interfaces.shift
interfaces.sort
</code></pre>

<p>  end</p>

<p>  def self.get_proxy_properties(int)</p>

<pre><code>interface_properties = {}

begin
  output = networksetup(['-getwebproxy', int])
rescue Puppet::ExecutionFailure =&gt; e
  Puppet.debug "#get_proxy_properties had an error -&gt; #{e.inspect}"
  return {}
end

output_array = output.split("\n")
output_array.each do |line|
  line_values = line.split(':')
  line_values.last.strip!
  case line_values.first
  when 'Enabled'
    interface_properties[:ensure] = line_values.last == 'No' ? :absent : :present
  when 'Server'
    interface_properties[:proxy_server] = line_values.last.empty? ? nil : line_values.last
  when 'Port'
    interface_properties[:proxy_port] = line_values.last == '0' ? nil : line_values.last
  when 'Authenticated Proxy Enabled'
    interface_properties[:proxy_authenticated] = line_values.last == '0' ? nil : line_values.last
  end
end

interface_properties[:provider] = :ruby
interface_properties[:name]     = int.downcase
Puppet.debug "Interface properties: #{interface_properties.inspect}"
interface_properties
</code></pre>

<p>  end</p>

<p>  def self.instances</p>

<pre><code>get_list_of_interfaces.collect do |int|
  proxy_properties = get_proxy_properties(int)
  new(proxy_properties)
end
</code></pre>

<p>  end</p>

<p>  def exists?</p>

<pre><code>@property_hash[:ensure] == :present
</code></pre>

<p>  end
end
{% endcodeblock %}</p>

<p>Here&rsquo;s a tree of the module I&rsquo;ve assembled on my machine:</p>

<pre><code>(~/src/puppet-mac_web_proxy) tree .
.
 lib
  puppet
      provider
       mac_web_proxy
           ruby.rb
      type
          mac_web_proxy.rb
</code></pre>

<p>To test out <code>puppet resource</code>, we need to make Puppet aware of our new custom
module. To do that, let&rsquo;s set the <code>$RUBYLIB</code> environmental variable. <code>$RUBYLIB</code>
is queried by Puppet and is added to its load path when looking for additional
Puppet plugins.  You will need to set <code>$RUBYLIB</code> to the path of the <code>lib</code> directory
in the custom module that you&rsquo;ve assembled.  Because my custom module is located
in <code>~/src/puppet-mac_web_proxy</code>, I&rsquo;m going to set <code>$RUBYLIB</code> like so:</p>

<pre><code>export RUBYLIB=~/src/puppet-mac_web_proxy/lib
</code></pre>

<p>You can execute that command from the command line, or set it in your
<code>~/.{bash,zsh}rc</code> and <code>source</code> that file.</p>

<p>Finally, with all the files in place and <code>$RUBYLIB</code> set, it&rsquo;s time to officially
run <code>puppet resource</code> (I&rsquo;m going to do it in <code>--debug</code> mode to see the debug output
that I&rsquo;ve written into the code):</p>

<pre><code>(~/src/blogtests) envpuppet puppet resource mac_web_proxy --debug
Debug: Executing '/usr/sbin/networksetup -listallnetworkservices'
Debug: Executing '/usr/sbin/networksetup -getwebproxy Bluetooth DUN'
Debug: Interface properties: {:ensure=&gt;:absent, :proxy_server=&gt;nil, :proxy_port=&gt;nil, :proxy_authenticated=&gt;nil, :provider=&gt;:ruby, :name=&gt;"bluetooth dun"}
Debug: Executing '/usr/sbin/networksetup -getwebproxy Bluetooth PAN'
Debug: Interface properties: {:ensure=&gt;:absent, :proxy_server=&gt;nil, :proxy_port=&gt;nil, :proxy_authenticated=&gt;nil, :provider=&gt;:ruby, :name=&gt;"bluetooth pan"}
Debug: Executing '/usr/sbin/networksetup -getwebproxy Display Ethernet'
Debug: Interface properties: {:ensure=&gt;:absent, :proxy_server=&gt;"foo.bar.baz", :proxy_port=&gt;"80", :proxy_authenticated=&gt;nil, :provider=&gt;:ruby, :name=&gt;"display ethernet"}
Debug: Executing '/usr/sbin/networksetup -getwebproxy Ethernet'
Debug: Interface properties: {:ensure=&gt;:absent, :proxy_server=&gt;"proxy.corp.net", :proxy_port=&gt;"1234", :proxy_authenticated=&gt;nil, :provider=&gt;:ruby, :name=&gt;"ethernet"}
Debug: Executing '/usr/sbin/networksetup -getwebproxy FireWire'
Debug: Interface properties: {:ensure=&gt;:present, :proxy_server=&gt;"stuff.bar.blat", :proxy_port=&gt;"8190", :proxy_authenticated=&gt;nil, :provider=&gt;:ruby, :name=&gt;"firewire"}
Debug: Executing '/usr/sbin/networksetup -getwebproxy Wi-Fi'
Debug: Interface properties: {:ensure=&gt;:absent, :proxy_server=&gt;nil, :proxy_port=&gt;nil, :proxy_authenticated=&gt;nil, :provider=&gt;:ruby, :name=&gt;"wi-fi"}
Debug: Executing '/usr/sbin/networksetup -getwebproxy iPhone USB'
Debug: Interface properties: {:ensure=&gt;:absent, :proxy_server=&gt;nil, :proxy_port=&gt;nil, :proxy_authenticated=&gt;nil, :provider=&gt;:ruby, :name=&gt;"iphone usb"}
mac_web_proxy { 'bluetooth dun':
  ensure =&gt; 'absent',
}
mac_web_proxy { 'bluetooth pan':
  ensure =&gt; 'absent',
}
mac_web_proxy { 'display ethernet':
  ensure =&gt; 'absent',
}
mac_web_proxy { 'ethernet':
  ensure =&gt; 'absent',
}
mac_web_proxy { 'firewire':
  ensure       =&gt; 'present',
  proxy_port   =&gt; '8190',
  proxy_server =&gt; 'stuff.bar.blat',
}
mac_web_proxy { 'iphone usb':
  ensure =&gt; 'absent',
}
mac_web_proxy { 'wi-fi':
  ensure =&gt; 'absent',
}
</code></pre>

<p>Note that you will only see &lsquo;is&rsquo; values if you have a proxy set on any of your
network interfaces (obviously, if you&rsquo;ve not setup a proxy, then it will show
as &lsquo;absent&rsquo; on every interface. You can setup a proxy by opening System
Preferences, clicking on the Network icon, choosing an interface from the list
on the left, clicking the Advanced button in the lower right corner of the
window, clicking the &lsquo;Proxies" tab at the top of the window, clicking the
checkbox next to the &ldquo;Web Proxy (HTTP)&rdquo; choice, and entering a proxy URL and
port. NOW do you get why we automate this bullshit?).  Also, your list of
network interfaces may not match mine if you have more or less interfaces than
I do.</p>

<p>TADA! <code>puppet resource</code> WORKS! ISN&rsquo;T THAT AWESOME?! WHY AM I TYPING IN CAPS?!</p>

<h2>Prefetching, flushing, caching, and other hard shit</h2>

<p>Okay, so up until now we&rsquo;ve implemented one half of the equation &ndash; we can query
&lsquo;is&rsquo; values and <code>puppet resource</code> works. What about using this &lsquo;more efficient&rsquo;
method of getting values for a type on the OTHER end of the spectrum? What if
instead of calling setter methods one-by-one to set values for all resources
of a type in a catalog we had a way to do it all at once? Well, such a way
exists, and it&rsquo;s called the <code>flush</code> method&hellip;but we&rsquo;re getting slightly ahead
of ourselves. Before we get to flushing, we need to point out that <code>self.instances</code>
is ONLY used by <code>puppet resource</code> &ndash; THAT&rsquo;S IT (and it&rsquo;s only used by <code>self.instances</code>
when you GET values from the system, not when you SET values on the system&hellip;and if
you never knew that <code>puppet resource</code> could actually SET values on the system, well,
I guess you got another surprise today). If we want <code>puppet agent</code> or
<code>puppet apply</code> to use the behavior that <code>self.instances</code> implements, we need
to create another method: <code>self.prefetch</code></p>

<h3><code>self.prefetch</code></h3>

<p>If you thought <code>self.instances</code> didn&rsquo;t have much documentation, wait until
you see <code>self.prefetch</code>.  After wading the waters of <code>self.prefetch</code>, I&rsquo;m
PRETTY SURE its implementation might have come to uncle Luke after a long
night in Reed&rsquo;s chem lab where he might have accidently synthesized mescaline.</p>

<p>Let&rsquo;s look at the codebase:</p>

<p>{% codeblock lang:ruby lib/puppet/provider.rb %}</p>

<h1>@comment Document prefetch here as it does not exist anywhere else (called from transaction if implemented)</h1>

<h1>@!method self.prefetch(resource_hash)</h1>

<h1>@abstract A subclass may implement this &ndash; it is not implemented in the Provider class</h1>

<h1>This method may be implemented by a provider in order to pre-fetch resource properties.</h1>

<h1>If implemented it should set the provider instance of the managed resources to a provider with the</h1>

<h1>fetched state (i.e. what is returned from the {instances} method).</h1>

<h1>@param resources_hash [Hash&lt;{String => Puppet::Resource}>] map from name to resource of resources to prefetch</h1>

<h1>@return [void]</h1>

<h1>@api public</h1>

<p>{% endcodeblock %}</p>

<p>That&rsquo;s right, documentation for <code>self.prefetch</code> in the Puppet codebase is
9 lines of comments in <code>lib/puppet/provider.rb</code>, which is awesome. So when
is <code>self.prefetch</code> used to provide information to Puppet and when is <code>self.instances</code> used?</p>

<table>
<thead>
<tr>
<th></th>
<th align="center">Puppet Subcommand        </th>
<th align="center"> Provider Method       </th>
<th align="center"> Execution Mode  </th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td align="center"> puppet resource         </td>
<td align="center"> self.instances        </td>
<td align="center"> getting values</td>
</tr>
<tr>
<td></td>
<td align="center"> puppet resource         </td>
<td align="center"> self.prefetch         </td>
<td align="center"> setting values</td>
</tr>
<tr>
<td></td>
<td align="center"> puppet agent            </td>
<td align="center"> self.prefetch         </td>
<td align="center"> getting values</td>
</tr>
<tr>
<td></td>
<td align="center"> puppet agent            </td>
<td align="center"> self.prefetch         </td>
<td align="center"> setting values</td>
</tr>
<tr>
<td></td>
<td align="center"> puppet apply            </td>
<td align="center"> self.prefetch         </td>
<td align="center"> getting values</td>
</tr>
<tr>
<td></td>
<td align="center"> puppet apply            </td>
<td align="center"> self.prefetch         </td>
<td align="center"> setting values  </td>
</tr>
</tbody>
</table>


<p>.</p>

<p>This doesn&rsquo;t mean that <code>self.instances</code> is really only handy for <code>puppet
resource</code> &ndash; that&rsquo;s definitely not the case.  In fact, frequently you will find
that <code>self.instances</code> is used by <code>self.prefetch</code> to do some of the heavy
lifting.  Even though <code>self.prefetch</code> works VERY SIMILARLY to the way that
<code>self.instances</code> works for <code>puppet resource</code> (and by that I mean that it&rsquo;s
going to gather a list of instances of a type on the system, and it&rsquo;s also
going to populate <code>@property_hash</code> for <code>puppet apply</code>, <code>puppet agent</code>, and when
when <code>puppet resource</code> is setting values), it&rsquo;s not an exact one-for-one match
with <code>self.instances</code>.  The <code>self.prefetch</code> method for a type is called once
per run when Puppet encounters a resource of that type in the catalog. The
argument to <code>self.prefetch</code> is a hash of all managed resources of that type
that are encountered in a compiled catalog for that node (the hash&rsquo;s key will
be the <code>namevar</code> of the resource, and the value will be an instance of
<code>Puppet::Type</code> &ndash; in this case, <code>Puppet::Type::Mac_web_proxy</code>).  Your task is to
implement a <code>self.prefetch</code> method that gets an array of instances of the
provider that are discovered on the system, iterates through the hash passed to
<code>self.prefetch</code> (containing all the resources of the type that were discovered
in the catalog), and passes the correct instance of the provider that was
discovered on the system to the <code>provider=</code> method of the correct instance of
the type that was discovered in the catalog.</p>

<p><strong>What the actual fuck?!</strong></p>

<p>Okay, let&rsquo;s break that apart to try and discover exactly what&rsquo;s going on here.
Assume that I&rsquo;ve setup a proxy for the &lsquo;FireWire&rsquo; interface on my laptop, and
I want to try and manage that resource with <code>puppet apply</code> (i.e. something that
uses <code>self.prefetch</code>). The resource in the manifest used to manage the proxy
will look something like this:</p>

<p>{% codeblock lang:puppet %}
mac_web_proxy { &lsquo;firewire&rsquo;:
  ensure       => &lsquo;present&rsquo;,
  proxy_port   => &lsquo;8080&rsquo;,
  proxy_server => &lsquo;proxy.server.org&rsquo;,
}
{% endcodeblock %}</p>

<p>When <code>self.prefetch</code> is called by Puppet, it&rsquo;s going to be passed a hash looking
something like this:</p>

<p>{% codeblock lang:ruby %}
{ &ldquo;firewire&rdquo; => Mac_web_proxy[firewire] }
{% endcodeblock %}</p>

<p>Because only one resource is encountered in the catalog, only one key/value
pair shows up in the hash that&rsquo;s passed as the argument to <code>self.prefetch</code>.</p>

<p>The job of <code>self.prefetch</code> is to find the current state of <code>Mac_web_proxy['firewire']</code>
on the system, create a new instance of the <code>mac_web_proxy</code> provider that contains
the &lsquo;is&rsquo; values for the <code>Mac_web_proxy['firewire']</code> resource, and assign this provider instance as the value
of the <code>provider=</code> method to the instance of the mac_web_proxy TYPE that is the
VALUE of the &lsquo;firewire&rsquo; key of the hash that&rsquo;s passed to <code>self.prefetch</code>.</p>

<p><strong>No, really, that&rsquo;s what it&rsquo;s supposed to do. I&rsquo;m not even sure what&rsquo;s real anymore</strong></p>

<p>You&rsquo;ll remember that <code>self.instances</code> gives us an array of resources that were
discovered on the system, so we have THAT part of the implementation written. We also have the
hash of resources that were encountered in the catalog &ndash; so we have THAT
part done too. Our only job is to connect the dots (la la la la), programmatically
speaking.  This should just about do it:</p>

<p>{% codeblock lang:ruby %}
def self.prefetch(resources)
  instances.each do |prov|</p>

<pre><code>if resource = resources[prov.name]
  resource.provider = prov
end
</code></pre>

<p>  end
end
{% endcodeblock %}</p>

<p>I want to make a confession right now &ndash; I&rsquo;ve only ever copied and pasted this
code into every provider I&rsquo;ve ever written that needed <code>self.prefetch</code> implemented.
It wasn&rsquo;t until someone actually asked me what it DID that I had to walk the path
of figuring out EXACTLY what it did. Based on the last couple of paragraphs &ndash; can
you blame me?</p>

<p>This code iterates through the array of resources returned by <code>self.instances</code>,
tries to assign a variable <code>resource</code> based on referencing a key in the
<code>resources</code> hash using the name of the resource (remember, <code>resources</code> is
a hash containing all resources in the catalog), and, if this assignment works
(i.e. it isn&rsquo;t <code>nil</code>, which is what happens when you reference a key in a Ruby
hash that doesn&rsquo;t exist), then we&rsquo;re calling the <code>provider=</code> method on the
instance of the type that was referenced in the <code>resources</code> hash, and passing
it the resource that was discovered on the system by <code>self.instances</code>.</p>

<p>Wow.</p>

<p>Why <strong>DID</strong> we do all of that?  We did it all for the <code>@provider_hash</code>. Doing
this will populate <code>@provider_hash</code> in all methods of the instance of the
provider (i.e. <code>exists?</code>, <code>create</code>, <code>destroy</code>, etc..) just like <code>self.instances</code>
did for <code>puppet resource</code>.</p>

<h2>Flush it; Ship it</h2>

<p>As I alluded to above, the opposite side of the coin to prefetching (which
is a way to query the state for all resources at once) is flushing (or
specifically the <code>flush</code> method). The <code>flush</code> method is called once per
resource whenever the &lsquo;is&rsquo; and &lsquo;should&rsquo; values for a property differ (and
synchronization needs to occur). The <code>flush</code> method <strong>does not take the place
of property setter methods</strong>, but, rather, is used in conjunction with them
to determine how to synchronize resource property values. In this vein, it&rsquo;s
a single trigger that can be used to set all property values for an individual
resource simultaneously.</p>

<p>There are a couple of strategies for implementing <code>flush</code>, but one of the more
popular ones in use is to create an instance variable that will hold values to
be synchronized, and then determine inside <code>flush</code> how best to make
as-few-as-possible calls to the system to synchronize all the property values
for an individual resource.</p>

<p>Our resource type is unique because the <code>networksetup</code> binary that we&rsquo;ll be
using to synchronize values allows us to set most every property value with
a single command. Because of this, we really only need that instance variable
for one property &ndash; the ensure value.  But let&rsquo;s start with the initialization
of that instance variable for the <code>flush</code> method:</p>

<p>{% codeblock lang:ruby %}
def initialize(value={})
  super(value)
  @property_flush = {}
end
{% endcodeblock %}</p>

<p>The <code>initialize</code> method is magic to Ruby &ndash; it&rsquo;s invoked when you instantiate
a new object. In our case, we want to create a new instance variable &ndash;
<code>@property_flush</code> &ndash; that will be available to all methods of the instance of
the provider. This instance variable will be a hash and will contain all the
&lsquo;should&rsquo; values that will need to be synchronized for a resource. The <code>super</code>
method in Ruby sends a message to the parent of the current object, asking it
to invoke a method of the same name (e.g. <code>intialize</code>).  Basically, the
<code>initialize</code> method is doing the exact same thing as it has always done with
one exception &ndash; making the instance variable available to all methods of the
instance of the provider.</p>

<h3>The only &lsquo;setter&rsquo; method you need</h3>

<p>This provider is going to be unique not only because the <code>networksetup</code>
binary will set values for ALL properties, but because to change/set ANY
property values you have to change/set ALL the property values at the same
time. Typically, you&rsquo;ll see providers that will need to pass arguments to
a binary in order to set individual values.  For example, if you had a
binary <code>fooset</code> that took arguments of <code>--bar</code> and <code>--baz</code> to set values
respectively for <code>bar</code> and <code>baz</code> properties of a resource, you might see the following
setter and flush methods for <code>bar</code> and <code>baz</code>:</p>

<p>{% codeblock lang:ruby %}
def bar=(value)
  @property_flush[:bar] = value
end</p>

<p>def baz=(value)
  @property_flush[:baz] = value
end</p>

<p>def flush
  array_arguments = []
  if @property_flush</p>

<pre><code>array_arguments &lt;&lt; '--bar' &lt;&lt; @property_flush[:bar] if @property_flush[:bar]
array_arguments &lt;&lt; '--baz' &lt;&lt; @property_flush[:baz] if @property_flush[:baz]
</code></pre>

<p>  end
  if ! array_arguments.empty?</p>

<pre><code>fooset(array_arguments, resource[:name])
</code></pre>

<p>  end
end
{% endcodeblock %}</p>

<p>That&rsquo;s not the case for <code>networksetup</code> &ndash; in fact, one of the ONLY places in our code
where we&rsquo;re going to throw a value inside <code>@property_flush</code> is going to be in
the <code>destroy</code> method. If our intention is to ensure a proxy absent (or, in
this case, disable the proxy for a network interface), then we can short-circuit
the method we&rsquo;re going to create to set proxy values by simply checking for
a value in <code>@property_flush[:ensure]</code>. Here&rsquo;s what the <code>destroy</code> method looks like:</p>

<p>{% codeblock lang:ruby %}
def destroy
  @property_flush[:ensure] = :absent
end
{% endcodeblock %}</p>

<p>Next, we need a method that will set values for our proxy. This method will
handle all interaction to <code>networksetup</code>.  So, how do you set proxy values
with <code>networksetup</code>?</p>

<pre><code>networksetup -setwebproxy &lt;networkservice&gt; &lt;domain&gt; &lt;port number&gt; &lt;authenticated&gt; &lt;username&gt; &lt;password&gt;
</code></pre>

<p>The three properties to our <code>mac_web_proxy</code> type are <code>proxy_port</code>, <code>proxy_server</code>,
and <code>proxy_authenticated</code> which map to the &lsquo;&lt;port number>&rsquo;, &lsquo;&lt;domain>&rsquo;,
and &lsquo;&lt;authenticated>&rsquo; values in this command. To change any of these values
means we have to pass ALL of these values (again, which is why our <code>flush</code>
implementation may be unique from other <code>flush</code> implementations). Here&rsquo;s what
the <code>set_proxy</code> method looks like:</p>

<p>{% codeblock lang:ruby %}
def set_proxy
  if @property_flush[:ensure] == :absent</p>

<pre><code>  networksetup(['-setwebproxystate', resource[:name], 'off'])
  return
</code></pre>

<p>  end</p>

<p>  if (resource[:proxy_server].nil? or resource[:proxy_port].nil?)</p>

<pre><code>raise Puppet::Error, "Proxy types other than 'auto' require both a proxy_server and proxy_port setting"
</code></pre>

<p>  end
  if resource[:proxy_authenticated] != :true</p>

<pre><code>networksetup(
  [
    '-setwebproxy',
    resource[:name],
    resource[:proxy_server],
    resource[:proxy_port]
  ]
)
</code></pre>

<p>  else</p>

<pre><code>networksetup(
  [
    '-setwebproxy',
    resource[:name],
    resource[:proxy_server],
    resource[:proxy_port],
    'on',
    resource[:authenticated_username],
    resource[:authenticated_password]
  ]
)
</code></pre>

<p>  end
  networksetup([&lsquo;-setwebproxystate&rsquo;, resource[:name], &lsquo;on&rsquo;])
end
{% endcodeblock %}</p>

<p>This helper method does all the validation checks for required properties,
executes the correct command, and enables the proxy. Now, let&rsquo;s implement
<code>flush</code>:</p>

<p>{% codeblock lang:ruby %}
def flush
  set_proxy</p>

<p>  # Collect the resources again once they&rsquo;ve been changed (that way <code>puppet
  # resource</code> will show the correct values after changes have been made).
  @property_hash = self.class.get_proxy_properties(resource[:name])
end
{% endcodeblock %}</p>

<p>The last line re-populates <code>@property_hash</code> with the current resource values,
and is necessary for <code>puppet resource</code> to return correct values after it
makes a change to a resource during a run.</p>

<h3>The final method</h3>

<p>We&rsquo;ve implemented logic to query the state of all resources, to prefetch those
states, to make changes to all properties at once, and to destroy a resource
if it exists, but we&rsquo;ve yet to implement logic to CREATE a resource if it
doesn&rsquo;t exist and it should.  Well, this is a bit of a lie &ndash; the logic is in
the code, but we don&rsquo;t have a <code>create</code> method, so Puppet&rsquo;s going to complain:</p>

<p>{% codeblock lang:ruby %}
def create
  @property_flush[:ensure] = :present
end
{% endcodeblock %}</p>

<p>Technically, this method doesn&rsquo;t have to do a DAMN thing. Why? Remember how the
<code>flush</code> method is triggered when a resource&rsquo;s &lsquo;is&rsquo; values differ from its
&lsquo;should&rsquo; values? Also, remember how the <code>flush</code> method only calls the <code>set_proxy</code>
method? And, finally, remember how <code>set_proxy</code> only checks if
<code>@property_flush[:ensure] == :absent</code> (and if it doesn&rsquo;t, then it goes about
its merry way running <code>networksetup</code>)?  Right, well add these things up and
you&rsquo;ll realize that the <code>create</code> method is essentially meaningless based on our
implementation (but if you OMIT <code>create</code>, then Puppet&rsquo;s going to throw a shit-fit
in the shape of of a <code>Puppet::Error</code> exception):</p>

<pre><code>Error: /Mac_web_proxy[firewire]/ensure: change from absent to present failed: Could not set 'present' on ensure: undefined method `create' for Mac_web_proxy[firewire]:Puppet::Type::Mac_web_proxy
</code></pre>

<p>So make Puppet happy and write the goddamn <code>create</code> method, okay?</p>

<h2>The complete provider:</h2>

<p>Wow, that was a wild ride, huh?  If you&rsquo;ve been coding along, you should have
created a file that looks something like this:</p>

<p>{% codeblock lang:ruby lib/puppet/provider/mac_web_proxy/ruby.rb %}
Puppet::Type.type(:mac_web_proxy).provide(:ruby) do
  commands :networksetup => &lsquo;networksetup&rsquo;</p>

<p>  mk_resource_methods</p>

<p>  def initialize(value={})</p>

<pre><code>super(value)
@property_flush = {}
</code></pre>

<p>  end</p>

<p>  def self.get_list_of_interfaces</p>

<pre><code>interfaces = networksetup('-listallnetworkservices').split("\n")
interfaces.shift
interfaces.sort
</code></pre>

<p>  end</p>

<p>  def self.get_proxy_properties(int)</p>

<pre><code>interface_properties = {}

begin
  output = networksetup(['-getwebproxy', int])
rescue Puppet::ExecutionFailure =&gt; e
  Puppet.debug "#get_proxy_properties had an error -&gt; #{e.inspect}"
  return {}
end

output_array = output.split("\n")
output_array.each do |line|
  line_values = line.split(':')
  line_values.last.strip!
  case line_values.first
  when 'Enabled'
    interface_properties[:ensure] = line_values.last == 'No' ? :absent : :present
  when 'Server'
    interface_properties[:proxy_server] = line_values.last.empty? ? nil : line_values.last
  when 'Port'
    interface_properties[:proxy_port] = line_values.last == '0' ? nil : line_values.last
  when 'Authenticated Proxy Enabled'
    interface_properties[:proxy_authenticated] = line_values.last == '0' ? nil : line_values.last
  end
end

interface_properties[:provider] = :ruby
interface_properties[:name]     = int.downcase
Puppet.debug "Interface properties: #{interface_properties.inspect}"
interface_properties
</code></pre>

<p>  end</p>

<p>  def self.instances</p>

<pre><code>get_list_of_interfaces.collect do |int|
  proxy_properties = get_proxy_properties(int)
  new(proxy_properties)
end
</code></pre>

<p>  end</p>

<p>  def create</p>

<pre><code>@property_flush[:ensure] = :present
</code></pre>

<p>  end</p>

<p>  def exists?</p>

<pre><code>@property_hash[:ensure] == :present
</code></pre>

<p>  end</p>

<p>  def destroy</p>

<pre><code>@property_flush[:ensure] = :absent
</code></pre>

<p>  end</p>

<p>  def self.prefetch(resources)</p>

<pre><code>instances.each do |prov|
  if resource = resources[prov.name]
    resource.provider = prov
  end
end
</code></pre>

<p>  end</p>

<p>  def set_proxy</p>

<pre><code>if @property_flush[:ensure] == :absent
    networksetup(['-setwebproxystate', resource[:name], 'off'])
    return
end

if (resource[:proxy_server].nil? or resource[:proxy_port].nil?)
  raise Puppet::Error, "Both the proxy_server and proxy_port parameters require a value."
end
if resource[:proxy_authenticated] != :true
  networksetup(
    [
      '-setwebproxy',
      resource[:name],
      resource[:proxy_server],
      resource[:proxy_port]
    ]
  )
else
  networksetup(
    [
      '-setwebproxy',
      resource[:name],
      resource[:proxy_server],
      resource[:proxy_port],
      'on',
      resource[:authenticated_username],
      resource[:authenticated_password]
    ]
  )
end
networksetup(['-setwebproxystate', resource[:name], 'on'])
</code></pre>

<p>  end</p>

<p>  def flush</p>

<pre><code>set_proxy

# Collect the resources again once they've been changed (that way `puppet
# resource` will show the correct values after changes have been made).
@property_hash = self.class.get_proxy_properties(resource[:name])
</code></pre>

<p>  end
end
{% endcodeblock %}</p>

<p>Undoubtedly there are better ways to write this Ruby code, no? Also, I&rsquo;m SURE
I have some errors/bugs in that code. It&rsquo;s those things that keep me in a job&hellip;</p>

<h2>Final Thoughts</h2>

<p>So, I write these posts not to belittle or mock anyone who works on Puppet
or wrote any of its implementation (except the amazing/terrifying bastard who
came up with <code>self.prefetch</code>). Anybody who contributes to open source and who
builds a tool to save some time for a bunch of sysadmins is fucking awesome
in my book.</p>

<p>No, I write these posts so that you can understand the <strong>&lsquo;WHY&rsquo;</strong> piece of the
puzzle. If you fuck up the <strong>&lsquo;HOW&rsquo;</strong> of the code, you can spend some time in
Google and IRB to figure it out, but if you don&rsquo;t understand the <strong>&lsquo;WHY&rsquo;</strong>
then you&rsquo;re probably not going to even bother.</p>

<p>Also, selfishly, I move from project to project so quickly that it&rsquo;s REALLY
easy to forget both why AND how I did what I did. Posts like these give me
someplace to point people when they ask me &ldquo;What&rsquo;s <code>self.prefetch</code>?&rdquo; that
ISN&rsquo;T just the source code or a liquor store.</p>

<p>This isn&rsquo;t the last post in the series, by the way. I haven&rsquo;t even TOUCHED
on writing unit tests for this code, so that&rsquo;s going to be a WHOLE other
piece altogether. Also, while this provider manages a <strong>WEB</strong> proxy for
a network interface, understand that there are MANY MORE kinds of proxies
for OS X network interfaces (including socks and gopher!). A future post
will show you how to refactor the above into a parent provider that can
be inherited to allow for code re-use among all the proxy providers that I
need to create.</p>

<p>As always, you&rsquo;re more than welcome to comment, ask questions, or simply bitch
at me both on this blog as well as <a href="http://www.twitter.com/glarizza">on Twitter: @glarizza</a>. Hopefully
this post helped you out and you learned a little bit more about how Puppet
providers do their dirty work&hellip;</p>

<p>Namaste, bitches.</p>
]]></content>
  </entry>
  
</feed>
