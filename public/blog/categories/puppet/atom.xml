<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: puppet | Shit Gary Says]]></title>
  <link href="http://garylarizza.com/blog/categories/puppet/atom.xml" rel="self"/>
  <link href="http://garylarizza.com/"/>
  <updated>2015-11-16T13:13:46-08:00</updated>
  <id>http://garylarizza.com/</id>
  <author>
    <name><![CDATA[Gary larizza]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Workflows Evolved: Even Besterer Practices]]></title>
    <link href="http://garylarizza.com/blog/2015/11/16/workflows-evolved-even-besterer-practices/"/>
    <updated>2015-11-16T07:00:24-08:00</updated>
    <id>http://garylarizza.com/blog/2015/11/16/workflows-evolved-even-besterer-practices</id>
    <content type="html"><![CDATA[<p>It&rsquo;s nearly been two years since I posted the Puppet Workflow series and
several things have changed:</p>

<ul>
<li>R10k now ships with Puppet Enterprise and <a href="http://docs.puppetlabs.com/pe/latest/r10k.html">there are docs for it!</a></li>
<li>There&rsquo;s even a <a href="http://docs.puppetlabs.com/pe/latest/r10k_config_console.html"><code>pe_r10k</code> module</a> that ships with Puppet Enterprise 2015.2.x and higher to configure R10k</li>
<li><a href="https://github.com/puppetlabs/control-repo">Control repos are the standard and are popping up all over the place</a></li>
<li>Most people are bundling Hiera data with their Control repo (unless they have a very good reason not to)</li>
<li>Ditto for Roles and Profiles</li>
<li>The one-role-per-node rule is a good start, but PE&rsquo;s rules-based classification engine allows us to relax that rule</li>
<li>Roles still include Profiles, but conditional logic is allowed and recommended to keep Hiera hierarchy levels minimal</li>
<li>&lsquo;Data&rsquo; goes in Hiera, but the definition of &lsquo;data&rsquo; changes between organizations</li>
<li>There&rsquo;s now a (somewhat) defined path for whether &lsquo;data&rsquo; is included in a profile or Hiera</li>
<li>Automatic Parameter Lookup + Hiera&hellip;it&rsquo;s still hard to debug, but we&rsquo;re getting there</li>
<li>I&rsquo;m incredibly wary of taking Uber during peak travel times with rate multipliers</li>
</ul>


<p>It&rsquo;s been awhile since I&rsquo;ve had a good rant, so let&rsquo;s get right into it!</p>

<h2>Code Management with R10k</h2>

<p>As of PE 3.8, R10k became bundled with Puppet Enterprise (PE) and was referred
to as &ldquo;Code Management&rdquo; which initially confused people because the only thing
about PE that was changed was that the R10k gem was preinstalled into PE&rsquo;s Ruby
installation.  The purpose of this act was twofold:</p>

<ol>
<li>The Professional Services team was installing R10k in essentially EVERY services engagement, and so it made sense to ship R10k and thus officially support its installation</li>
<li>We&rsquo;ve always had plans to keep the functionality that R10k provided but not NECESSARILY the tool-known-as-R10k, so calling the service it provided something OTHER than R10k would allow us to swap out the implementation underneath the hood while still being able to talk about the functionality it provided</li>
</ol>


<p>Of course, if you didn&rsquo;t live inside Puppet Labs it&rsquo;s possible that you might not have gotten this
memo, but, hey: better late than never?</p>

<p>For various reasons, we also never initially shipped a PE-specific module to
configure R10k, so you ALSO had to either manually setup <code>r10k.yaml</code> or use
<a href="https://github.com/acidprime/r10k">Zack Smith&rsquo;s R10k module</a> to manage that file. Of course, that
module did all kinds of OTHER things (like installing the R10k gem, setting up
webhooks, and making my breakfast), which meant that if you used it with the
version of PE that shipped R10k, you had to be careful to use the version of
the module that didn&rsquo;t ALSO try to upgrade that gem on your system (and whoops
if the module actually upgraded the version of R10k that we shipped). This is
why that module is Puppet Approved but not an offical Puppet Labs module: it
does things that we would consider &ldquo;unsupported&rdquo; outside of a professional
services engagement (i.e. the webhook stuff). Finally, the path to
<code>r10k.yaml</code> was changed to <code>/etc/puppetlabs/r10k/r10k.yaml</code>, but, in its
absence, the old path of <code>/etc/r10k.yaml</code> would be used and a message would
be displayed to inform you of the new file path (in the case that both files
were present, the file at <code>/etc/puppetlabs/r10k/r10k.yaml</code> would win).</p>

<p>When PE version 2015.2.0 shipped (I&rsquo;m still not used to these version numbers
either, folks), we FINALLY shipped a <code>pe_r10k</code> module with similar structure to
Zack&rsquo;s R10k module &ndash; this meant you could FINALLY setup R10k immediatly without
having to install additional Puppet modules. Even better(er), in PE 2015.2.2 we
expose <a href="http://docs.puppetlabs.com/pe/latest/r10k_config_answers.html">a couple of PE installer answer file questions</a> that allow
you to configure R10k DURING INSTALL TIME &ndash; so now your servers could be
immediately bootstrapped with a single answers file (seriously, I know, it&rsquo;s
about time; I do this shit every week, you have no idea). It finally feels like
R10k has grown into the first-class citizen we all wanted it to be!</p>

<p>Which means it&rsquo;s time to dump it.</p>

<p>I kid. Mostly. The fact of the matter is that we&rsquo;re introducing a new service
to manage code within Puppet Enterprise, <a href="https://puppetlabs.com/blog/managing-infrastructure-as-code-now-easier-than-ever">and if you&rsquo;re interested in reading more about it, check out this blog post by Lindsay Smith about Code Manager.</a>
For you, the consumer, the process will be the same: you have a control
repo, you push changes, a service is triggered on your Puppet masters, and code
is synchronized on the Puppet master. What WILL change is the setup of this tool
(there will still be PE installer answer file questions that allow you to configure
this service, don&rsquo;t fret, and you&rsquo;ll still be able to configure this service through
a Puppet module, but the name of said module and configuration files on disk
will probably be different. Welcome to IT).</p>

<p>Be on the lookout for this service, and, as always, check out the <a href="http://docs.puppetlabs.com">PE docs site</a> for
more information on the Code Management service.</p>

<h2>Control (repo) freak</h2>

<p>With the explosion of R10k came the explosion of &ldquo;Control Repos&rdquo; all over the place.
Everyone had one, everyone had an opinion on what worked best, and, well, we didn&rsquo;t
really do a good job at offering a good startup control repo for you. Because of
that, <a href="https://github.com/puppetlabs/control-repo">we recently posted a &lsquo;starter&rsquo; control repo on Github</a> in the Puppet Labs
namespace that could be used to get started with R10k. Yes, it&rsquo;s definitely long
overdue, but there it is! I use it on all engagements I do with new customers, so
you can guarantee it&rsquo;ll have the use of Puppet Labs' PS team behind it. If you&rsquo;ve
not started with R10k yet (or if you have but you wanna see what kinda crazy shit
we&rsquo;re doing now), check it out. It&rsquo;s got great stuff in there like a config_version
script to spit out the most recent commit of the current branch of the control repo
(read: also current Puppet environment) as the &ldquo;Config Version&rdquo; string that Puppet
prints out during every Puppet run (<a href="https://docs.puppetlabs.com/puppet/latest/reference/config_file_environment.html#configversion">see here for more info on this functionality</a>).
We&rsquo;re also slowly adding things like inital bootstrapping profiles that will do
things like configure R10k/Code Manager, manage the SSH key necessary to contact
the control repo (should you be using an internal git repository server and
also require an SSH key to access that repo), and so on. Star that repo and keep
checking back, especially around PE releases, to see if we&rsquo;ve updated things in
a way that will help you out!</p>

<h2>&ldquo;Just put it in the control repo&rdquo;</h2>

<p>Look, if there&rsquo;s one thing that my blog emphasizes (other than the fact that I&rsquo;ve
got a hairpin trigger for cursing and an uncomfortable Harry Potter fetish) it&rsquo;s
that &ldquo;best practices&rdquo; are inversely related to the insecurities of the speaker.
Fortunately, I have no problem saying when I&rsquo;m wrong. If you&rsquo;ve got the time,
allow me my mea culpa moment. In the past I had recommended:</p>

<ul>
<li>Using a separate git repo for Hiera data</li>
<li>Using separate git repos for Roles and Profiles</li>
<li>The Dave Matthews Band</li>
</ul>


<p>Time, experience, and the legalization of recreational marijuana in Oregon have
helped me see the error in my ways (though, look, #41 is a good goddamn song,
especially on the Dave &amp; Tim Live at Luther College album), so allow me to provide
some insight into WHY I&rsquo;ve reconsidered my message(s)&hellip;</p>

<h3>Hiera Data</h3>

<p>In the past, I recommended a separate git repo for Hiera data along with
a separate entry in <code>r10k.yaml</code> that would allow R10k to clone the Hiera data repo
along the same vein as the control repo. The pro was that a separate Hiera data
repo would afford you different access rights to this repo as you would the
control repo (especially if different people needed different access to each
function). The con was that now the branch structure of your Hiera data repo
needed to EXACTLY MIRROR the structure of your control repo&hellip;.even if certain
branches had EXACTLY THE SAME Hiera data and no changes were necessary.</p>

<p>Puppet has enough moving parts, why did we need to complicate this if most
people didn&rsquo;t care about access levels differing between the two repos? The
solution was to bundle the Hiera data inside the control repo all the way up
until you had a specific need to split it out. Truth be told both methods
work with Puppet, so the choice is up to you (read: I DON&rsquo;T CARE WHICH METHOD
YOU USE OH MY GOD WILL YOU QUIT TRYING TO PICK A FIGHT WITH ME OVER THIS LOL) :)</p>

<p>Finally, there&rsquo;s an added benefit of putting this data inside the control repo,
and it&rsquo;s ALSO the reason for the next recommendation&hellip;</p>

<h3>Roles and Profiles</h3>

<p>This is one that I actually fought when someone suggested it&hellip;I even started to
recommend that a customer NOT do the thing I&rsquo;m about to recommend to you until they
very eloquently explained why they did it. In the end, they were right, and I&rsquo;m
passing this tip on to you:  Unless you have a very specific reason NOT to,
put your &lsquo;roles&rsquo; and &lsquo;profiles&rsquo; modules in your control repo.</p>

<p>Here&rsquo;s the thing about the control repo &ndash; you can set a post-receive hook on
the repository (or setup a Jenkins/Bamboo/whatever job) that will update all your
Puppet masters whenever changes are pushed to the remote git repository (i.e.
your git repository server). This means that anytime the control repo is updated
your Puppet masters will be updated. That&rsquo;s why it&rsquo;s CALLED the control repo &ndash; it
effectively CONTROLS your Puppet masters.</p>

<p>Understanding THAT, think about when you want your Puppet masters updated? Well,
you usually want to update them when you&rsquo;re testing something out &ndash; you made a
change to a couple of modules, then a profile (and possibly also a role), and
now you wanna see if that code works on more than just your local laptop.
But the Puppet landscape has changed a bit as the Puppet Forge has matured &ndash; most
people are using modules off the Forge and are at least TRYING not to use their
own component modules. This means that changes to your infrastructure are being
controlled from within roles/profiles. But even IF you&rsquo;re one of those people
who aren&rsquo;t using the Forge or who have to update an internal component module,
you&rsquo;re probably not wanting to update all your Puppet masters every time you
update a component module. There&rsquo;s probably lots of tinkering there, and every
change isn&rsquo;t &ldquo;update-worthy&rdquo;. Conversely, changes to your profiles probably
ARE &ldquo;update-worthy&rdquo;: &ldquo;Okay, let&rsquo;s pull this bit from Hiera, pass it as a parameter,
and now I&rsquo;m ready to check it out on a couple of machines.&rdquo;</p>

<p>If your roles and profiles modules are separate from your control repo, you
end up having to push changes to, say, a class in the profiles module, then
updating the Puppetfile in the control repo, then trigger an R10k run/sync.
If things aren&rsquo;t correct, you end up changing the profile, pushing that change
to the profile repo, and THEN having to trigger an R10k run/sync (and if you
don&rsquo;t have SSH access to your masters, you have to make a dummy commit to the
control repo so it triggers an R10k run OR doing a curl to some endpoint that
will update your Puppet master for you). That last step is the thing that ends
up wasting a bit of your time: why do we need to push a profile and then manually
do an R10k run of we&rsquo;ve established that roles and profiles will pretty much
ALWAYS be &ldquo;update-worthy&rdquo;? We don&rsquo;t. If you put the roles and profiles module
inside the control repo, then it will automatically update your Puppet masters
every time you make a change to one or the other. Bam &ndash; step saved. ALSO, if
you do this, you can take Roles/Profiles out of Puppetfile, which means you
no longer need to pin them! No more will you have to tie that module to a topic
branch during development time: just create a branch of the control repo and
go to town!  Wow, that saves even more time! I&rsquo;m uncomfortable with this level
of excitement!</p>

<p>The one thing you WILL need to do is to update <code>environment.conf</code> so that it
knows to look for the roles/profiles modules in a different path from all the
other modules (because removing it from Puppetfile means that it will no longer
go to the same modulepath as every other module managed inside Puppetfile).
For the purposes of cleanliness, we usually end up putting both roles/profiles
inside a <code>site</code> folder in the control repo. If you do that, your modulepath
in <code>environment.conf</code> looks a little something like this:</p>

<p>{% codeblock %}
modulepath = site:modules:$basemodulepath
{% endcodeblock %}</p>

<p>This means that Puppet will look for modules first in the &lsquo;site&rsquo; directory of
its current environment (this is the directory where we put roles/profiles),
and then inside the &lsquo;modules&rsquo; directory (this is where modules managed in Puppetfile
are cloned by default), and then in $basemodulepath (i.e. modules common to all
environments and also modules that Puppet Enterprise ships).</p>

<p>LOOK, BEFORE YOU FREAK OUT, YES, SITE COMES FIRST HERE, AND OTHER PEOPLE HAVE
SITE COME SECOND! Basically, if you have roles/profiles in the &lsquo;site&rsquo; directory
AND you manage to still have the module in Puppetfile, then the module in the &lsquo;site&rsquo;
directory will win. Feel free to flip/flop that if you want.</p>

<p><strong>TL;AR: (yes, you already read all of this so it&rsquo;s futile) put roles/profiles
inside the site directory of the control repo to save you time, but also don&rsquo;t
do it if you have a specific reason not to&hellip;or if you like being contrarian.</strong></p>

<h3>Dave Matthews</h3>

<p>The &ldquo;Everyday&rdquo; album was the &ldquo;jump the shark&rdquo; moment for the Dave Matthews band,
while the leaked &ldquo;Lillywhite Sessions&rdquo; that would largely make it to &ldquo;Busted Stuff&rdquo;
definitely indicated where the band wanted to go. They never recovered after that,
and, just like Boone&rsquo;s Farm &lsquo;wine&rsquo;, I stopped partaking in them.</p>

<p>Also, not ONCE did being able to play most every Dave Matthews song on the
acoustic guitar ever get me laid&hellip;though I can&rsquo;t tell exactly whose fault that
was. On second thought, that was probably me. Though Tim Reynolds is an absolute
beast of a musician; I&rsquo;m still #teamtim.</p>

<h2>One role per node, until you don&rsquo;t want to</h2>

<p>Why do we even make these rules if you&rsquo;re not gonna follow them? It&rsquo;s getting
awfully &ldquo;Who&rsquo;s Line Is It Anyways?&rdquo; up in here. Before PE 3.7, and its
rules-based classification engine, we recommended not assigning more than one
role to a node.  Why? Well, the Puppet Enterprise Console around that time
wasn&rsquo;t the best at tracking changes or providing authentication around tasks
like classification.  This meant if you tried to manage ALL of your
classification within the console you could have a hard time telling when
things changed or why. Fortunately, git provides you with this functionality.
Because of that, we (and when I say &lsquo;we&rsquo; I mean &lsquo;everyone in the field trying
to design a Puppet workflow that not only made sense but also had some level of
accountability&rsquo;) tried to displace most classification tasks from the Console
into flat files that could be managed with git. This is largely the impetus for
Roles and Profiles when you think about it: Profiles connect Puppet to external
ata and give you a layer to express dependencies between multiple Puppet
classes, and Roles is a mechanism for boiling down classification to a single
unit.</p>

<p>Once we launched a new Node Classifier that had a rules-based classification
engine AND role-based authentication control, we became more comfortable
delegating some of these classification tasks BACK to the console. The Node
Classifier ALSO made it easy to click on a node and not only see what was
classified to that node, but also WHERE it got that bit of classification
from (&ldquo;This node is getting the JBoss profile because it was put into the
App Servers nodegroup&rdquo;). With that level of accountability, we could start
relaxing our &ldquo;One Role Per Nodeâ„¢&rdquo; mandate, OR eliminate the roles module
altogether (and use nodegroups in the Node Classifier in place of roles).</p>

<p>The goal has always been to err on the side of &ldquo;debugability&rdquo; (I like making words).
I will usually try to optimize a task for tracing errors later, because I&rsquo;ve been
a sysadmin where the world is falling apart around you and you need to quickly
determine what caused this mess. Using one role per node makes sense if you
don&rsquo;t use a node classifier that gives you this flexibility, but MIGHT not if
you DO use a classifier that has some level of accountability.</p>

<h2>Roles, conditional logic, Hiera, and you</h2>

<p>Over time as I&rsquo;ve talked to people that ended up building Puppet workflows
based on the things I&rsquo;ve written (which still feels batshit crazy to me,
by the way, since I&rsquo;ve known myself for over 34 years), I&rsquo;ve noticed that people
seem to take the things I say VERY LITERALLY. And to this I say: &ldquo;You should
probably send me money via Paypal.&rdquo; Also &ndash; note that I&rsquo;m writing these things
to address the 80% of people out there using/getting started with Puppet. You
don&rsquo;t HAVE to do what I say, especially if you have a good reason not to, and
you SHOULDN&rsquo;T do what I say, especially if you&rsquo;re the one that&rsquo;s going to stay
with that organization forever and manage the entire Puppet deployment. For
everyone else out there, let&rsquo;s talk some more about roles.</p>

<p>The talking points around roles has always been &ldquo;Roles include profiles; that&rsquo;s it.&rdquo;
Again, going back to the idea that roles exist to support classification, this
makes sense &ndash; you don&rsquo;t want to add resources at a very high level like a roles
class because, well, honestly, there&rsquo;s probably a better place for it, but any
logic added to simply classification is a win.</p>

<p>Consider an organization that has both Windows and Linux application servers.
The question of whether to have separate roles for Linux and Windows
application servers is always one of the first questions to be surfaced. At
a low level, everything you do in a Puppet manifest is solely for the
purpose of getting resources into the catalog (a JSON object containing
a list of all resource Puppet is to be managing ond their desired end-state).
Whether you have two different roles matters not to Puppet so long as the
right node gets the right catalog. For a Puppet developer writing code, having
two separate roles also might not matter (and, in reality, based on the amount
of code assigned to either role, it might be cleaner to have different roles
for each). For the person in charge of classifying nodes with their assigned
role, it&rsquo;s probably easier to have a single role (<code>roles::application_server</code>, for example)
that can be assigned to ALL application servers, and then logic inside the role
to determine whether this will be a Windows application server using IIS or
a Linux application server using JBoss (or, going further, a Linux application
server running Weblogic, or Websphere, or Tomcat, whatever). Like we mentioned
in the previous point, if you&rsquo;re using the &ldquo;One role per node&rdquo; philosophy, then
you probably want a single role with conditional logic to determine Windows/Linux,
and then determine Tomcat/JBoss, and so on. If you&rsquo;re using the Puppet Enterprise
Console&rsquo;s node classifier, and thus the rule-based engine, you can afford not
to care about the number of node groups you create because you can create a rule
to match for application servers, and then a rule to match on operating system,
and create as many rules as you want to dynamically discover and classify nodes
on the fly.</p>

<p>The point here is that the PURPOSE of the Role is to aid classification, and
the focus on creating a role is to start small, use conditional logic to
determine which profiles to include, and then simply include them. If that
conditional logic uses Facter facts, awesome. If you need to look at a variable
coming from the Console to do the job, fine &ndash; go for it! But if you&rsquo;re using
the Role as a substitute for a Profile (i.e. data lookups, declaring classes,
even declaring resources), then you&rsquo;re probably going down a path that&rsquo;s gonna
make it confusing for people follow what&rsquo;s going on.</p>

<p>Bottom line: technology-agnostic roles that utilize conditional logic around
including profiles is a win, but keep tasks like declaring resources and
component modules to Profiles. Doing this provides a top-down path for
debugging and a cleaner overall Puppet codebase.</p>

<h2>What the hell is &lsquo;Data&rsquo; anyhow?</h2>

<p>This point has single-handedly caused more people to come up and argue with me.
I&rsquo;m not kidding. I shit you not, I&rsquo;ve had people legitimately *SCREAM* at me
about how wrong I was with my opinions here. The cool thing is that people LOVE
the idea of Hiera &ndash; it lets you keep the business-specific data out of your
Puppet manifests, it&rsquo;s expressed in YAML and not the Puppet DSL, and when it
works, it&rsquo;s magical.</p>

<p>The problem is that it&rsquo;s fucking magical. Seriously.</p>

<p>So what IS a good use of Hiera? Anytime you have a bit of data that is subject
to override (for example: the classical NTP problem where everyone should use
the generic company NTP server, except nodes at this location should use a
different NTP server, and this particular node should use ITSELF as its NTP
server), that bit of data goes into Hiera (and by &lsquo;that bit of data&rsquo;, I mean
&lsquo;the value of the NTP server&rsquo; or &lsquo;the NTP server&rsquo;s FQDN&rsquo;), which would look
SOMETHING like this:</p>

<p>{% codeblock lang:yaml %}
ntpserver: pool.ntp.org
{% endcodeblock %}</p>

<p>What does NOT go into Hiera is a hash-based representation of the Puppet
resource that would then be passed to create_resources() and used to create
the resource in the catalog&hellip;which would look something like this:</p>

<p>{% codeblock lang:yaml %}
ntpfiles:
  &lsquo;/etc/ntp/ntpd.conf&rsquo;:</p>

<pre><code>ensure: file
owner:  0
group:  0
mode:   0644
source: 'puppet:///modules/ntp/ntpd.conf'
</code></pre>

<p>{% endcodeblock %}</p>

<p>&hellip;which would then be passed into Puppet like this:</p>

<p>{% codeblock lang:puppet %}
create_resources(&lsquo;file&rsquo;, hiera_hash(&lsquo;ntpfiles))
{% endcodeblock %}</p>

<p>Yes, this is an exaggeration based on a very narrow use case, but what I&rsquo;m trying
to highlight is that the &lsquo;data&rsquo; bit in all that above mess is SOLELY an FQDN,
and everything else is arguably the &ldquo;Model&rdquo;, or your Puppet code.</p>

<p>Organizations LOVE that you can put as much &ldquo;stuff&rdquo; into Hiera as you want and
then Puppet can call Hiera, create resources based on what it tells you, and
merrily be on your way. Well, they &ldquo;love&rdquo; it until it doesn&rsquo;t work or does
something unexpected, and then debugging Hiera is a right bastard.</p>

<p>Understand that the problem I have would be with unexpected Hiera behavior. If
you&rsquo;re skilled in the ways of the Hiera and its (sometimes cloudy) interaction
with Puppet, then by ALL means use it for whatever ya like. BUT, if you&rsquo;re
still new to Puppet, then you may have a very loose mental map for how Hiera
works and where it interacts with Puppet&hellip;and nobody should have to have that
advanced level of knowledge just to debug the damn thing.</p>

<p>The Hiera + create_resources() use above is of particular nastiness simply
because it turns your Hiera YAML files into a potential mechanized weapon of Puppet
destruction.  If I know that you&rsquo;re doing this under the hood, I could
POTENTIALLY slip data into Hiera that would end up creating resources on a node
to do what I want. Frequently Puppet code is more heavily scrutinized than
Hiera data, and I could see something like this getting overlooked (especially
if you don&rsquo;t have a ton of testing around your Puppet code before it gets
deployed).</p>

<p>The REASON why create_resources() was created was because Puppet lacked the
ability to do things like recursion and loops inside the DSL, and sometimes
you WANT to automate very repeated tasks. Consider the case where you truly
DON&rsquo;T know how many of something is going to be on a node ahead of time &ndash; maybe
you&rsquo;re using VMware vRO/vRA and someone is building a node on-the-fly with
the web GUI. For every checkbox someone ticks there will be another application
to be installed, or another series of firewall rules, or SOMETHING like that.
You can choose to model these individually with profiles, OR, if the task is
repetitive, you can accept their choices as data and feed it back into Puppet
like a defined resource type. In fact, most use-cases for Hiera + create_resources()
is passing data into a defined resource type. As of Puppet 4.x.x, we have
looping constructs inside the DSL, so we can finally AUTOMATE these tasks
without having to use an extra function (of course, in THIS use case, whether
you use recursion/looping in the DSL or create_resources() matters not &ndash; you
get the same thing in the end).</p>

<p>For one last point, the Puppet DSL is still pretty easy to read (as of right now),
and most people can follow what&rsquo;s going on even if they&rsquo;re NOT PuppEdumicated.
Having 10 resource declarations in a row seems like a pain in the ass to write
when you&rsquo;re doing it, but READING it makes sense. Later on, if you need to know
what&rsquo;s going on with this profile, you can scan it and see exactly what&rsquo;s there.
If you start slipping lots of data into Hiera and looping logic into the DSL,
you&rsquo;re gonna force the person who manages Puppet to go back and forth between
reading Hiera code, then back to Puppet code, then back to the node, and so on.
Again, it&rsquo;s totally possible to do now, and frequently NECESSARY when you have
a more complex deployment and well-trained Puppet administrators, but initially
it&rsquo;s possible to build your own DSL to Puppet by slipping things into Hiera and
running away laughing.</p>

<p>So when do I put this &lsquo;data&rsquo; into the Profile and when is a good time to put it
into Hiera?  I&rsquo;m glad you asked&hellip;</p>

<h2>A path to Hiera data</h2>

<p>These last two points I&rsquo;ve written about before. I may be repeating myself, but
bytes are cheap. Like I wrote above (and before), putting data directly into a
Profile is the easiest and most legible way of providing &ldquo;external data&rdquo; into
Puppet. Yes, you&rsquo;ll argue, putting the data into a Profile, which is Puppet code,
is ARGUABLY NOT being very &ldquo;external&rdquo; about it. In my opinion it is &ndash; your Profile
is YOUR IMPLEMENTATION of a technology stack, and thus isn&rsquo;t going to be shared
outside your organization. I consider that external to all the component modules
out there, but, again, potato/potato. I recommend STARTING HERE when you&rsquo;re getting
started with Puppet. Hiera comes in when you have a very clear-cut need for
overriding data (a la: this NTP server everywhere, except here and here). The second
you might need to have different data, you can either start building conditional logic
inside the Profile, OR use the conditional logic that Hiera provides.</p>

<p>So &ndash; which do you use?</p>

<p>The point of Hiera is to solve 80% or better of all conditional choices in your
organization. Consider this data organization model:</p>

<ul>
<li>Everyone shares most of the same data items</li>
<li>San Francisco/London do their own things sometimes</li>
<li>Application tiers get their own level for dev/test/qa/prod-specific overrides</li>
<li>Combinations of tiers/locations/and business units want their own overrides</li>
<li>Node specific data is the most specific (and least-used) level</li>
</ul>


<p>If you&rsquo;re providing some data to Puppet that follows this model, then cool
&ndash; use Hiera. What about specific &ldquo;exceptions&rdquo; that don&rsquo;t fit this model? Do you
try to create specialized layers in Hiera just for these exceptions? Certain
organizations absolutely do &ndash; I see it all the time. What you find is that
certain layers in Hiera go together (this location/tier/business_unit level
goes right above location/tier, which goes right above location), and we
start referring to those coupled layers as &ldquo;Chains&rdquo;. Chains are usually tied
to some specific need (deploying applications, for example). Sometimes you
create a chain just to solve a VERY SPECIFIC hard problem (populating
<code>/etc/sudoers</code> in large organizations, for example).</p>

<p>The question is &ndash; do I create another &ldquo;Chain&rdquo; of layers in the hierarchy
solely because deploying <code>sudoers</code> is hard, or do I throw a couple of case
statements into the <code>sudoers</code> profile and keep it out of Hiera altogether?</p>

<p>My answer is to start with conditional logic in the <code>sudoers</code> profile and break
it out into Hiera if you see that &ldquo;Chain&rdquo; being needed elsewhere. Why? Because, like
I&rsquo;ve said many times before, debugging Hiera kinda sucks right now &ndash; there&rsquo;s no
way currently to get a dump of all variables and parameters for a particular node
and determine which were set by Hiera, which were set with variables in the DSL, which
came out of the console, and so on. If we HAD that tool, I&rsquo;d be all about using
it and polluting your hierarchy all day long (I expand upon this slightly in the
next point about the Automatic Parameter Lookup + Hiera).</p>

<p>Bottom line: Start with the data in the Profile, then move it to Hiera when you
need to override. Start with conditional logic in the Profile, then create a
&ldquo;Chain&rdquo; in the Hierarchy if you need to use it in more than one place.</p>

<h2>Hiera, APL, Refactoring, WTF</h2>

<p>Like I said, I&rsquo;ve written about this before. I like the Automatic Parameter
Lookup functionality in Puppet &ndash; it&rsquo;s ace. I like Hiera. But if you don&rsquo;t know
how it works, or that it exists, it feels too much like Magic. There are certain
things in the product that can ONLY be set by putting data inside Hiera and running
Puppet, and that is truly an awesome thing: just tell a customer &ldquo;drop this bit
of data somewhere in Hiera, run Puppet, and you&rsquo;re all set.&rdquo; But, again, if you
need to know how a particular line got into a particular config file on your
node, and it was set with the APL, then you&rsquo;ve got some digging to do.</p>

<p>There&rsquo;s still no tool, like I mentioned in the last item, to give me full
introspection into all variables/parameters set for a node and that
variable/parameter&rsquo;s origin.  Part of the reason as to WHY this tool doesn&rsquo;t
exist is because the internals of Puppet don&rsquo;t necessarily make it easy for you
to determine where a parameter/variable was set.  That&rsquo;s OUR problem, and
I feel like we&rsquo;re slowly making progress on marking these things internally so
we can expose them to our customers. Until then, you have to trace through code
and Hiera data.</p>

<p>I know the second I publish and tweet about this, I&rsquo;m gonna get a message from
R.I. Pienaar saying that I&rsquo;ve crazy for NOT pushing people toward using Hiera
more with the Automatic Parameter Lookup, because the more we use it, the faster
we can move away from things like params classes, and profiles, and everything
else, but the reality is I&rsquo;m ALL ABOUT PEOPLE using it if they know how it works.
I&rsquo;m ACTUALLY fucking happy that it works well for you &ndash; please continue to use
it and do awesome Puppet things. I only recommend to people who are getting
started to NOT USE it FIRST, and then, when you understand how it would help
you by clocking some hours of Puppet code writing and debugging, do some refactoring
and move to it!</p>

<p>Yes, refactoring is involved.</p>

<p>Look, refactoring is a way of life. You&rsquo;re gonna re-tool your Puppet code for
the purposes of legibility, or efficiency, or any of the many other reasons why
you refactor code &ndash; it&rsquo;s unavoidable. Also, if I come into your org and setup
Puppet for the most efficient use-case, and then I leave that into your
relatively-new-to-Puppet hands, it&rsquo;s probably not gonna be the best situation
because you won&rsquo;t have known WHY I made the decisions I did (and, even if I
document them, you might have gaps of knowledge that would help you understand
the problems I&rsquo;m helping you avoid).</p>

<p>Sometimes hitting the problem so you have first-hand knowledge of why you need
to avoid it in the future isn&rsquo;t the WORST thing in the world.</p>

<p>To move to any configuration management system means you&rsquo;re gonna be
refactoring.  Embrace it. Start small, get things working, then clean it up.
Don&rsquo;t try to build the &ldquo;fortress of sysadmin perfection&rdquo; with your first bit of
Puppet code &ndash; just get shit done! Allow yourself time during the month simply
to unwind some misgivings you realize after-the fact, and definitely seek
advice before doing something you feel might be particularly complex or
overarching, but getting shit done is gonna trump &ldquo;not working&rdquo; any day (or
whatever the manager-y buzzspeak is this week).</p>

<p>Bottom Line: APL if you understand it, start small, get shit done, refactor, repeat</p>

<h2>Hopefully this leads to more posts</h2>

<p>Holy shit, you&rsquo;re still reading?! Ohh, you skimmed down this far to see how long
this post was gonna be &ndash; got it. Either way, I&rsquo;m glad I finally got this out there.
It&rsquo;s been months, yes, but that doesn&rsquo;t mean I haven&rsquo;t been writing. We&rsquo;ve been
doing lots of internal work to try and get more official docs out to you and
less of &ldquo;Go read Gary&rsquo;s blog!&rdquo; You&rsquo;ll notice <a href="http://docs.puppetlabs.com/pe/latest/r10k.html">R10k has some official docs, right?!</a>
Yeah, that&rsquo;s awesome! We want more of that. BUT, there&rsquo;s still going to be times
where I feel like what I&rsquo;m gonna say isn&rsquo;t necessarily the &ldquo;party line&rdquo;, and that&rsquo;s
what this blog is about.</p>

<p>Thanks to everyone at Puppetconf and beyond who approached me and told me how
much they love what I write. I&rsquo;m gonna be humble as fuck in person, but I really
do get excited whenever someone says that. It&rsquo;s also crazy as hell when someone
from Wal-mart approaches you and says they built part of their deployment based
on the shit you wrote. From a guy who came from a town in Ohio with a population
of less than 8000 people, it&rsquo;s crazy to see where you&rsquo;re &ldquo;recognized.&rdquo;</p>

<p>So thank you, again, for all the support.</p>

<p>And sorry, Dave Matthews &ndash; it&rsquo;s not you, it&rsquo;s me. Actually, that&rsquo;s a lie; it was you.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppet Workflows 4: Using Hiera in anger]]></title>
    <link href="http://garylarizza.com/blog/2014/10/24/puppet-workflows-4-using-hiera-in-anger/"/>
    <updated>2014-10-24T06:13:49-07:00</updated>
    <id>http://garylarizza.com/blog/2014/10/24/puppet-workflows-4-using-hiera-in-anger</id>
    <content type="html"><![CDATA[<p>Hiera. That thing nobody is REALLY quite sure how to say (FYI: It&rsquo;s pronounced
&lsquo;hiera&rsquo;), the tool that everyone says you should be using, and the tool that
will make you hate YAML syntax errors with a passion. It&rsquo;s a data/code
separation dream, (potentially) a debugging nightmare, and absolutely vital in
creating a Puppet workflow that scales better than your company&rsquo;s Wifi strategy
(FYI: your company&rsquo;s Wifi password just changed. Again. Because they&rsquo;re not
using certificates). I&rsquo;ve already written a GOOD AMOUNT on why/how to use it,
but now I&rsquo;m going to give you a couple of edge cases. Call them &ldquo;best
practices&rdquo; (and I&rsquo;ll cut you), but I like to call it &ldquo;shit I learned
after using Hiera in anger.&rdquo; Here are a couple of the most popular questions
I hear, and my usual responses&hellip;</p>

<h2>&ldquo;How should I setup my hierarchy?&rdquo;</h2>

<p>This is such a subjective question because it&rsquo;s specific to your organization
(because it&rsquo;s your data). I usually ask back &ldquo;What are the things about your
nodes that are different, and when are they different?&rdquo; Usually I hear something
back like &ldquo;Well, nodes in this datacenter have different DNS settings&rdquo; or
&ldquo;Application servers in production use one version of java, and those in dev
use a different version&rdquo; or &ldquo;All machines in the dev environment in this datacenter
need to have a specific repository&rdquo;. All of these replies give me ideas to your
hierarchy.  When you think of Hiera as a giant conditional statment, you can
start seeing how your hierarchy could be laid out.  With the first response, we
know we need a <code>location</code> fact to determine where a node is, and then we can
have a hierarchy level for that location. The second response tells me we need
a level for the application tier (i.e. dev/test/prod).  The third response tells
me we need a level that combines both the location and the application tier. When
you add in that you should probably have a node-specific level at the top (for
overrides) and a default level at the bottom (or not: see the next section), I&rsquo;m
starting to picture this:</p>

<p>{% codeblock lang:yaml %}
:hierarchy:
  &ndash; &ldquo;nodes/%{::clientcert}&rdquo;
  &ndash; &ldquo;%{::location}/%{::applicationtier}&rdquo;
  &ndash; &ldquo;%{::location}/common&rdquo;
  &ndash; &ldquo;tier/%{::applicationtier}&rdquo;
  &ndash; common
{% endcodeblock %}</p>

<p>Every time you have a need, you consider a level.  Now, obviously, it doesn&rsquo;t
mean that you NEED a level for every request (sometimes if it&rsquo;s an edge case
you can handle it in the profile or the role). There&rsquo;s a performance hit for
every level of your Hiera hierarchy, so ideally keep it minimal (or around
5 levels or so), but we&rsquo;re talking about flexibility here, and, if that&rsquo;s more
important than performance then you should go for it.</p>

<p>Next comes ordering. This one&rsquo;s SLIGHTLY easier &ndash; your hierarchy should read from
most-specific to least-specific. Note that when you specify an application tier
at a specific location that that it is MORE specific than just saying &ldquo;all nodes in
this application tier.&rdquo; Sometimes you will have levels that might be hard to
define an order &ndash; such as location vs. application tier. You kinda just have to
go with your gut here. In many cases you may find that the data you put in those
two levels will be entirely different (location-based data may not ever overlap
with application-tier-specific data). Do remember than any time you change the
order of your hierarchy you&rsquo;re going to introduce the possibility that values
get flip/flopped.</p>

<p>If you look at level 3 of the hierarchy above, you&rsquo;ll see that I have &lsquo;common&rsquo;
at the end. Some people like this syntax (where they put a &lsquo;common&rsquo; file in a
folder that matches the fact they&rsquo;re checking against), and some people prefer
a filename matching the fact.  Do what makes you happy, but, in this case,
we can unify the location folder and just put the common file underneath the
application tier files.</p>

<p>Finally, DO MAKE USE OF FOLDERS!  For the love of god, this. Putting all files
in a single folder both makes that a BIG folder, but also introduces a namespace
collision (i.e. what if you have a location named &lsquo;dev&rsquo; for example? Now you have
both an application tier and a location with the same name.  Oops).</p>

<p>How you setup your hierarchy is up to you, but this should hopefully give you
somewhere to start.</p>

<h2>Common.yaml, your organization&rsquo;s common values &ndash; <strong>REVISED</strong></h2>

<p><strong>UPDATE &ndash; 28 October</strong></p>

<p><em>Previously, this section was where I presented the idea of removing the lowest
level of the hierarchy as a way of ensuring that you didn&rsquo;t omit a value in Hiera
(the idea being that common values would be in the profile, anything higher would
be in Hiera, and all your &lsquo;defaults&rsquo;, or &lsquo;common values&rsquo; would be inside the profile).
The idea of removing the lowest level of the Hiera hierarchy was always something
I was kicking around in my head, but R.I. made a comment below that&rsquo;s made me revise
my thought process. There&rsquo;s still a greater concern around definitively tracking
down values pulled from Hiera, but I think we can accomplish that through other
means. I&rsquo;m going to revise what I wrote below to point out the relevant details.</em></p>

<p>When using Hiera, you need to define a hierarchy that Hiera uses in its search
for your data. Most often, it looks something like this:</p>

<h2>{% codeblock lang:yaml hiera.yaml %}</h2>

<p>:backends:
  &ndash; yaml
:yaml:
  :datadir: /etc/puppetlabs/puppet/hieradata
:hierarchy:
  &ndash; &ldquo;nodes/%{::clientcert}&rdquo;
  &ndash; &ldquo;location/%{::location}&rdquo;
  &ndash; &ldquo;environment/%{::applicationtier}&rdquo;
  &ndash; common
{% endcodeblock %}</p>

<p>Notice that little &ldquo;common&rdquo; at the end?  That means that, failing everything
else, it&rsquo;s going to look in <code>common.yaml</code> for a value. I had thought of common
as the &lsquo;defaults&rsquo; level, but the reality is that it is a list of values common
across all the nodes in your infrastructure.  These are the values, SPECIFIC TO
YOUR ORGANIZATION, that should be the same everywhere. Barring an override at a
higher level, these values are your organization&rsquo;s &lsquo;defaults&rsquo;, if you will.</p>

<p>Previously, you may have heard me rail against Hiera&rsquo;s optional second argument
and how I really don&rsquo;t like it.  Take this example:</p>

<p>{% codeblock lang:puppet %}
$foo = hiera(&lsquo;port&rsquo;, &lsquo;80&rsquo;)
{% endcodeblock %}</p>

<p>Given this code, Hiera is going to look for a parameter called &lsquo;port&rsquo; in its
hierarchy, and, if it doesn&rsquo;t find one in ANY of the levels, assign back a default
value of &lsquo;80&rsquo;.  I don&rsquo;t like using this second argument because:</p>

<ol>
<li>If you forget to enter the &lsquo;port&rsquo; parameter into the hierarchy, or typo it in the YAML file, Hiera will gladly assign the default value of &lsquo;80&rsquo; (which, unless you&rsquo;re checking for this, might sneak and get into production)</li>
<li>Where is the real &lsquo;default&rsquo; value: the value in <code>common.yaml</code> or the optional second argument?</li>
</ol>


<p>It actually depends on where you do the hiera() call as to what &lsquo;kind&rsquo; of
default value this is. Note that previously we talked about how the &lsquo;common&rsquo;
level represented values common across your infrastructure. If you do this
hiera() call inside a profile (which is where I recommend it be done), providing
the optional second argument ends up being redundant (i.e. the value should be
inside Hiera).</p>

<p>The moral of this story being: values common to all nodes should be in the
lowest level of the Hiera hierarchy, and all explicit hiera calls should
omit the default second argument if that common value is expected to be found
in the hierarchy.</p>

<h2>Data Bindings</h2>

<p>In Puppet 3, we introduced the concept of &lsquo;data bindings&rsquo; for parameterized classes,
which meant that Puppet now had another choice for gathering parmeter values.
Previously, the order Puppet would look to assign a value for parameters to
classes was:</p>

<ol>
<li>A value passed to the class via the parameterized class syntax</li>
<li>A default value provided by the class</li>
</ol>


<p>As of Puppet 3, this is the new parameter assignment order:</p>

<ol>
<li>A value passed to the class via the parameterized class syntax</li>
<li>A Hiera lookup for <em>classname::parametername</em></li>
<li>A default value provided by the class</li>
</ol>


<p>Data bindings is meant to be pluggable to allow for ANY data backend, but,
as of this writing, there&rsquo;s currently only one: Hiera.  Because of this,
Puppet will now automatically do a Hiera lookup for every parameter to a
parameterized class that isn&rsquo;t explicitly passed a value via the parameterized
class syntax (which means that if you just do <code>include classname</code>, Puppet
will do a Hiera lookup for EVERY parameter defined to the &ldquo;classname&rdquo; class).</p>

<p>This is really cool because it means that you can just add <em>classname::parametername</em>
to your Hiera setup, and, as long as you&rsquo;re not EXPLICITLY passing that
parameter&rsquo;s value to the class, Puppet will do a lookup and find the value.</p>

<p>It&rsquo;s also completely transparent to you unless you know it&rsquo;s happening.</p>

<p>The issue here is that this is new functionality to Puppet, and it feels like
magic to me. You can make the argument and say &ldquo;If you don&rsquo;t start using it,
Gary, people will never take to it,&rdquo; however I feel like this kind of magical
lookup in the background is always going to be a bad thing.</p>

<p>There&rsquo;s also another problem.  Consider a Hiera hierarchy that has 15 levels
(they exist, TRUST ME).  What happens if you don&rsquo;t define ANY parameters in
Hiera in the form of <em>classname::parametername</em> and simply want to rely on
the default values for every class?  Well, it means that Hiera is STILL going
to be triggered for every parameter to a class that isn&rsquo;t explicitly passed a
value.  That&rsquo;s a hell of a performance hit.  Fortunately, there&rsquo;s a way to
disable this lookup.  Simply add the following to the Puppet master&rsquo;s <code>puppet.conf</code>
file:</p>

<p>{% codeblock %}
data_binding_terminus = none
{% endcodeblock _%}</p>

<p>It&rsquo;s going to be up to how your team needs to work as to whether you use Hiera
data bindings or not. If you have a savvy team that feels they can debug these
lookups, then cool &ndash; use the hell out of it. I prefer to err on the side of an
explicit hiera() lookup for every value I&rsquo;m querying, even if it&rsquo;s a lot of extra
lines of code. I prefer the visibility, especially for new members to your team.
For those people with large hierarchies, you may want to weigh the performance
hit.  Try to disable data bindings and see if your master is more performant. If
so, then explicit hiera() calls may actually buy you some rewards.</p>

<p><strong>PROS:</strong></p>

<ul>
<li>Adding parameters to Hiera in the style of <em>classname::parametername</em> will set parameterized class values automatically</li>
<li>Simplified code &ndash; simply use the include() function everywhere (which is safer than the parameterized class syntax)</li>
</ul>


<p><strong>CONS:</strong></p>

<ul>
<li>Lookup is completely transparent unless you know what&rsquo;s going on</li>
<li>Debugging parameter values can be difficult (especially with typos or forgetting to set values in Hiera)</li>
<li>Performance hit for values you want to be assigned the class default value</li>
</ul>


<h2>Where to data &ndash; Hiera or Profile?</h2>

<p>&ldquo;Does this go right into the Profile or into Hiera?&rdquo;  I get that question
repeatedly when I&rsquo;m working with customers. It&rsquo;s a good question, and one of
the quickest ways to blow up your YAML files in Hiera. Here&rsquo;s the order I use
when deciding where to put data:</p>

<h3>WHERE did that data come from?</h3>

<p>Remember that the profile is YOUR implementation &ndash; it describes how YOU define
the implementation of a piece of technology in YOUR organization. As such, it&rsquo;s
less about Puppet code and more about pulling data and passing it TO the Puppet
code. It&rsquo;s the glue-code that grabs the data and wires it up to the model that
uses it. How it grabs the data is not really a big deal, so long as it grabs
the RIGHT data &ndash; right? You can choose to hardcode it into the Profile, or use
Hiera, or use some other magical data lookup mechanism &ndash; we don&rsquo;t really care
(so long as the Profile gathers the data and passes it to the correct Puppet
class).</p>

<p>The PROBLEM here is debugging WHERE the data came from. As I said previously,
Hiera has a level for all bits of data common to your organization, and, obviously,
data overridden at a higher level takes precedence over the &lsquo;common&rsquo; level at
the bottom. With Hiera, unless you run the <code>hiera</code> binary in debug mode (-d),
you can never be completely sure where the data came from. Puppet has no way of
dumping out every variable and where it came from (whether Hiera or set directly
in the DSL, and, if it WAS Hiera, exactly what level or file it came from).</p>

<p>It is THIS REASON that causes me to eschew things like data bindings in Puppet.
Debugging where a value came from can be a real pain in the ass. If there were
amazing tooling around this, I would 100% support using data bindings and just
setting everything inside Hiera and using the include() function, but, alas,
that&rsquo;s not been my experience. Until then, I will continue to recommend explicit
<code>hiera</code> calls for visibility into when Hiera is being called and when values
are being set inside the DSL.</p>

<h3>Enter the data into the Profile</h3>

<p>One of the first choices people make is to enter the data (like ntpserver
address, java version, or whatever it is) directly into the Profile.
&ldquo;BUT GARY! IT&rsquo;S GOING TO MAKE IT HARD TO DEBUG!&rdquo;  Not really. You&rsquo;re going to
have to open the Profile anyway to see what&rsquo;s going on (whether you pull the
data from Hiera or hardcode it in the Profile), right? And, arguably, the
Profile is legible&hellip;doing Hiera lookups gives you flexibility at a cost of
abstracting away how it got that bit of data (i.e. &ldquo;It used Hiera&rdquo;). For newer
users of Puppet, having the data in the Profile is easier to follow. So, in the
end, putting the data into the Profile itself is the least-flexible and most-visible
option&hellip;so consequently people consider it as the first available option. This option
is good for common/default values, BUT, if you eventually want to use Hiera, you need
to re-enter the data into the common level of Hiera. It also splits up your
&ldquo;source of truth&rdquo; to include BOTH the Profile manifest and Hiera. In the end,
you need to weigh your team&rsquo;s goals, who has access to the Hiera repo, and
how flexible you need to be with your data.</p>

<p><strong>PROS:</strong></p>

<ul>
<li>Data is clearly visible and legible in the profile (no need to open additional files)</li>
</ul>


<p><strong>CONS:</strong></p>

<ul>
<li>Inability to redefine variables in Puppet DSL makes any settings constants by default (i.e. no overriding permitted)</li>
<li>Data outside of Hiera creates a second &ldquo;source of truth&rdquo;</li>
</ul>


<h3>Enter the data into Hiera</h3>

<p>If you find that you need to have different bits of data for different nodes
(i.e. a different version of Java in the dev tier instead of the prod tier),
then you can look to put the data into Hiera.  Where to put the data is going
to depend on your own needs &ndash; I&rsquo;m trusting that you can figure this part out &ndash; but
the bigger piece here is that once the data is in Hiera you need to ensure
you&rsquo;re getting the RIGHT data (i.e. if it&rsquo;s overridden at a higher level, you
are certain you entered it into the right file and didn&rsquo;t typo anything).</p>

<p>This answers that &ldquo;where&rdquo; question, but doesn&rsquo;t answer the &ldquo;what&rdquo; question&hellip;as
in &ldquo;What data should I put into Hiera?&rdquo;  For that, we have another section&hellip;</p>

<p><strong>PROS:</strong></p>

<ul>
<li>Flexibility in returning different values based on different conditions</li>
<li>All the data is inside one &lsquo;source of truth&rsquo; for data according to your organization</li>
</ul>


<p><strong>CONS:</strong></p>

<ul>
<li>Visibility &ndash; you must do a Hiera lookup to find the value (or open Hiera&rsquo;s YAML files)</li>
</ul>


<h2>&ldquo;What exactly goes into Hiera?&rdquo;</h2>

<p>If there were one question that, if answered incorrectly, could make or break
your Puppet deployment, this would be it. The greatest strength and weakness of
Hiera is its flexibility.  You can truly put almost anything in Hiera, and, when
combined with something like the create_resources() function, you can create
your own YAML configuration language (tip: don&rsquo;t actually do this).</p>

<p>&ldquo;But, seriously, what should go into Hiera, and what shouldn&rsquo;t?&rdquo;</p>

<p>The important thing to consider here is the price you pay by putting data into
Hiera. You&rsquo;re gaining flexibility at a cost of visibility.  This means that you
can do things like enter values at all level of the hierarchy that can be
concatenated together with a single hiera_array() call, BUT, you&rsquo;re losing the
visibility of having the data right in front of you (i.e. you need to open up
all the YAML files individually, or use the <code>hiera</code> binary to debug how you got
those values). Hiera is REALLY COOL until you have to debug why it grabbed (or
DIDN&rsquo;T grab) a particular value.</p>

<p>Here&rsquo;s what I usually tell people about what should be put into Hiera:</p>

<ul>
<li>The exact data values that need to be different conditionally (i.e. a different ntp server for different sites, different java versions in dev/prod, a password hash, etc.)</li>
<li>Dynamic data expressed in multiple levels of the hierarchy (i.e. a lookup for &lsquo;packages&rsquo; that returns back an array of all the values that were found in all the levels of the hierarchy)</li>
<li>Resources as a hash ONLY WHEN ABSOLUTELY NECESSARY</li>
</ul>


<h3>Puppet manifest vs. create_resources()</h3>

<p>Bullets 1 and 2 above should be pretty straightforward &ndash; you either need to use
Hiera to grab a specific value or return back a list of ALL the values from ALL
the levels of the hierarchy. The point here is that Hiera should be returning
back only the minimal amount of data that is necessary (i.e. instead of
returning back a hash that contains the title of the resource, all the attributes
of the resource, and all the attribute values for that resource, just return
back a specific value that will be assigned to an attribute&hellip;like the password
hash itself for a user). This data lookup appears to be &ldquo;magic&rdquo; to new users of
Puppet &ndash; all they see is the magic phrase of &ldquo;hiera&rdquo; and a parameter to search
for &ndash; and so it becomes slightly confusing. It IS, however, easier to understand
that this magical phrase will return data, and that that data is going to be used
to set the value for an attribute. Consider this example:</p>

<p>{% codeblock lang:puppet %}
$password = hiera(&lsquo;garypassword&rsquo;)</p>

<p>user { &lsquo;gary&rsquo;:
  ensure   => present,
  uid      => &lsquo;5001&rsquo;,
  gid      => &lsquo;gary&rsquo;,
  shell    => &lsquo;zsh&rsquo;,
  password => $password,
}
{% endcodeblock %}</p>

<p>This leads us to bullet 3, which is &ldquo;the Hiera + create_resources() solution.&rdquo;
This solution allows you to lookup data from within Hiera and pass it directly
to a function where Puppet creates the individual resources as if you had typed
them into a Puppet manifest itself. The previous example can be entered into
a Hiera YAML file like so:</p>

<p>{% codeblock lang:yaml sysadmins.yaml %}
users:
  gary:</p>

<pre><code>ensure: 'present'
uid: '5001'
gid: 'gary'
shell: 'zsh'
password: 'biglongpasswordhash'
</code></pre>

<p>{% endcodeblock %}</p>

<p>And then a resource can be created inside the Puppet DSL by doing the following:</p>

<p>{% codeblock lang:puppet %}
$users = hiera(&lsquo;users&rsquo;)
create_resources(&lsquo;users&rsquo;)
{% endcodeblock _%}</p>

<p>Both examples are functionally identical, except the first one only uses Hiera
to get the password hash value, whereas the second one grabs both the
attributes, and their values, for a specific resource. Imagine Puppet gives you
an error with the &lsquo;gary&rsquo; user resource and you were using the latter example.
You grep your Puppet code looking for &lsquo;gary&rsquo;, but you won&rsquo;t find that user
resource in your Puppet manifest anywhere (because it&rsquo;s being created with the create_resources() function).
You will instead have to know to go into Hiera&rsquo;s data directory, then the
correct datafile, and then look for the hash of values for the &lsquo;gary&rsquo; user.</p>

<h3>Functional differences between the two approaches</h3>

<p>Functionally, you COULD do this either way. When you come up with a solution
using create_resources(), I challenge you to draw up another solution using
Puppet code in a Puppet manifest (however lengthy it may be) that queries Hiera
for ONLY the specific values necessary. Consider this example, but, instead,
you need to manage 500 users.
If you use create_resources(), you would then need to add 500 more blocks to
the &lsquo;users&rsquo; parameter in your Hiera datafiles.  That&rsquo;s a lot of YAML. And on
what level will you add these blocks? <code>prod.yaml</code>? <code>dev.yaml</code>? Are you using a
<code>common.yaml</code>? Your YAML files suddenly got huge, and the rest of your team
modifying them will not be so happy to scroll through 500 entries. Now consider
the first example using Puppet code. Your Puppet manifest suddenly grew, but it
didn&rsquo;t affect all the OTHER manifests out there: only this file. The Hiera YAML
files will still grow &ndash; but now 500 individual lines instead of 3000 lines in
the previous example. Okay, now which one is more LEGIBLE? I would argue that
the Puppet manifest is more legible, because I consider the Puppet DSL to be
very legible (again, subject to debate versus YAML). Moreover, when debugging,
you can stay inside Puppet files more often using Puppet manifests to define
your resources. Using create_resources, you need to jump into Hiera more often.
That&rsquo;s a context shift, which adds more annoyance to debugging. Also, it
creates multiple &ldquo;sources of truth.&rdquo; Suddenly you have the ability of entering
data in Hiera as well as entering it in the Puppet manifest, which may be clear
to YOU, but if you leave the company, or you get another person on your team,
they may choose to abuse the Hiera settings without knowing why.</p>

<p>Now consider an example that you might say is more tailored to create_resources().
Say you have a defined type that sets up tomcat applications. This defined type
accepts things like a path to install the application, the application&rsquo;s package
name, the version, which tomcat installation to target, and etc. Now consider
that all application servers need application1, but only a couple
of servers need application2, and a very snowflake server needs application3 (in
this case, we&rsquo;re NOT saying that all applications are on all boxes and that their
data, like the version they&rsquo;re using, is different. We&rsquo;re actually saying that
different machines require entirely different applications).</p>

<p>Using Hiera + create_resources() you could enter the resource for the
application1 at a low level, then, at a higher level, add the resource for
application2, and finally add the resource for application3 at the
node-specific level. In the end, you can do a hiera_hash() lookup to discover
and concatenate all resources from all levels of the hierarchy and pipe that to
create_resources.</p>

<p>How would you do this with Puppet code?  Well, I would create profiles for every
application, and either different roles for the different kinds of servers (i.e.
the snowflake machine gets its own role), or conditional checks inside the role
(i.e. if this node is at the London location, it gets these application profiles,
and etc&hellip;).</p>

<p>Now which is more legible? At this point, I&rsquo;d still say that separate profiles
and conditional checks in roles (or sub-roles) are more legible &ndash; including
a class is a logical thing to follow, and conditionals inside Puppet code are
easy to follow. The create_resources() solution just becomes magic. Suddenly,
applications are on the node. If you want to know where they came from, you
have to switch contexts and open Hiera data files or use the <code>hiera</code> binary
and do a debug run. If you&rsquo;re a small team that&rsquo;s been using Puppet forever,
then rock on and go for it. If you&rsquo;re just getting started, though, I&rsquo;d shy
away.</p>

<h3>Final word on create_resources?</h3>

<p>{% codeblock %}
Some people, when confronted with a problem, think â€œI know, I&rsquo;ll use create_resources().&ldquo;
Now they have two problems.
{% endcodeblock _%}</p>

<p>The create_resources() function is often called the &ldquo;PSE Swiss Army knife&rdquo;
(or, Professional Services Engineer &ndash; the people who do what
I do and consult with our customers) because we like to break it out when we&rsquo;re
painted into a corner by customer requirements. It will work ANYWHERE, but, again,
at that cost of visibility. I am okay with someone using it so long as they
understand the cost of visibility and the potential debugging issues they&rsquo;ll hit.
I will always argue against using it, however, for those reasons. More code in
a Puppet manifest is not a bad thing&hellip;especially if it&rsquo;s reasonably legible
code that can be kept to a specific class. Consider the needs and experience
level of your team before using create_resources() &ndash; if you don&rsquo;t have a good
reason for using it, simply don&rsquo;t.</p>

<h3>create_resources()</h3>

<p><strong>PROS:</strong></p>

<ul>
<li>Dynamically iterate and create resources based on Hiera data</li>
<li>Using Hiera&rsquo;s hash merging capability, you can functionally override resource values at higher levels of the hierarchy</li>
</ul>


<p><strong>CONS:</strong></p>

<ul>
<li>Decreased visibility</li>
<li>Becomes a second &lsquo;source of truth&rsquo; to Puppet</li>
<li>Can increase confusion about WHERE to manage resources</li>
<li>When used too much, it creates a DSL to Puppet&rsquo;s DSL (DSLs all the way down)</li>
</ul>


<h3>Puppet DSL + single Hiera lookup</h3>

<p><strong>PROS:</strong></p>

<ul>
<li>More visible (sans the bit of data you&rsquo;re looking up)</li>
<li>Using wrapper classes allows for flexibility and conditional inclusion of resources/classes</li>
</ul>


<p><strong>CONS:</strong></p>

<ul>
<li>Very explicit &ndash; doesn&rsquo;t have the dynamic overriding capability like Hiera does</li>
</ul>


<h2>Using Hiera as an ENC</h2>

<p>One of the early &ldquo;NEAT!&rdquo; moments everyone has with Hiera is using it as an
External Node Classifier, or ENC. There is a function called <code>hiera_include()</code>
that allows you to include classes into the catalog as if you were to write
&ldquo;include (classname)&rdquo; in a Puppet manifest.  It works like this:</p>

<p>{% codeblock lang:yaml london.yaml %}
classes:
  &ndash; profiles::london::base
  &ndash; profiles::london::network
{% endcodeblock %}</p>

<p>{% codeblock lang:yaml dev.yaml %}
classes:
  &ndash; profiles::tomcat::application2
{% endcodeblock %}</p>

<p>{% codeblock lang:puppet site.pp%}
node default {
  hiera_include(&lsquo;classes&rsquo;)
}
{% endcodeblock _%}</p>

<p>Given the above example, the hiera_include() function will search every level
of the hierarchy looking for a parameter called &lsquo;classes&rsquo;. It returns
a concatenated list of classnames, which it then passes to Puppet&rsquo;s include()
function (in the end, Puppet will declare the profiles::london::base,
profiles::london::network, and profiles::tomcat::application2 classes). Puppet
puts the contents of these classes into the catalog, and away we go. This is
awesome because you can change the classification of a node conditionally
according to a Hiera lookup, and it&rsquo;s terrible because you can CHANGE THE
CLASSIFICATION OF A NODE CONDITIONALLY ACCORDING TO A HIERA LOOKUP!  This means
that anyone with access to the repo holding your Hiera data files can affect
changes to every node in Puppet just by modifying a magical key. It also means
that in order to see the classification for a node, you need to do a Hiera
lookup (i.e. you can&rsquo;t just open a file and see it).</p>

<p>Remember that WHOLE blog post about Roles and Profiles?  I do, because I wrote
the damn thing. <a href="http://bit.ly/puppetworkflows2">You can even go back and read it again, too, if you want to.</a>
One of the core tenets of that article was that each node get classified with a
single role. If you adhere to that (and you should; it makes for a much more
logical Puppet deployment), a node really only ever needs to be classified
ONCE. You don&rsquo;t NEED this conditional classification behavior. It&rsquo;s one of those
&ldquo;It seemed like a good idea at the time&rdquo; moments that I assure you will pass.</p>

<p>Now, you CAN use Roles with hiera_include() &ndash; simply create a Facter fact that
returns the node&rsquo;s role, add a level to the Hiera hierarchy for this role fact,
and in the role&rsquo;s YAML file in Hiera, simply do:</p>

<p>{% codeblock lang:yaml appserver.yaml %}
classes: role::application_server
{% endcodeblock _%}</p>

<p>Then you can use the same hiera_include() call in the default node definition
in <code>site.pp</code>. The ONLY time I recommend this is if you don&rsquo;t already have some
other classification method. The downside of this method is that if your role
fact CHANGES, for some reason or another, classification immediately changes.
Facts are NOT secure &ndash; they can be overridden really easily. I don&rsquo;t like to
leave classification to an insecure method that anyone with root access on a
machine can change. Using an ENC or <code>site.pp</code> for classification means that the
node ABSOLUTELY CANNOT override its classification. It&rsquo;s the difference between
being authoritative and simply &lsquo;suggesting&rsquo; a classification.</p>

<p><strong>PROS:</strong></p>

<ul>
<li>Dynamic classification: no need to maintain a site.pp file or group in the Console</li>
<li>Fact-based: a node&rsquo;s classification can change immediately when its role fact does</li>
</ul>


<p><strong>CONS:</strong></p>

<ul>
<li>Decreased visibility: need to do a Hiera lookup to determine classification</li>
<li>Insecure: since facts are insecure and can be overridden, so can classification</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Puppetconf 2014 Talk - The Refactor Dance]]></title>
    <link href="http://garylarizza.com/blog/2014/10/23/puppetconf-2014-talk/"/>
    <updated>2014-10-23T06:15:42-07:00</updated>
    <id>http://garylarizza.com/blog/2014/10/23/puppetconf-2014-talk</id>
    <content type="html"><![CDATA[<p>This year at Puppetconf 2014, I presented a 1.5 hour talk entitled &ldquo;The Refactor
Dance&rdquo; that comprised nearly EVERYTHING that I&rsquo;ve written about in my Puppet
Workflows series (from writing better component modules, to Roles/Profiles,
to Workflow, and lots of stories in-between) as well as a couple of bad words,
a pair of leather pants (trousers), and an Uber story that beats your Uber
story. It&rsquo;s long, informative, and you get to watch the sweat stains under my
arms grow in an attractive grey Puppet Labs shirt.  What&rsquo;s not to love?</p>

<p><a href="https://puppetlabs.com/presentations/workshop-doing-refactor-dance-making-your-puppet-modules-more-modular-gary-larizza">To watch the video, click here to check it out!</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[On Dependencies and Order]]></title>
    <link href="http://garylarizza.com/blog/2014/10/19/on-dependencies-and-order/"/>
    <updated>2014-10-19T06:09:53-07:00</updated>
    <id>http://garylarizza.com/blog/2014/10/19/on-dependencies-and-order</id>
    <content type="html"><![CDATA[<p>This blog post was born out of a number of conversations that I&rsquo;ve had about
Puppet, its dependency model, and why &lsquo;ordering&rsquo; is not necessarily the way to
think about dependencies when writing Puppet manifests. Like most everything on
this site, I&rsquo;m getting it down in a file so I don&rsquo;t have to repeat this all over
again the next time someone asks. Instead, I can point them to this page (and,
when they don&rsquo;t actually <strong>READ</strong> this page, I can end up explaining everything
I&rsquo;ve written here anyways&hellip;).</p>

<p>Before we go any further, let me define a couple of terms:</p>

<p>{% codeblock %}
dependencies     &ndash; In a nutshell, what happens when you use the metaparameters of</p>

<pre><code>               'before', 'require', 'subscribe' or 'notify' on resources in a
               Puppet manifest: it's a chain of resources that are to be
               evaluted in a specific order every time Puppet runs. Any failure
               of a resource in this chain stops Puppet from evaluating the
               remaining resources in the chain.
</code></pre>

<p>evaluate         &ndash; When Puppet determines the &lsquo;is&rsquo; value (or current state) of a</p>

<pre><code>               resource (i.e. for package resources, "is the package installed?")
</code></pre>

<p>remediate        &ndash; When Puppet determines that the &lsquo;is&rsquo; value (or current state of</p>

<pre><code>               the resource) is different from the 'should' value (or the value
               entered into the Puppet manifest...the way the resource SHOULD
               end up looking on the system) and Puppet needs to make a change.
</code></pre>

<p>declarative(ish) &ndash; When I use the word &lsquo;declarative(ish)&rsquo;, I mean that the order</p>

<pre><code>               by which Puppet evaluates resources that do not contain dependencies
               does not have a set procedure/order. The way Puppet EVALUATES
               resources does not have a set procedure/order, but the order
               that Puppet reads/parses manifest files IS from top-to-bottom
               (which is why variables in Puppet manifests need to be declared
               before they can be used).
</code></pre>

<p>{% endcodeblock %}</p>

<h2>Why Puppet doesn&rsquo;t care about execution order (until it does)</h2>

<p>The biggest shock to the system when getting started with a declarative (ish)
configuration management tool like Puppet is understanding that Puppet describes
the end-state of the machine, and NOT the order that it&rsquo;s (Puppet) going to
take you to that state. To Puppet, the order that it chooses to affect change
in any resource (be it a file to be corrected, a package to be installed, or
any other resource type) is entirely arbitrary because resources that have no
relationship to another resource shouldn&rsquo;t CARE about the order in which they&rsquo;re
evaluated and remediated.</p>

<p>For example, imagine Puppet is going to create both <code>/etc/sudoers</code> and update
the system&rsquo;s authorized keys file to enter all the sysadmins' SSH keys. Which
one should it do first? In an imperative system like shell scripts or
a runbook-style system, you are forced to choose an order. So I ask again,
which one goes first? If you try to update the <code>sudoers</code> file in your script
first, and there&rsquo;s a problem with that update, then the script fails and the
SSH keys aren&rsquo;t installed. If you switch the order and there&rsquo;s a problem with
the SSH keys, then you can&rsquo;t <code>sudo</code> up because the <code>sudoers</code> file hasn&rsquo;t been
touched.</p>

<p>Because of this, Puppet has always taken the stance that if there are failures,
we want to get as much of the system into a working state as possible (i.e. any
resources that don&rsquo;t depend upon the failing resource are going to still be
evaluated, or &lsquo;inspected&rsquo;, and remediated, or &lsquo;changed if need be&rsquo;). There are
definitely philosophical differences here: the argument can be made that if there&rsquo;s
a failure somewhere, the system is bad and you should cast it off until you&rsquo;ve
fixed whatever the problem is (or the part of the code causing the problem). In
virtualized or &lsquo;cloud&rsquo; environments where everything is automated, this is just
fine, but in environments without complete and full automation, sometimes you
have to fix and deal with what you have. Puppet &ldquo;believes in your system&rdquo;, which
is borderline marketing-doubletalk for &ldquo;alert you of errors and give you time
to fix the damn thing and do another Puppet run without having to spin up a whole
new system.&rdquo;</p>

<p>Once you know WHY Puppet takes the stance it does, you realize that Puppet does
not give two shits about the order of resources without dependencies. If you
write perfect Puppet code, you&rsquo;re fine. But the majority of the
known-good-world does not do that. In fact, most of us write shit code. Which
was the problem&hellip;</p>

<h2>The history of Puppet&rsquo;s ordering choices</h2>

<h3>&lsquo;Random&rsquo; random order</h3>

<p>In the early days, the only resources that were guaranteed to have a consistent
order were those resources with dependencies (i.e. as I stated above, resources
that used the &lsquo;before&rsquo;, &lsquo;require&rsquo;, &lsquo;subscribe&rsquo;, or &lsquo;notify&rsquo; metaparameters to
establish an evaluation order). Every other resource was evaluted at random
every time that Puppet ran&hellip;which meant that you could run Puppet ten times
and, theoretically, resources without dependencies could be evaluated in
a different order between every Puppet run (we call this non-deterministic
ordering). This made things REALLY hard to debug.  Take the case where you had
a catalog of thousands of resources but you forgot a SINGLE dependency between
a couple of file resources. If you roll that change out to 1000 nodes, you
might have 10 or less of them fail (because Puppet chose an evaluation order
that ordered these two resources incorrectly). Imagine trying to figure out
what happened and replicate the problem. You could waste lots of time just
trying to REPLICATE the issue, even if it was a small fix like this.</p>

<p><strong>PROS</strong>:</p>

<ul>
<li>IS there a pro here?</li>
</ul>


<p><strong>CONS</strong>:</p>

<ul>
<li>Ordering could change between runs, and thus it was very hard to debug missing dependencies</li>
</ul>


<p>Philosophically, we were correct: resources that are to be evaluated in a certain
order require dependencies. Practically, we were creating more work for ourselves.</p>

<p>Incidentally, I&rsquo;d heard that Adam Jacob, who created Chef, had cited this reason
as one of the main motivators for creating Chef. I&rsquo;d heard that as a Puppet
consultant, he would run into these buried dependency errors and want to flip
tables. Even if it&rsquo;s not a true STORY, it was absolutely true for tables where
I used to work&hellip;</p>

<h3>Title-hash, &lsquo;Predictable&rsquo; random order</h3>

<p>Cut to Puppet version 2.7 where we introduced deterministic ordering with
&lsquo;title-hash&rsquo; ordering. In a nutshell, resources that didn&rsquo;t have dependencies
would still be executed in a random order, but the order Puppet chose could be
replicated (it created a SHA1 hash based on the titles of the resources without
dependencies, and ordered the hashes alphabetically). This meant that if you
tested out a catalog on a node, and then ran that same catalog on 1000 other
nodes, Puppet would choose the same order for all 1000 of the nodes. This
gave you the ability to actually TEST whether your changes would successfully
run in production. If you omitted a dependency, but Puppet managed to pick the
correct evaluation order, you STILL had a missing dependency, but you didn&rsquo;t
care about it because the code worked. The next change you made to the catalog
(by adding or removing resources), the order might change, but you would
discover and fix the dependency at that time.</p>

<p><strong>PROS</strong>:</p>

<ul>
<li>&lsquo;Predictable&rsquo; and repeatable order made testing possible</li>
</ul>


<p><strong>CONS</strong>:</p>

<ul>
<li>Easy to miss dependency omissions if Puppet chose the right order (but do you really care?)</li>
</ul>


<h3>Manifest ordering, the &lsquo;bath salts&rsquo; of ordering</h3>

<p>Title-hash ordering seemed like the best of both worlds &ndash; being opinionated about
resource dependencies but also giving sysadmins a reliable, and repeatable, way
to test evaluation order before it&rsquo;s pushed out to production.</p>

<p>Buuuuuuuuuut, y'all JUST weren&rsquo;t happy enough, were you?</p>

<p>When you move from an imperative solution like scripts to a declarative(ish)
solution like Puppet, it is absolutely a new way to think about modeling your
system. Frequently we heard that people were having issues with Puppet because
the order that resources shows up in a Puppet master WASN&rsquo;T the order that Puppet
would evaluate the resources. I just dropped a LOT of words explaining why this
isn&rsquo;t the case, but who really has the time to read up on all of this? People
were dismissing Puppet too quickly because their expectations of how the tool
worked didn&rsquo;t align with reality. The assumption, then, was to align these
expectations in the hopes that people wouldn&rsquo;t dismiss Puppet so quickly.</p>

<p><a href="http://puppetlabs.com/blog/introducing-manifest-ordered-resources">Eric Sorenson wrote a blog post on our thesis and experimentation</a>
around manifest ordering that is worth a read (and, incidentally, is shorter
than this damn post), but the short version is that we tested this theory out
and determined that Manifest Ordering would help new users to Puppet. Because
of this work, we created a feature called &lsquo;Manifest Ordering&rsquo; that stated that
resources that DID NOT HAVE DEPENDENCIES would be evaluated by Puppet in the
order that they showed up in the Puppet manifest (when read top to bottom). If
a resource truly does not have any dependencies, then you honestly should not
care one bit what order it&rsquo;s evaluated (because it doesn&rsquo;t matter).  Manifest
Ordering made ordering of resources without dependencies VERY predictable.</p>

<p>But&hellip;.</p>

<p>This doesn&rsquo;t mean I think it&rsquo;s the best thing in the world. In fact, I&rsquo;m really
wary of how I feel people will come to use Manifest Ordering. There&rsquo;s a reason
I called it the &ldquo;bath salts of ordering&rdquo; &ndash; because a little bit of it, when
used correctly, can be a lovely thing, but too much of it, used in unintended
circumstances, leads to hypothermia, paranoia, and the desire to gnaw someone
else&rsquo;s face off. We were/are giving you a way to bypass our dependency model by
using the mental-model you had with scripts, but ALSO telling you NOT to rely
on that mental-model (and instead set dependencies explicitly using metaparameters).</p>

<p>Seriously, what could go wrong?</p>

<p>Manifest Ordering is not a substitution for setting dependencies &ndash; that IS NOT
what it was created for. <strong>Puppet Labs still maintains that you should use
dependencies to order resources and NOT simply rely on Manifest Ordering as
a form of setting dependencies!</strong> Again, the problem is that you need to KNOW
this&hellip;and if Manifest Ordering allows you to keep the same imperative
&ldquo;mindset&rdquo; inside a declarative(ish) language, then eventually you&rsquo;re going to
experience pain (if not today, but possibly later when you actually try to
refactor code, or share code, or use this code on a system that ISN&rsquo;T using
Manifest Ordering). A declarative(ish) language like Puppet requires seeing
your systems according to the way their end-state will look and worrying about
WHAT the system will look like, and not necessarily HOW it will get there. Any
shortcut to understanding this process means you&rsquo;re going to miss key bits of
what makes Puppet a good tool for modeling this state.</p>

<p><strong>PROS:</strong></p>

<ul>
<li>Evaluation order of resources without dependencies is absolutely predictable</li>
</ul>


<p><strong>CONS:</strong></p>

<ul>
<li>If used as a substitution for setting dependencies, then refactoring code (moving around the order in which resources show up in a manifest) means changing the evaluation order</li>
</ul>


<h2>What should I actually take from this?</h2>

<p>Okay, here&rsquo;s a list of things you SHOULD be doing if you don&rsquo;t want to create
a problem for future-you or future-organization:</p>

<ul>
<li>Use dependency metaparameters like &lsquo;before&rsquo;, &lsquo;require&rsquo;, &lsquo;notify&rsquo;, and &lsquo;subscribe&rsquo; if resources in a catalog NEED to be evaluated in a particular order</li>
<li>Do not use Manifest Ordering as a substitute for explicitly setting dependencies (disable it if this is too tempting)</li>
<li>Use Roles and Profiles for a logical module layout (see: <a href="http://bit.ly/puppetworkflows2">http://bit.ly/puppetworkflows2</a> for information on Roles and Profiles)</li>
<li>Order individual components inside the Profile</li>
<li>Order Profiles (if necessary) inside the Role</li>
</ul>


<p>And, seriously, trust us with the explicit dependencies. It seems like a giant
pain in the ass initially, but you&rsquo;re ultimately documenting your infrastructure,
and a dependency (or, saying &lsquo;this thing MUST come before that thing&rsquo;) is a pretty
important decision. There&rsquo;s a REASON behind it &ndash; treat it with some more weight
other than having one line come before another line, ya know? The extra time
right now is absolutely going to buy you the time you spend at home with your
kids (and by &lsquo;kids&rsquo;, I mean &lsquo;XBox&rsquo;).</p>

<p>And don&rsquo;t use bath salts, folks.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[R10k + Directory Environments]]></title>
    <link href="http://garylarizza.com/blog/2014/08/31/r10k-plus-directory-environments/"/>
    <updated>2014-08-31T12:00:00-07:00</updated>
    <id>http://garylarizza.com/blog/2014/08/31/r10k-plus-directory-environments</id>
    <content type="html"><![CDATA[<p>If you&rsquo;ve read anything I&rsquo;ve posted in the past year, you know my feelings about
the word &lsquo;environments&rsquo; and about how well we tend to name things here at
Puppet Labs (and if you don&rsquo;t, <a href="http://garylarizza.com/blog/2014/03/26/random-r10k-workflow-ideas/">you can check out that post here</a>).
Since then, Puppet Labs has released a new feature called <a href="https://docs.puppetlabs.com/puppet/latest/reference/environments.html">directory
environments (click this link for further reading)</a>
that replace the older &lsquo;config file environments&rsquo; that we all used to use (i.e.
stanzas in puppet.conf).  Directory environments weren&rsquo;t without their false
starts and issues, but further releases of Puppet, and their inclusion in
Puppet Enterprise 3.3.0, have allowed more people
to ask about them.  SO, I thought I&rsquo;d do a quick writeup about them&hellip;</p>

<h2>R10k had a child: Directory Environments</h2>

<p>The Puppet platform team had a couple of problems with config file environments
in puppet.conf &ndash; namely:</p>

<ul>
<li>Entering them in puppet.conf meant that you couldn&rsquo;t use environments named &lsquo;master&rsquo;, &lsquo;main&rsquo;, or &lsquo;agent&rsquo;</li>
<li>There was no easy/reliable way to determine all the available/used Puppet environments without making assumptions (and hacky code) &ndash; especially if someone were using R10k + dynamic environments</li>
<li>Adding more environments to <code>puppet.conf</code> made managing that file something of a nightmare (<code>environments.d</code> anyone?)</li>
</ul>


<p>Combine this with the fact that <a href="http://bit.ly/puppetworkflows3">most of the Professional Services team was
rolling out R10k to create dynamic environments</a> (which meant we
were abusing <code>$environment</code> inside <code>puppet.conf</code> and creating environments&hellip;well&hellip;
dynamically and on-the-fly), and they knew something needed to be done.
Because R10k was so popular and widely deployed, an environment solution that
was a simple step-up from an R10k deployment was made the target, and directory
environments were born.</p>

<h2>How does it work?</h2>

<p>Directory environments, essentially, are born out of a folder on the Puppet master
(typically <code>$confdir/environments</code>, where <code>$confdir</code> is <code>/etc/puppetlabs/puppet</code>
in Puppet Enterprise) wherein every subfolder is a new Puppet environment. Every
subfolder contains a couple of key items:</p>

<ul>
<li>A <code>modules</code> folder containing all modules for that environment</li>
<li>A <code>manifests/site.pp</code> file containing the site.pp file for that environment</li>
<li>A new <code>environment.conf</code> file which can be used to set the <code>modulepath</code>, the <code>environment_timeout</code>, and, a new and often-requested feature, the ability to have environment-specific <code>config_version</code> settings</li>
</ul>


<p>Basically, it&rsquo;s everything that R10k ALREADY does with a couple of added goodies
dropped into an <code>environment.conf</code> file. <a href="https://docs.puppetlabs.com/puppet/latest/reference/environments_configuring.html">Feel free to read the official docs
on configuring directory environments</a> for further information
on all of the goodies!</p>

<h2>Cool, how do we set it up?</h2>

<p>It wouldn&rsquo;t be one of my blog posts if it didn&rsquo;t include exact steps to configure
shit, would it? For this walkthrough, I&rsquo;m using a Centos 6.5 vm with DNS working
(i.e. the node can ping itself and knows its own hostname and FQDN), and I&rsquo;ve
already installed an All-in-one installation of Puppet Enterprise 3.3.0. For
the walkthrough, we&rsquo;re going to setup:</p>

<ul>
<li>Directory environments based on a control repo</li>
<li>Hiera data inside a <code>hieradata</code> folder in the control repo</li>
<li>Hiera to use the per-environment hieradata folder</li>
</ul>


<p>Let&rsquo;s start to break down the components:</p>

<h3>The &lsquo;Control Repo&rsquo;?</h3>

<p>Sometime between <a href="http://bit.ly/puppetworkflows3">my initial R10k post</a> and THIS post, the Puppet Labs PS
team has come to call the repository that contains the Puppetfile and is used
to track Puppet environments on all Puppet masters the &lsquo;Control Repo&rsquo; (because
it &lsquo;Controls the creation of Puppet environments&rsquo;, ya dig?  Zack Smith and
James Sweeny are actually pretty tickled about making that name stick). For
the purpose of this demonstration, I&rsquo;m using a repository on Github:</p>

<p><a href="https://github.com/glarizza/puppet_repository">https://github.com/glarizza/puppet_repository</a></p>

<p>Everything you will need for this walkthrough is in that repository, and we
will refer to it frequently. You DO NOT need to use my repository, and it&rsquo;s
definitely going to be required that you create your OWN, but it&rsquo;s there
for reference purposes (and to give you a couple of Puppet manifests to
make setup a bit easier).</p>

<h3>Configuring the Puppet master</h3>

<p>We&rsquo;re going to first clone my control repo to <code>/tmp</code> so we can use it to
configure R10k and the Puppet master itself:</p>

<p>```
[root@master ~]# cd /tmp</p>

<p>[root@master /tmp]# git clone <a href="https://github.com/glarizza/puppet_repository.git">https://github.com/glarizza/puppet_repository.git</a>
Initialized empty Git repository in /tmp/puppet_repository/.git/
remote: Counting objects: 164, done.
remote: Compressing objects: 100% (134/134), done.
remote: Total 164 (delta 54), reused 81 (delta 16)
Receiving objects: 100% (164/164), 22.68 KiB, done.
Resolving deltas: 100% (54/54), done.</p>

<p>[root@master /tmp]# cd puppet_repository
```</p>

<p>Great, I&rsquo;ve cloned my repo. To configure R10k, we&rsquo;re going to need to pull
down Zack Smith&rsquo;s R10k module from the forge with <code>puppet module install zack/r10k</code>
and then use <code>puppet apply</code> on a manifest in my repo with
<code>puppet apply configure_r10k.pp</code>.  <strong>DO NOTE: If you want to use YOUR Control
Repo, and NOT the one I use on Github, then you need to modify the
<code>configure_r10k.pp</code> file and replace the <code>remote</code> property with the URL to
YOUR Control Repo that&rsquo;s housed on a git repository!</strong></p>

<p>```
[root@master /tmp/puppet_repository:production]# puppet module install zack/r10k</p>

<p>Notice: Preparing to install into /etc/puppetlabs/puppet/modules &hellip;
Notice: Downloading from <a href="https://forgeapi.puppetlabs.com">https://forgeapi.puppetlabs.com</a> &hellip;
Notice: Found at least one version of puppetlabs-stdlib compatible with PE (3.3.0);
Notice: Skipping versions which don&rsquo;t express PE compatibility. To install
the most recent version of the module regardless of compatibility
with PE, use the &lsquo;&mdash;ignore-requirements&rsquo; flag.
Notice: Found at least one version of puppetlabs-inifile compatible with PE (3.3.0);
Notice: Skipping versions which don&rsquo;t express PE compatibility. To install
the most recent version of the module regardless of compatibility
with PE, use the &lsquo;&mdash;ignore-requirements&rsquo; flag.
Notice: Found at least one version of puppetlabs-vcsrepo compatible with PE (3.3.0);
Notice: Skipping versions which don&rsquo;t express PE compatibility. To install
the most recent version of the module regardless of compatibility
with PE, use the &lsquo;&mdash;ignore-requirements&rsquo; flag.
Notice: Found at least one version of puppetlabs-concat compatible with PE (3.3.0);
Notice: Skipping versions which don&rsquo;t express PE compatibility. To install
the most recent version of the module regardless of compatibility
with PE, use the &lsquo;&mdash;ignore-requirements&rsquo; flag.
Notice: Installing &mdash; do not interrupt &hellip;
/etc/puppetlabs/puppet/modules
â””â”€â”¬ zack-r10k (v2.2.7)
  â”œâ”€â”¬ gentoo-portage (v2.2.0)
  â”‚ â””â”€â”€ puppetlabs-concat (v1.0.3) [/opt/puppet/share/puppet/modules]
  â”œâ”€â”€ mhuffnagle-make (v0.0.2)
  â”œâ”€â”€ puppetlabs-gcc (v0.2.0)
  â”œâ”€â”€ puppetlabs-git (v0.2.0)
  â”œâ”€â”€ puppetlabs-inifile (v1.1.0) [/opt/puppet/share/puppet/modules]
  â”œâ”€â”€ puppetlabs-pe_gem (v0.0.1)
  â”œâ”€â”€ puppetlabs-ruby (v0.2.1)
  â”œâ”€â”€ puppetlabs-stdlib (v3.2.2) [/opt/puppet/share/puppet/modules]
  â””â”€â”€ puppetlabs-vcsrepo (v1.1.0)</p>

<p>[root@master /tmp/puppet_repository:production]# puppet apply configure_r10k.pp</p>

<p>Notice: Compiled catalog for master.puppetlabs.vm in environment production in 0.71 seconds
Warning: The package type&rsquo;s allow_virtual parameter will be changing its default value from false to true in a future release. If you do not want to allow virtual packages, please explicitly set allow_virtual to false.
   (at /opt/puppet/lib/ruby/site_ruby/1.9.1/puppet/type.rb:816:in `set_default')
Notice: /Stage[main]/R10k::Install/Package[r10k]/ensure: created
Notice: /Stage[main]/R10k::Install::Pe_gem/File[/usr/bin/r10k]/ensure: created
Notice: /Stage[main]/R10k::Config/File[r10k.yaml]/ensure: defined content as &lsquo;{md5}5cda58e8a01e7ff12544d30105d13a2a&rsquo;
Notice: Finished catalog run in 11.24 seconds
```</p>

<p>Performing those commands will successfully setup R10k to point to my Control
Repo out on Github (and, again, if you don&rsquo;t WANT that, then you need to make
the change to the <code>remote</code> property in <code>configure_r10k.pp</code>). We next need to
configure Directory Environments in <code>puppet.conf</code> by setting two attributes:</p>

<ul>
<li><code>environmentpath</code> (Or the path to the folder containing environments)</li>
<li><code>basemodulepath</code> (Or, the set of modules that will be shared across ALL ENVIRONMENTS)</li>
</ul>


<p>I have created a Puppet manifest that will set these attributes, and this
manifest requires the <code>puppetlabs/inifile</code> module from the Puppet Forge.
Fortunately, since I&rsquo;m using Puppet Enterprise, that module is already installed.
If you&rsquo;re using open source Puppet and the module is NOT installed, feel free
to install it by running <code>puppet module install puppetlabs/inifile</code>. Once
this is done, go ahead and execute the manifest by running
<code>puppet apply configure_directory_environments.pp</code>:</p>

<p>```
[root@master /tmp/puppet_repository:production]# puppet apply configure_directory_environments.pp</p>

<p>Notice: Compiled catalog for master.puppetlabs.vm in environment production in 0.05 seconds
Notice: /Stage[main]/Main/Ini_setting[Configure environmentpath]/ensure: created
Notice: /Stage[main]/Main/Ini_setting[Configure basemodulepath]/value: value changed &lsquo;/etc/puppetlabs/puppet/modules:/opt/puppet/share/puppet/modules&rsquo; to &lsquo;$confdir/modules:/opt/puppet/share/puppet/modules&rsquo;
Notice: Finished catalog run in 0.20 seconds
```</p>

<p>The last step to configuring the Puppet master is to execute an R10k run.
We can do that by running <code>r10k deploy environment -pv</code>:</p>

<p>```
[root@master /tmp/puppet_repository:production]# r10k deploy environment -pv</p>

<p>[R10K::Source::Git &ndash; INFO] Determining current branches for &ldquo;<a href="https://github.com/glarizza/puppet_repository.git">https://github.com/glarizza/puppet_repository.git</a>&rdquo;
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment production
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync &ndash; INFO] Deploying profiles into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying ntp into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying profiles into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying ntp into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/production/modules
[R10K::Task::Environment::Deploy &ndash; NOTICE] Deploying environment webinar_env
[R10K::Task::Puppetfile::Sync &ndash; INFO] Loading modules from Puppetfile into queue
[R10K::Task::Module::Sync &ndash; INFO] Deploying profiles into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying haproxy into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying ntp into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying profiles into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying notifyme into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying haproxy into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying mysql into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying ntp into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Module::Sync &ndash; INFO] Deploying apache into /etc/puppetlabs/puppet/environments/webinar_env/modules
[R10K::Task::Deployment::PurgeEnvironments &ndash; INFO] Purging stale environments from /etc/puppetlabs/puppet/environments
```</p>

<p>Great!  Everything should be setup (if you&rsquo;re using my repo)!  My repository has
a production branch, which is what Puppet&rsquo;s default environment is named,
so we can test that everything works by listing out all modules in the main
production environment with the <code>puppet module list</code> command:</p>

<p>```
[root@master /tmp/puppet_repository:production]# puppet module list</p>

<p>Warning: Module &lsquo;puppetlabs-stdlib&rsquo; (v3.2.2) fails to meet some dependencies:
  &lsquo;puppetlabs-ntp&rsquo; (v3.1.2) requires &lsquo;puppetlabs-stdlib&rsquo; (>= 4.0.0)
/etc/puppetlabs/puppet/environments/production/modules
â”œâ”€â”€ notifyme (???)
â”œâ”€â”€ profiles (???)
â”œâ”€â”€ puppetlabs-apache (v1.1.1)
â””â”€â”€ puppetlabs-ntp (v3.1.2)
/etc/puppetlabs/puppet/modules
â”œâ”€â”€ gentoo-portage (v2.2.0)
â”œâ”€â”€ mhuffnagle-make (v0.0.2)
â”œâ”€â”€ puppetlabs-gcc (v0.2.0)
â”œâ”€â”€ puppetlabs-git (v0.2.0)
â”œâ”€â”€ puppetlabs-pe_gem (v0.0.1)
â”œâ”€â”€ puppetlabs-ruby (v0.2.1)
â”œâ”€â”€ puppetlabs-vcsrepo (v1.1.0)
â””â”€â”€ zack-r10k (v2.2.7)
/opt/puppet/share/puppet/modules
â”œâ”€â”€ puppetlabs-apt (v1.5.0)
â”œâ”€â”€ puppetlabs-auth_conf (v0.2.2)
â”œâ”€â”€ puppetlabs-concat (v1.0.3)
â”œâ”€â”€ puppetlabs-firewall (v1.1.2)
â”œâ”€â”€ puppetlabs-inifile (v1.1.0)
â”œâ”€â”€ puppetlabs-java_ks (v1.2.4)
â”œâ”€â”€ puppetlabs-pe_accounts (v2.0.2-3-ge71b5a0)
â”œâ”€â”€ puppetlabs-pe_console_prune (v0.1.1-4-g293f45b)
â”œâ”€â”€ puppetlabs-pe_mcollective (v0.2.10-15-gb8343bb)
â”œâ”€â”€ puppetlabs-pe_postgresql (v1.0.4-4-g0bcffae)
â”œâ”€â”€ puppetlabs-pe_puppetdb (v1.1.1-7-g8cb11bf)
â”œâ”€â”€ puppetlabs-pe_razor (v0.2.1-1-g80acb4d)
â”œâ”€â”€ puppetlabs-pe_repo (v0.7.7-32-gfd1c97f)
â”œâ”€â”€ puppetlabs-pe_staging (v0.3.3-2-g3ed56f8)
â”œâ”€â”€ puppetlabs-postgresql (v2.5.0-pe2)
â”œâ”€â”€ puppetlabs-puppet_enterprise (v3.2.1-27-g8f61956)
â”œâ”€â”€ puppetlabs-reboot (v0.1.4)
â”œâ”€â”€ puppetlabs-request_manager (v0.1.1)
â””â”€â”€ puppetlabs-stdlib (v3.2.2)  invalid
```</p>

<p>Notice a couple of things:</p>

<ul>
<li>First, I&rsquo;ve got some dependency issues&hellip;oh well, nothing that&rsquo;s a game-stopper</li>
<li>Second, the path to the production environment&rsquo;s module is correct at: <code>/etc/puppetlabs/puppet/environments/production/modules</code></li>
</ul>


<h3>Configuring Hiera</h3>

<p>The last dinghy to be configured on this dreamboat is Hiera. Hiera is Puppet&rsquo;s
data lookup mechanism, and is used to gather specific bits of data (such
as versions of packages, hostnames, passwords, and other business-specific
data). Explaining HOW Hiera works is beyond the scope of this article, but
configuring Hiera data on a per-environment basis IS absolutely a worthwhile
endeavor.</p>

<p>In this example, I&rsquo;m going to demonstrate coupling Hiera data with the Control
Repo for simple replication of Hiera data across environments. You COULD also
choose to put your Hiera data in a separate repository and set it up in
<code>/etc/r10k.yaml</code> as another source, but that exercise is left to the reader
<a href="http://bit.ly/puppetworkflows3b">(and if you&rsquo;re interested, I talk about it in this post).</a></p>

<p>You&rsquo;ll notice that my demonstration repository ALREADY includes Hiera data,
and so that data is automatically being replicated to all environments. By
default, Hiera&rsquo;s configuration file (<code>hiera.yaml</code>) has no YAML data directory
specified, so we&rsquo;ll need to make that change.  <a href="https://github.com/glarizza/puppet_repository/blob/production/hiera.yaml">In my demonstration control
repository, I&rsquo;ve included a sample <code>hiera.yaml</code>,</a> but let&rsquo;s take a look at
one below:</p>

<p>```yaml</p>

<h2>/etc/puppetlabs/puppet/hiera.yaml</h2>

<hr />

<p>:backends:
  &ndash; yaml
:hierarchy:
  &ndash; &ldquo;%{clientcert}&rdquo;
  &ndash; &ldquo;%{application_tier}&rdquo;
  &ndash; common</p>

<p>:yaml:</p>

<h1>datadir is empty here, so hiera uses its defaults:</h1>

<h1>&ndash; /var/lib/hiera on *nix</h1>

<h1>&ndash; %CommonAppData%\PuppetLabs\hiera\var on Windows</h1>

<h1>When specifying a datadir, make sure the directory exists.</h1>

<p>  :datadir: &ldquo;/etc/puppetlabs/puppet/environments/%{environment}/hieradata&rdquo;
```</p>

<p>This hiera.yaml file specifies a hierarchy with three levels &ndash; a node-specific,
level, a level for different application tiers (like &lsquo;dev&rsquo;, &lsquo;test&rsquo;, &lsquo;prod&rsquo;, and
etc), and finally makes the change we need: mapping the data directory to each
environment&rsquo;s hieradata folder.  The path to <code>hiera.yaml</code> is Puppet&rsquo;s
configuration directory (which is <code>/etc/puppetlabs/puppet</code> for Puppet
Enterprise, or <code>/etc/puppet</code> for the open source version of Puppet), so open
the file there, make your changes, and finally you&rsquo;ll need to need to restart
the Puppet master service to have the changes picked up.</p>

<p>Next, let&rsquo;s perform a test by executing the <code>hiera</code> binary from the command
line before running puppet:</p>

<p>```
[root@master /etc/puppetlabs/puppet/environments]# hiera message environment=production
This node is using common data</p>

<p>[root@master /etc/puppetlabs/puppet/environments]# hiera message environment=webinar_env -d
DEBUG: 2014-08-31 19:55:44 +0000: Hiera YAML backend starting
DEBUG: 2014-08-31 19:55:44 +0000: Looking up message in YAML backend
DEBUG: 2014-08-31 19:55:44 +0000: Looking for data source common
DEBUG: 2014-08-31 19:55:44 +0000: Found message in common
This node is using common data</p>

<p>[root@master /etc/puppetlabs/puppet/environments]# hiera message environment=bad_env -d
DEBUG: 2014-08-31 19:58:22 +0000: Hiera YAML backend starting
DEBUG: 2014-08-31 19:58:22 +0000: Looking up message in YAML backend
DEBUG: 2014-08-31 19:58:22 +0000: Looking for data source common
DEBUG: 2014-08-31 19:58:22 +0000: Cannot find datafile /etc/puppetlabs/puppet/environments/bad_env/hieradata/common.yaml, skipping
nil
```</p>

<p>You can see that for the first example, I passed the environment of <code>production</code>
and did a simple lookup for a key called <code>message</code> &ndash; Hiera then returned me
the value of out that environment&rsquo;s <code>common.yaml</code> file.  Next, I did another
lookup, but added <code>-d</code> to enable debug mode (debug mode on the <code>hiera</code>
binary is REALLY handy for debugging problems with Hiera &ndash; combine it with
specifying values from the command line, and you can pretty quickly simulate
what value a node is going to get).  Notice the last example where I specified
an invalid environment &ndash; Hiera logged that it couldn&rsquo;t find the datafile
requested and ultimately returned a nil, or empty, value.</p>

<p>Since we&rsquo;re working on the Puppet master machine, we can even check for a value
using <code>puppet apply</code> combined with the notice function:</p>

<p><code>
[root@master /etc/puppetlabs/puppet/environments]# puppet apply -e "notice(hiera('message'))"
Notice: Scope(Class[main]): This node is using common data
Notice: Compiled catalog for master.puppetlabs.vm in environment production in 0.09 seconds
Notice: Finished catalog run in 0.19 seconds
</code></p>

<p>Great, it&rsquo;s working, but let&rsquo;s look at pulling data from a higher level in the
hierarchy &ndash; like from the <code>application_tier</code> level. We haven&rsquo;t defined an
<code>application_tier</code> fact, however, so we&rsquo;ll need to fake it. First, let&rsquo;s do
that with the <code>hiera</code> binary:</p>

<p><code>
[root@master /etc/puppetlabs/puppet/environments]# hiera message environment=production application_tier=dev -d
DEBUG: 2014-08-31 20:04:12 +0000: Hiera YAML backend starting
DEBUG: 2014-08-31 20:04:12 +0000: Looking up message in YAML backend
DEBUG: 2014-08-31 20:04:12 +0000: Looking for data source dev
DEBUG: 2014-08-31 20:04:12 +0000: Found message in dev
You are in the development application tier
</code></p>

<p>And then also with <code>puppet apply</code>:</p>

<p><code>
[root@master /etc/puppetlabs/puppet/environments]# FACTER_application_tier=dev puppet apply -e "notice(hiera('message'))"
Notice: Scope(Class[main]): You are in the development application tier
Notice: Compiled catalog for master.puppetlabs.vm in environment production in 0.09 seconds
Notice: Finished catalog run in 0.18 seconds
</code></p>

<h2>Tuning <code>environment.conf</code></h2>

<p>The brand-new, per-environment  <code>environment.conf</code> file is meant to be (for
the most part) a one-stop-shop for your Puppet environment tuning needs. Right
now, the only things you&rsquo;ll need to tune will be the <code>modulepath</code>,
<code>config_version</code>, and possibly the <code>environment_timeout</code>.</p>

<h3>Module path</h3>

<p>Before directory environments, every environment had its own <code>modulepath</code> that
needed to be tuned to allow for modules that were to be used by this
machine/environment, as well as shared modules.  That <code>modulepath</code> worked like
<code>$PATH</code> in that it was a priority-based lookup for modules (i.e. the first
directory in <code>modulepath</code> that had a module matching the module name you wanted
won).  It also previously required the FULL path to be used for every path in
<code>modulepath</code>.</p>

<p>Those days are over.</p>

<p>As I mentioned before, the main <code>puppet.conf</code> configuration file has a new
parameter called <code>basemodulepath</code> that can be used to specify modules that are
to be shared across ALL modules in ALL environments. Paths defined here
(typically <code>$confdir/modules</code> and <code>/opt/puppet/share/puppet/modules</code>) are
usually put at the END of a <code>modulepath</code> so Puppet can search for any
overridden modules that show up in earlier <code>modulepath</code> paths. In the previous
configuration steps, we executed a manifest that setup <code>basemodulepath</code> to
look like:</p>

<p><code>
basemodulepath = $confdir/modules:/opt/puppet/share/puppet/modules
</code></p>

<p>Again, feel free to add or remove paths (except don&rsquo;t remove
<code>/opt/puppet/share/puppet/modules</code> if you&rsquo;re using Puppet Enterprise, because
that&rsquo;s where all Puppet Enterprise modules are located), especially if you&rsquo;re
using a giant monolithic repo of modules (which was typically done before things
like R10k evolved).</p>

<p>With <code>basemodulepath</code> configured, it&rsquo;s now time to configure the <code>modulepath</code>
to be defined for every environment. My demonstration control repo contains
a sample <code>environment.conf</code> that defines a <code>modulepath</code> like so:</p>

<p><code>
modulepath = modules:$basemodulepath
</code></p>

<p>You&rsquo;ll notice, now, that there are relative paths in <code>modulepath</code>. This is
possible because now each environment contains an <code>environment.conf</code>, and thus
relative paths make sense. In this example, nodes in the production environment
(<code>/etc/puppetlabs/puppet/environments/production</code>) will look for a module by its
name FIRST by looking in a folder called <code>modules</code> inside the current
environment folder (i.e. <code>/etc/puppetlabs/puppet/environments/production/modules/&lt;module_name&gt;</code>).
If the module wasn&rsquo;t found there, it looks for the module in the order that
paths are defined for <code>basemodulepath</code> above. If Puppet fails to find a module
in ANY of the paths, a compile error is raised.</p>

<h3>Per-environment <code>config_version</code></h3>

<p><a href="https://docs.puppetlabs.com/references/stable/configuration.html#configversion">Setting <code>config_version</code> has been around for awhile</a> &ndash; hell,
I remember video of Jeff McCune talking about it at the first Puppetcamp Europe
in like 2010 &ndash; but the new directory environments implementation has fine
tuned it a bit. Previously, <code>config_version</code> was a command executed on the
Puppet master at compile time to determine a string used for versioning the
configuration enforced during that Puppet run. When it&rsquo;s not set it defaults
to something of a time/date stamp off the parser, but it&rsquo;s way more useful to
make it do something like determine the most recent commit hash from a repository.</p>

<p>In the past when we used a giant monolithic repository containing all Puppet
modules, it was SUPER easy to get a single commit hash and be done. As everyone
moved their modules into individual repositories, determining <em>WHAT</em> you were
enforcing became harder. With the birth of R10k an the control repo, we
suddenly had something we could query for the state of our modules being
enforced. The problem existed, though, that with multiple dynamic environments
using multiple git branches, <code>config_version</code> wasn&rsquo;t easily tuned to be able
to grab the most recent commit from every branch.</p>

<p>Now that <code>config_version</code> is set in a per-environment <code>environment.conf</code>, we
can make <code>config_version</code> much smarter. Again, looking in the <code>environment.conf</code>
defined in my demonstration control repo produces this:</p>

<p><code>
config_version = '/usr/bin/git --git-dir $confdir/environments/$environment/.git rev-parse HEAD'
</code></p>

<p>This setting will cause the Puppet master to produce the most recent commit ID
for whatever environment you&rsquo;re in and embed it in the catalog and the report
that is sent back to the Puppet master after a Puppet run.</p>

<p><a href="https://tickets.puppetlabs.com/browse/PUP-3150">I actually discovered a bug in <code>config_version</code> while writing this post</a>,
and it&rsquo;s that <code>config_version</code> is subject to the relative pathing fun that other
<code>environment.conf</code> settings are subject to. Relative pathing is great for things like
<code>modulepath</code>, and it&rsquo;s even good for <code>config_version</code> if you&rsquo;re including the
script you want to run to gather the <code>config_version</code> string inside the control
repo, but using a one-line command that tries to execute a binary on the system
that DOESN&rsquo;T include the full path to the binary causes an error (because Puppet
attempts to look for that binary in the current environment path, and NOT by
searching <code>$PATH</code> on the system).  Feel free to follow or comment on the bug
if the mood hits you.</p>

<h3>Caching and environment_timeout</h3>

<p>The Puppet master loads environments on-request, but it also caches data associated
with each environment to make things faster. This caching is finally tunable on a
per-environment basis by defining the <code>environment_timeout</code> setting in
<code>environment.conf</code>.  The default setting is 3 minutes, which means the Puppet master
will invalidate its caches and reload environment data every 3 minutes, but that&rsquo;s
now tunable. <a href="https://docs.puppetlabs.com/puppet/3.6/reference/environments_configuring.html#environmenttimeout">Definitely read up on this setting before making changes.</a></p>

<h2>Classification</h2>

<p>One of the last new features of directory environments is the ability to include
an environment-specific <code>site.pp</code> file for classification. You could ALWAYS do
this by modifying the <code>manifest</code> configuration item in <code>puppet.conf</code>, but now
each environment can have its own <code>manifest</code> setting. The default behavior is
to have the Puppet master look for <code>manifests/site.pp</code> in every environment
directory, and I really wouldn&rsquo;t change that unless you have a good reason. DO
NOTE, however, that if you&rsquo;re using Puppet Enterprise, you&rsquo;ll need to be careful
with your <code>site.pp</code> file.  Puppet Enterprise defines things like the Filebucket
and overrides for the File resource in <code>site.pp</code>, so if you&rsquo;re using Puppet Enterprise,
you&rsquo;ll need to copy those changes into the <code>site.pp</code> file you add into your control
repo (as I did).</p>

<p>It may take you a couple of times to change your thinking from looking at the main
<code>site.pp</code> in <code>$confdir/manifests</code> to looking at each environment-specific <code>site.pp</code>
file, but definitely take advantage of Puppet&rsquo;s commandline tool to help you track
which <code>site.pp</code> Puppet is monitoring:</p>

<p>```
[root@master /etc/puppetlabs/puppet/environments]# puppet config print manifest
/etc/puppetlabs/puppet/environments/production/manifests</p>

<p>[root@master /etc/puppetlabs/puppet/environments]# puppet config print manifest &mdash;environment webinar_env
/etc/puppetlabs/puppet/environments/webinar_env/manifests
```</p>

<p>You can see that <code>puppet config print</code> can be used to get the path to the
directory that contains <code>site.pp</code>.  Even cooler is what happens when you
specify an environment that doesn&rsquo;t exist:</p>

<p><code>
[root@master /etc/puppetlabs/puppet/environments]# puppet config print manifest --environment bad_env
no_manifest
</code></p>

<p>Yep, Puppet tells you if it can&rsquo;t find the manifest file.  That&rsquo;s pretty cool.</p>

<h2>Wrapping Up</h2>

<p>Even though the new implementation of directory environments is meant to map
closely to a workflow most of us have been using (if you&rsquo;ve been using R10k, that is),
there are still some new features that may take you by surprise. Hopefully this
post gets you started with just enough information to setup your own test
environment and start playing. PLEASE DO make sure to file bugs on any behavior
that comes as unexpected or stops you from using your existing workflow. Cheers!</p>
]]></content>
  </entry>
  
</feed>
